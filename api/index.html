


<!doctype html>
<html lang="kr" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <meta name="author" content="HGU DL Lab">
      
      <link rel="shortcut icon" href="../assets/images/favicon.ico">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.3">
    
    
      
        <title>API - WICWIU</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.947af8d5.min.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/palette.7f672a1f.min.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
      <link rel="stylesheet" href="../stylesheets/gradient-dark.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#summary" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="WICWIU" class="md-header-nav__button md-logo" aria-label="WICWIU">
      
  <img src="../assets/images/favicon.png" alt="logo">

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            WICWIU
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              API
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="검색" placeholder="검색" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/WICWIU/WICWIU/" title="저장소로 이동" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    WICWIU
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="WICWIU" class="md-nav__button md-logo" aria-label="WICWIU">
      
  <img src="../assets/images/favicon.png" alt="logo">

    </a>
    WICWIU
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/WICWIU/WICWIU/" title="저장소로 이동" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    WICWIU
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../about/" title="About" class="md-nav__link">
      About
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        API
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"/></svg>
        </span>
      </label>
    
    <a href="./" title="API" class="md-nav__link md-nav__link--active">
      API
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      목차
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdagradOptimizer" class="md-nav__link">
    class AdagradOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdam" class="md-nav__link">
    class Adam
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdamOptimizer" class="md-nav__link">
    class AdamOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddall" class="md-nav__link">
    class Addall
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddChannelWise" class="md-nav__link">
    class AddChannelWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddColWise" class="md-nav__link">
    class AddColWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAvaragePooling2D" class="md-nav__link">
    class AvaragePooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBatchNormalize" class="md-nav__link">
    class BatchNormalize
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBatchNormalizeLayer" class="md-nav__link">
    class BatchNormalizeLayer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGAN" class="md-nav__link">
    class BEGAN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGANDiscriminatorLoss" class="md-nav__link">
    class BEGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGANGeneratorLoss" class="md-nav__link">
    class BEGANGeneratorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConcatenateChannelWise" class="md-nav__link">
    class ConcatenateChannelWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classContainer" class="md-nav__link">
    class Container
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConvolution2D" class="md-nav__link">
    class Convolution2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConvolutionLayer2D" class="md-nav__link">
    class ConvolutionLayer2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classCrossEntropy" class="md-nav__link">
    class CrossEntropy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDataLoader" class="md-nav__link">
    class DataLoader
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDataset" class="md-nav__link">
    class Dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDropout" class="md-nav__link">
    class Dropout
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classFewShotClassifier" class="md-nav__link">
    class FewShotClassifier
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGAN" class="md-nav__link">
    class GAN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGaussianNoiseGenerator" class="md-nav__link">
    class GaussianNoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGlobalAvaragePooling2D" class="md-nav__link">
    class GlobalAvaragePooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGradientDescentOptimizer" class="md-nav__link">
    class GradientDescentOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classHingeLoss" class="md-nav__link">
    class HingeLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classKNearestNeighbor" class="md-nav__link">
    class KNearestNeighbor
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLinear" class="md-nav__link">
    class Linear
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLongArray" class="md-nav__link">
    class LongArray
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLossFunction" class="md-nav__link">
    class LossFunction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLRelu" class="md-nav__link">
    class LRelu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMatMul" class="md-nav__link">
    class MatMul
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMaxpooling2D" class="md-nav__link">
    class Maxpooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classModule" class="md-nav__link">
    class Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMSE" class="md-nav__link">
    class MSE
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNagOptimizer" class="md-nav__link">
    class NagOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNeuralNetwork" class="md-nav__link">
    class NeuralNetwork
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNoiseGenerator" class="md-nav__link">
    class NoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classOperator" class="md-nav__link">
    class Operator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classOptimizer" class="md-nav__link">
    class Optimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classPRelu" class="md-nav__link">
    class PRelu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classReconstructionError" class="md-nav__link">
    class ReconstructionError
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRecurrent" class="md-nav__link">
    class Recurrent
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRelu" class="md-nav__link">
    class Relu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classReShape" class="md-nav__link">
    class ReShape
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRMSPropOptimizer" class="md-nav__link">
    class RMSPropOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSequential" class="md-nav__link">
    class Sequential
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classShape" class="md-nav__link">
    class Shape
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSigmoid" class="md-nav__link">
    class Sigmoid
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSoftmax" class="md-nav__link">
    class Softmax
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSoftmaxCrossEntropy" class="md-nav__link">
    class SoftmaxCrossEntropy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSwitch" class="md-nav__link">
    class Switch
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTanh" class="md-nav__link">
    class Tanh
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTensor" class="md-nav__link">
    class Tensor
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTensorholder" class="md-nav__link">
    class Tensorholder
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTransposedConvolution2D" class="md-nav__link">
    class TransposedConvolution2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTransposedConvolutionLayer2D" class="md-nav__link">
    class TransposedConvolutionLayer2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTripletLoss" class="md-nav__link">
    class TripletLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classUniformNoiseGenerator" class="md-nav__link">
    class UniformNoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classVanillaGANDiscriminatorLoss" class="md-nav__link">
    class VanillaGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classVanillaGANGeneratorLoss" class="md-nav__link">
    class VanillaGANGeneratorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWData" class="md-nav__link">
    class WData
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWGANDiscriminatorLoss" class="md-nav__link">
    class WGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWGANGeneratorLoss" class="md-nav__link">
    class WGANGeneratorLoss
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      WICWIU 개발 가이드
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="WICWIU 개발 가이드" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        WICWIU 개발 가이드
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1">
    
    <label class="md-nav__link" for="nav-4-1">
      WICWIU
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="WICWIU" data-md-level="2">
      <label class="md-nav__title" for="nav-4-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        WICWIU
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/wicwiu/about/" title="1. About WICWIU" class="md-nav__link">
      1. About WICWIU
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/wicwiu/nn/" title="2. WICWIU 신경망 구성" class="md-nav__link">
      2. WICWIU 신경망 구성
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/wicwiu/learn/" title="3. WICWIU 로 학습하기" class="md-nav__link">
      3. WICWIU 로 학습하기
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/wicwiu/code/" title="4. WICWIU 코드 같이보기" class="md-nav__link">
      4. WICWIU 코드 같이보기
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-2" type="checkbox" id="nav-4-2">
    
    <label class="md-nav__link" for="nav-4-2">
      Git
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Git" data-md-level="2">
      <label class="md-nav__title" for="nav-4-2">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Git
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/Git/git/" title="Collaborate with Git" class="md-nav__link">
      Collaborate with Git
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/Git/message/" title="Commit/PR protocol" class="md-nav__link">
      Commit/PR protocol
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/Git/update/" title="Update forked repo" class="md-nav__link">
      Update forked repo
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-3" type="checkbox" id="nav-4-3">
    
    <label class="md-nav__link" for="nav-4-3">
      GPU Acceleration
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="GPU Acceleration" data-md-level="2">
      <label class="md-nav__title" for="nav-4-3">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        GPU Acceleration
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/GPU/cuda/" title="cuda" class="md-nav__link">
      cuda
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-4" type="checkbox" id="nav-4-4">
    
    <label class="md-nav__link" for="nav-4-4">
      Makefile
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="Makefile" data-md-level="2">
      <label class="md-nav__title" for="nav-4-4">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        Makefile
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/makefile/makefile/" title="Makefile 기본" class="md-nav__link">
      Makefile 기본
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/makefile/makefile2/" title="Makefile 고급" class="md-nav__link">
      Makefile 고급
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-5" type="checkbox" id="nav-4-5">
    
    <label class="md-nav__link" for="nav-4-5">
      CLI
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="CLI" data-md-level="2">
      <label class="md-nav__title" for="nav-4-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        CLI
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/cli/cli/" title="CLI" class="md-nav__link">
      CLI
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/cli/zsh/" title="zsh" class="md-nav__link">
      zsh
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../dev/cli/tmux/" title="tmux" class="md-nav__link">
      tmux
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      WICWIU 분석
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="WICWIU 분석" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        WICWIU 분석
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1">
    
    <label class="md-nav__link" for="nav-5-1">
      fewshot diary
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="fewshot diary" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        fewshot diary
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../doit/fewshot/step1-1/" title="Step 1 (1). Data → Tensor" class="md-nav__link">
      Step 1 (1). Data &rarr; Tensor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../doit/fewshot/step1-2/" title="Step 1 (2). Data → Tensor" class="md-nav__link">
      Step 1 (2). Data &rarr; Tensor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../doit/fewshot/step2/" title="Step 2. 순전파" class="md-nav__link">
      Step 2. 순전파
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../doit/fewshot/step3/" title="Step 3. 역전파" class="md-nav__link">
      Step 3. 역전파
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../doit/fewshot/step4/" title="Step 4. 최적화" class="md-nav__link">
      Step 4. 최적화
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      이곳에 문서 작성하기
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"/></svg>
      </span>
    </label>
    <nav class="md-nav" aria-label="이곳에 문서 작성하기" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
        </span>
        이곳에 문서 작성하기
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../write/markdown/" title="Step 1. Markdown 파일" class="md-nav__link">
      Step 1. Markdown 파일
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/code/" title="Step 2. 소스코드 설명하기" class="md-nav__link">
      Step 2. 소스코드 설명하기
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/format/" title="Step 3. 고오급 포매팅" class="md-nav__link">
      Step 3. 고오급 포매팅
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/admonitions/" title="Step 4. Admonitions" class="md-nav__link">
      Step 4. Admonitions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/tab/" title="Step 5. 컨텐츠 탭" class="md-nav__link">
      Step 5. 컨텐츠 탭
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/button/" title="Step 6. 버튼 넣기" class="md-nav__link">
      Step 6. 버튼 넣기
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/math/" title="Step 7. 수식 보여주기" class="md-nav__link">
      Step 7. 수식 보여주기
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write/api/" title="Step 8. API 작성" class="md-nav__link">
      Step 8. API 작성
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="목차">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </span>
      목차
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdagradOptimizer" class="md-nav__link">
    class AdagradOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdam" class="md-nav__link">
    class Adam
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAdamOptimizer" class="md-nav__link">
    class AdamOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddall" class="md-nav__link">
    class Addall
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddChannelWise" class="md-nav__link">
    class AddChannelWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAddColWise" class="md-nav__link">
    class AddColWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classAvaragePooling2D" class="md-nav__link">
    class AvaragePooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBatchNormalize" class="md-nav__link">
    class BatchNormalize
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBatchNormalizeLayer" class="md-nav__link">
    class BatchNormalizeLayer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGAN" class="md-nav__link">
    class BEGAN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGANDiscriminatorLoss" class="md-nav__link">
    class BEGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classBEGANGeneratorLoss" class="md-nav__link">
    class BEGANGeneratorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConcatenateChannelWise" class="md-nav__link">
    class ConcatenateChannelWise
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classContainer" class="md-nav__link">
    class Container
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConvolution2D" class="md-nav__link">
    class Convolution2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classConvolutionLayer2D" class="md-nav__link">
    class ConvolutionLayer2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classCrossEntropy" class="md-nav__link">
    class CrossEntropy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDataLoader" class="md-nav__link">
    class DataLoader
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDataset" class="md-nav__link">
    class Dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classDropout" class="md-nav__link">
    class Dropout
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classFewShotClassifier" class="md-nav__link">
    class FewShotClassifier
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGAN" class="md-nav__link">
    class GAN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGaussianNoiseGenerator" class="md-nav__link">
    class GaussianNoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGlobalAvaragePooling2D" class="md-nav__link">
    class GlobalAvaragePooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classGradientDescentOptimizer" class="md-nav__link">
    class GradientDescentOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classHingeLoss" class="md-nav__link">
    class HingeLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classKNearestNeighbor" class="md-nav__link">
    class KNearestNeighbor
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLinear" class="md-nav__link">
    class Linear
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLongArray" class="md-nav__link">
    class LongArray
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLossFunction" class="md-nav__link">
    class LossFunction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classLRelu" class="md-nav__link">
    class LRelu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMatMul" class="md-nav__link">
    class MatMul
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMaxpooling2D" class="md-nav__link">
    class Maxpooling2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classModule" class="md-nav__link">
    class Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classMSE" class="md-nav__link">
    class MSE
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNagOptimizer" class="md-nav__link">
    class NagOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNeuralNetwork" class="md-nav__link">
    class NeuralNetwork
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classNoiseGenerator" class="md-nav__link">
    class NoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classOperator" class="md-nav__link">
    class Operator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classOptimizer" class="md-nav__link">
    class Optimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classPRelu" class="md-nav__link">
    class PRelu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classReconstructionError" class="md-nav__link">
    class ReconstructionError
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRecurrent" class="md-nav__link">
    class Recurrent
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRelu" class="md-nav__link">
    class Relu
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classReShape" class="md-nav__link">
    class ReShape
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classRMSPropOptimizer" class="md-nav__link">
    class RMSPropOptimizer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSequential" class="md-nav__link">
    class Sequential
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classShape" class="md-nav__link">
    class Shape
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSigmoid" class="md-nav__link">
    class Sigmoid
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSoftmax" class="md-nav__link">
    class Softmax
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSoftmaxCrossEntropy" class="md-nav__link">
    class SoftmaxCrossEntropy
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classSwitch" class="md-nav__link">
    class Switch
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTanh" class="md-nav__link">
    class Tanh
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTensor" class="md-nav__link">
    class Tensor
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTensorholder" class="md-nav__link">
    class Tensorholder
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTransposedConvolution2D" class="md-nav__link">
    class TransposedConvolution2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTransposedConvolutionLayer2D" class="md-nav__link">
    class TransposedConvolutionLayer2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classTripletLoss" class="md-nav__link">
    class TripletLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classUniformNoiseGenerator" class="md-nav__link">
    class UniformNoiseGenerator
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classVanillaGANDiscriminatorLoss" class="md-nav__link">
    class VanillaGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classVanillaGANGeneratorLoss" class="md-nav__link">
    class VanillaGANGeneratorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWData" class="md-nav__link">
    class WData
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWGANDiscriminatorLoss" class="md-nav__link">
    class WGANDiscriminatorLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classWGANGeneratorLoss" class="md-nav__link">
    class WGANGeneratorLoss
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/WICWIU/WICWIU/edit/master/docs/api.md" title="이 페이지를 편집" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                  <h1>API</h1>
                
                <h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>class</code><a href="#classAdagradOptimizer"><code>AdagradOptimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classAdam"><code>Adam</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classAdamOptimizer"><code>AdamOptimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classAddall"><code>Addall</code></a></td>
<td>값들을 서로 더하는 class</td>
</tr>
<tr>
<td><code>class</code><a href="#classAddChannelWise"><code>AddChannelWise</code></a></td>
<td>서로 더하는 class</td>
</tr>
<tr>
<td><code>class</code><a href="#classAddColWise"><code>AddColWise</code></a></td>
<td>중 Colunm에만 값을 더하는 class</td>
</tr>
<tr>
<td><code>class</code><a href="#classAvaragePooling2D"><code>AvaragePooling2D</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classBatchNormalize"><code>BatchNormalize</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classBatchNormalizeLayer"><code>BatchNormalizeLayer</code></a></td>
<td>구성해 Batch Normalization Layer의 기능을 수행하는 모듈을 생성하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classBEGAN"><code>BEGAN</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classBEGANDiscriminatorLoss"><code>BEGANDiscriminatorLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classBEGANGeneratorLoss"><code>BEGANGeneratorLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classConcatenateChannelWise"><code>ConcatenateChannelWise</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classContainer"><code>Container</code></a></td>
<td>저장하기 위한 Queue에 해당하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classConvolution2D"><code>Convolution2D</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classConvolutionLayer2D"><code>ConvolutionLayer2D</code></a></td>
<td>구성해 2-Dimensional Convolution Layer의 기능을 수행하는 모듈을 생성하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classCrossEntropy"><code>CrossEntropy</code></a></td>
<td>Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classDataLoader"><code>DataLoader</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classDataset"><code>Dataset</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classDropout"><code>Dropout</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classFewShotClassifier"><code>FewShotClassifier</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classGAN"><code>GAN</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classGaussianNoiseGenerator"><code>GaussianNoiseGenerator</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classGlobalAvaragePooling2D"><code>GlobalAvaragePooling2D</code></a></td>
<td>Row * Colunm 공간을 GlobalAvaragePooling하는 클래스.</td>
</tr>
<tr>
<td><code>class</code><a href="#classGradientDescentOptimizer"><code>GradientDescentOptimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classHingeLoss"><code>HingeLoss</code></a></td>
<td>Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classKNearestNeighbor"><code>KNearestNeighbor</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classLinear"><code>Linear</code></a></td>
<td>구성해 fully connected layer의 기능을 수행하는 모듈을 생성하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classLongArray"><code>LongArray</code></a></td>
<td>데이터를 저장하고 관리하는 클래스.</td>
</tr>
<tr>
<td><code>class</code><a href="#classLossFunction"><code>LossFunction</code></a></td>
<td>손실 함수를 계산하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classLRelu"><code>LRelu</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classMatMul"><code>MatMul</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classMaxpooling2D"><code>Maxpooling2D</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classModule"><code>Module</code></a></td>
<td>구성해 모듈화하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classMSE"><code>MSE</code></a></td>
<td>Squared Error) Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classNagOptimizer"><code>NagOptimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a></td>
<td>모델 생성, 학습 및 평가를 총괄하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classNoiseGenerator"><code>NoiseGenerator</code></a></td>
<td><a href="#classTensor">Tensor</a> 클래스의 Random_normal 함수를 사용하여 범위 내의 임의의 값을 갖는 <a href="#classTensor">Tensor</a> 생성</td>
</tr>
<tr>
<td><code>class</code><a href="#classOperator"><code>Operator</code></a></td>
<td>본 프래임워크의 가장 작은 연산 단위.</td>
</tr>
<tr>
<td><code>class</code><a href="#classOptimizer"><code>Optimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classPRelu"><code>PRelu</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classReconstructionError"><code>ReconstructionError</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classRecurrent"><code>Recurrent</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classRelu"><code>Relu</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classReShape"><code>ReShape</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classRMSPropOptimizer"><code>RMSPropOptimizer</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classSequential"><code>Sequential</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classShape"><code>Shape</code></a></td>
<td>정보를 담고 있는 Shape을 저장하고 관리하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classSigmoid"><code>Sigmoid</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classSoftmax"><code>Softmax</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classSoftmaxCrossEntropy"><code>SoftmaxCrossEntropy</code></a></td>
<td>이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classSwitch"><code>Switch</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classTanh"><code>Tanh</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classTensor"><code>Tensor</code></a></td>
<td>저장하고 관리하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classTensorholder"><code>Tensorholder</code></a></td>
<td>Result만 사용하기 위한 클래스.</td>
</tr>
<tr>
<td><code>class</code><a href="#classTransposedConvolution2D"><code>TransposedConvolution2D</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classTransposedConvolutionLayer2D"><code>TransposedConvolutionLayer2D</code></a></td>
<td>구성해 2-Dimensional TransposedConvolution Layer의 기능을 수행하는 모듈을 생성하는 클래스</td>
</tr>
<tr>
<td><code>class</code><a href="#classTripletLoss"><code>TripletLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classUniformNoiseGenerator"><code>UniformNoiseGenerator</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classVanillaGANDiscriminatorLoss"><code>VanillaGANDiscriminatorLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classVanillaGANGeneratorLoss"><code>VanillaGANGeneratorLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classWData"><code>WData</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classWGANDiscriminatorLoss"><code>WGANDiscriminatorLoss</code></a></td>
<td></td>
</tr>
<tr>
<td><code>class</code><a href="#classWGANGeneratorLoss"><code>WGANGeneratorLoss</code></a></td>
<td></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="classAdagradOptimizer">class <code>AdagradOptimizer</code><a class="headerlink" href="#classAdagradOptimizer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class AdagradOptimizer
  : public Optimizer&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAdagradOptimizer_1a57ec3fb8b88c955719598afba8dc7a85"><code>AdagradOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classAdagradOptimizer">AdagradOptimizer</a> 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAdagradOptimizer_1a43f6c5b1975640a30a562ad377cdf877"><code>AdagradOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float epsilon,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classAdagradOptimizer">AdagradOptimizer</a> 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAdagradOptimizer_1a9b28f6ca7f58bd151f44e5043d2735b2"><code>~AdagradOptimizer</code></a><code>()</code></td>
<td><a href="#classAdagradOptimizer">AdagradOptimizer</a> 소멸자</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAdagradOptimizer_1aa4c51cf728ca90d2aa6bc71d1c4f22d6"><code>Delete</code></a><code>()</code></td>
<td>Optimizer의 Delete 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAdagradOptimizer_1a15d0e89567fdbffd4fd2076dbee6f286"><code>Alloc</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAdagradOptimizer_1ae8b0d226a29ac5716fbffe0add5000ed"><code>Alloc</code></a><code>(float epsilon)</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAdagradOptimizer_1addf7ab70645c4d0e5966b8fb72f31b93"><code>InitializeAttributeForGPU</code></a><code>(unsigned int idOfDevice)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAdagradOptimizer_1a770179d3d869898282bb7397e93003fb"><code>UpdateParameter</code></a><code>()</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAdagradOptimizer_1a60131cf4400fbc376bb584a6652f1723"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td>UpdateParameter default 함수</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAdagradOptimizer_1af728a868bb4faf9885d9b2707ebd04ef"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pGradientSquared)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAdagradOptimizer_1a57ec3fb8b88c955719598afba8dc7a85"><code>public inline</code><a href="#classAdagradOptimizer_1a57ec3fb8b88c955719598afba8dc7a85"><code>AdagradOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classAdagradOptimizer">AdagradOptimizer</a> 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(epsilon)</p>
<h4 id="classAdagradOptimizer_1a43f6c5b1975640a30a562ad377cdf877"><code>public inline</code><a href="#classAdagradOptimizer_1a43f6c5b1975640a30a562ad377cdf877"><code>AdagradOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float epsilon,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classAdagradOptimizer">AdagradOptimizer</a> 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>weightDecayRate</code> 가중치 매개변수가 클 때 패널티를 부과하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(epsilon)</p>
<h4 id="classAdagradOptimizer_1a9b28f6ca7f58bd151f44e5043d2735b2"><code>public inline</code><a href="#classAdagradOptimizer_1a9b28f6ca7f58bd151f44e5043d2735b2"><code>~AdagradOptimizer</code></a><code>()</code></h4>
<p><a href="#classAdagradOptimizer">AdagradOptimizer</a> 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classAdagradOptimizer_1aa4c51cf728ca90d2aa6bc71d1c4f22d6"><code>public inline void</code><a href="#classAdagradOptimizer_1aa4c51cf728ca90d2aa6bc71d1c4f22d6"><code>Delete</code></a><code>()</code></h4>
<p>Optimizer의 Delete 매소드</p>
<p>맴버 변수 m_aaGradientSquared 메모리 할당을 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classAdagradOptimizer_1a15d0e89567fdbffd4fd2076dbee6f286"><code>public inline int</code><a href="#classAdagradOptimizer_1a15d0e89567fdbffd4fd2076dbee6f286"><code>Alloc</code></a><code>()</code></h4>
<h4 id="classAdagradOptimizer_1ae8b0d226a29ac5716fbffe0add5000ed"><code>public inline int</code><a href="#classAdagradOptimizer_1ae8b0d226a29ac5716fbffe0add5000ed"><code>Alloc</code></a><code>(float epsilon)</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_ppParameter, m_numOfParameter, m_ppParameter, m_aaGradientSquared 초기화한다.</p>
<p>m_aaGradientSquared m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다. </p>
<h5>Parameters</h5>
<ul>
<li><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: <a href="#classContainer">Container</a>&lt;<a href="#classOperator">Operator<DTYPE></a> <em>&gt;</em> GetTrainableTensor() </p>
<p><strong>See also</strong>: int GetTrainableTensorDegree()</p>
<h4 id="classAdagradOptimizer_1addf7ab70645c4d0e5966b8fb72f31b93"><code>public inline void</code><a href="#classAdagradOptimizer_1addf7ab70645c4d0e5966b8fb72f31b93"><code>InitializeAttributeForGPU</code></a><code>(unsigned int idOfDevice)</code></h4>
<h4 id="classAdagradOptimizer_1a770179d3d869898282bb7397e93003fb"><code>public inline virtual int</code><a href="#classAdagradOptimizer_1a770179d3d869898282bb7397e93003fb"><code>UpdateParameter</code></a><code>()</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_epsilon 유무에 따라 UpdateParameter 호출과 에러 메세지 호출 </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classAdagradOptimizer_1af728a868bb4faf9885d9b2707ebd04ef">UpdateParameter(Operator<DTYPE> *pParameter, Tensor<DTYPE> *m_pGradientSquared)</a></p>
<h4 id="classAdagradOptimizer_1a60131cf4400fbc376bb584a6652f1723"><code>public inline virtual int</code><a href="#classAdagradOptimizer_1a60131cf4400fbc376bb584a6652f1723"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<p>UpdateParameter default 함수</p>
<h5>Parameters</h5>
<ul>
<li><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classAdagradOptimizer_1af728a868bb4faf9885d9b2707ebd04ef"><code>public inline int</code><a href="#classAdagradOptimizer_1af728a868bb4faf9885d9b2707ebd04ef"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pGradientSquared)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>gradient 제곱 값으로 pGradientSquared 업데이트</p>
<p>signed_learning_rate와 gradient의 곱을 업데이트 된 pGradientSquared값에 root를 적용 한 값으로 나누어 파라미터를 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pGradientSquared</code> 업데이트 할 pGradientSquared </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<hr />
<h2 id="classAdam">class <code>Adam</code><a class="headerlink" href="#classAdam" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<hr />
<h2 id="classAdamOptimizer">class <code>AdamOptimizer</code><a class="headerlink" href="#classAdamOptimizer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class AdamOptimizer
  : public Optimizer&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAdamOptimizer_1af21a930d69dbc8ac3a539019c2e0cb34"><code>AdamOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float Beta1,float Beta2,float epsilon,OptimizeDirection pOptimizeDirection)</code></td>
<td>AdamOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAdamOptimizer_1ac06df8f4edbbf0d567e496f09dccfce6"><code>AdamOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float Beta1,float Beta2,float epsilon,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td>AdamOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAdamOptimizer_1add0faced6d3126163acfc4e0c36fa294"><code>~AdamOptimizer</code></a><code>()</code></td>
<td><a href="#classAdamOptimizer">AdamOptimizer</a> 소멸자</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classAdamOptimizer_1a826c98d4c1b0182ad571e3d4ebcdd9a4"><code>Delete</code></a><code>()</code></td>
<td>Optimizer의 Delete 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAdamOptimizer_1acef5cf04a176f41e9ce0db58bcdc4119"><code>Alloc</code></a><code>(float Beta1,float Beta2,float epsilon)</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAdamOptimizer_1a8587c95667564353e1649bfe4c2c34e2"><code>UpdateParameter</code></a><code>()</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAdamOptimizer_1a92911ca3e755b8028a02ee21a57b8c2d"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td>UpdateParameter default 함수</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAdamOptimizer_1a6ee9461e547e56ee60153a53b4ecf246"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pFirstMomentum,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pFirstVelocity,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pUnbiasedMomentum,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pUnbiasedVelocity)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAdamOptimizer_1af21a930d69dbc8ac3a539019c2e0cb34"><code>public inline</code><a href="#classAdamOptimizer_1af21a930d69dbc8ac3a539019c2e0cb34"><code>AdamOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float Beta1,float Beta2,float epsilon,OptimizeDirection pOptimizeDirection)</code></h4>
<p>AdamOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>Beta1</code> FirstMomentum 조정 가중치 값 </p>
</li>
<li>
<p><code>Beta2</code> FirstVelocity 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(Beta1, Beta2, epsilon)</p>
<h4 id="classAdamOptimizer_1ac06df8f4edbbf0d567e496f09dccfce6"><code>public inline</code><a href="#classAdamOptimizer_1ac06df8f4edbbf0d567e496f09dccfce6"><code>AdamOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float Beta1,float Beta2,float epsilon,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p>AdamOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>Beta1</code> FirstMomentum 조정 가중치 값 </p>
</li>
<li>
<p><code>Beta2</code> FirstVelocity 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>weightDecayRate</code> 가중치 매개변수가 클 때 패널티를 부과하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(Beta1, Beta2, epsilon)</p>
<h4 id="classAdamOptimizer_1add0faced6d3126163acfc4e0c36fa294"><code>public inline</code><a href="#classAdamOptimizer_1add0faced6d3126163acfc4e0c36fa294"><code>~AdamOptimizer</code></a><code>()</code></h4>
<p><a href="#classAdamOptimizer">AdamOptimizer</a> 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classAdamOptimizer_1a826c98d4c1b0182ad571e3d4ebcdd9a4"><code>public inline virtual void</code><a href="#classAdamOptimizer_1a826c98d4c1b0182ad571e3d4ebcdd9a4"><code>Delete</code></a><code>()</code></h4>
<p>Optimizer의 Delete 매소드</p>
<p>맴버 변수 m_aaFirstVelocity, m_aaFirstMomentum m_aaUnbiasedVelocity, m_aaUnbiasedMomentum 메모리 할당을 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classAdamOptimizer_1acef5cf04a176f41e9ce0db58bcdc4119"><code>public inline int</code><a href="#classAdamOptimizer_1acef5cf04a176f41e9ce0db58bcdc4119"><code>Alloc</code></a><code>(float Beta1,float Beta2,float epsilon)</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_ppParameter, m_numOfParameter, m_aaFirstVelocity, m_aaUnbiasedVelocity, m_aaFirstMomentum m_aaUnbiasedMomentum를 초기화한다.</p>
<p>m_aaFirstVelocity를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다.</p>
<p>m_aaUnbiasedVelocity를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다.</p>
<p>m_aaFirstMomentum를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다.</p>
<p>m_aaUnbiasedMomentum를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>Beta1</code> FirstMomentum 조정 가중치 값 </p>
</li>
<li>
<p><code>Beta2</code> FirstVelocity 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> Root Sqaure 값이 0이 되는 것을 방지 하는 값 </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: <a href="#classContainer">Container</a>&lt;<a href="#classOperator">Operator<DTYPE></a> <em>&gt;</em> GetTrainableTensor() </p>
<p><strong>See also</strong>: int GetTrainableTensorDegree()</p>
<h4 id="classAdamOptimizer_1a8587c95667564353e1649bfe4c2c34e2"><code>public inline virtual int</code><a href="#classAdamOptimizer_1a8587c95667564353e1649bfe4c2c34e2"><code>UpdateParameter</code></a><code>()</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_Beta1 유무에 따라 UpdateParameter 호출과 에러 메세지 호출 </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classAdamOptimizer_1a6ee9461e547e56ee60153a53b4ecf246">UpdateParameter(Operator<DTYPE> *pParameter, Tensor<DTYPE> *pFirstMomentum, Tensor<DTYPE> *pFirstVelocity, Tensor<DTYPE> *pUnbiasedMomentum, Tensor<DTYPE> *pUnbiasedVelocity)</a></p>
<h4 id="classAdamOptimizer_1a92911ca3e755b8028a02ee21a57b8c2d"><code>public inline virtual int</code><a href="#classAdamOptimizer_1a92911ca3e755b8028a02ee21a57b8c2d"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<p>UpdateParameter default 함수</p>
<h5>Parameters</h5>
<ul>
<li><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classAdamOptimizer_1a6ee9461e547e56ee60153a53b4ecf246"><code>public inline int</code><a href="#classAdamOptimizer_1a6ee9461e547e56ee60153a53b4ecf246"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pFirstMomentum,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pFirstVelocity,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pUnbiasedMomentum,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pUnbiasedVelocity)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_Beta1값으로 가중치가 조정된 pFirstMomentum와 gradinet로 pFirstMomentum를 업데이트 한다.</p>
<p>m_Beta2값으로 가중치가 조정된 pFirstVelocity와 elementwise 연산이 된 gradient로 pFirstVelocity를 업데이트 한다.</p>
<p>학습 초반 부, pFirstMomentum, pFirstVelocity는 0으로 biased 상태이므로 이를 unbiased 해주는 연산하여 업데이트 한다.</p>
<p>signed_learning_rate와 pUnbiasedMomentum곱을 root가 적용된 pUnbiasedVelocity와 m_epsilon으로 나눈 값으로 weight(trainable_data)를 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pFirstMomentum</code> 업데이트 할 pFirstMomentum </p>
</li>
<li>
<p><code>pFirstVelocity</code> 업데이트 할 pFirstVelocity </p>
</li>
<li>
<p><code>pUnbiasedMomentum</code> 업데이트 할 pUnbiasedMomentum </p>
</li>
<li>
<p><code>pUnbiasedVelocity</code> 업데이트 할 pUnbiasedVelocity </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<hr />
<h2 id="classAddall">class <code>Addall</code><a class="headerlink" href="#classAddall" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Addall
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p>값들을 서로 더하는 class</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAddall_1a99310814f54bce052866e8694b4fe6ac"><code>Addall</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLeftInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pRightInput,std::string pName,int pLoadflag)</code></td>
<td>Addall의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAddall_1a690307eba0d553a908b21a1d6f9110a0"><code>~Addall</code></a><code>()</code></td>
<td>Addall의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAddall_1ab8295fc0432e2ba0844df46254b2e5c0"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLeftInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pRightInput)</code></td>
<td>파라미터로 들어온 pLeftInput을 이용해 맴버 변수들을 초기화한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAddall_1acf09771a4170ac38c563890e391cf7b3"><code>Delete</code></a><code>()</code></td>
<td>메모리를 헤제하는 Delete 메소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddall_1a25b0cdf81f3021bf0aca0c9d65977810"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Addall의 forwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddall_1a1fc80ca8d9908d2d126fa1ba6a9264a3"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>Addall의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAddall_1a99310814f54bce052866e8694b4fe6ac"><code>public inline</code><a href="#classAddall_1a99310814f54bce052866e8694b4fe6ac"><code>Addall</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLeftInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pRightInput,std::string pName,int pLoadflag)</code></h4>
<p>Addall의 생성자</p>
<p>pLeftInput, pRightInput을 Alloc시킨다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pLeftInput</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pRightInput</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classAddall_1ab8295fc0432e2ba0844df46254b2e5c0">Alloc(Operator<DTYPE> *pLeftInput, Operator<DTYPE> *pRightInput)</a></p>
</li>
</ul>
<h4 id="classAddall_1a690307eba0d553a908b21a1d6f9110a0"><code>public inline</code><a href="#classAddall_1a690307eba0d553a908b21a1d6f9110a0"><code>~Addall</code></a><code>()</code></h4>
<p>Addall의 소멸자.</p>
<h4 id="classAddall_1ab8295fc0432e2ba0844df46254b2e5c0"><code>public inline int</code><a href="#classAddall_1ab8295fc0432e2ba0844df46254b2e5c0"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLeftInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pRightInput)</code></h4>
<p>파라미터로 들어온 pLeftInput을 이용해 맴버 변수들을 초기화한다.</p>
<p>파라미터로 들어온 pLeftInput과 m_pRightInput의 Shape정보를 맴버변수에 저장하고 다른 맴버 변수들은 pLeftInput의 Shape값으로 초기화한다.</p>
<p>Result값과 gradient값을 저장 할 Tensor를 새로 만든다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>생성</code> 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pRightInput</code> 연산에 사용 할 inputTensor. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddall_1acf09771a4170ac38c563890e391cf7b3"><code>public inline void</code><a href="#classAddall_1acf09771a4170ac38c563890e391cf7b3"><code>Delete</code></a><code>()</code></h4>
<p>메모리를 헤제하는 Delete 메소드.</p>
<p>cudnnDescriptor들을 GPU메모리에서 해제하고 포인터를 null로 초기화한다.</p>
<h4 id="classAddall_1a25b0cdf81f3021bf0aca0c9d65977810"><code>public inline virtual int</code><a href="#classAddall_1a25b0cdf81f3021bf0aca0c9d65977810"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Addall의 forwardPropagate 매소드.</p>
<p>Container에 저장한 left, right의 Result값을 서로 더해 result에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddall_1a1fc80ca8d9908d2d126fa1ba6a9264a3"><code>public inline virtual int</code><a href="#classAddall_1a1fc80ca8d9908d2d126fa1ba6a9264a3"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>Addall의 BackPropagate 매소드.</p>
<p>Container에 저장한 pLeftInput, pRightInput의 Gradient값에 계산한 Gradient값을 각각 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classAddChannelWise">class <code>AddChannelWise</code><a class="headerlink" href="#classAddChannelWise" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class AddChannelWise
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p>서로 더하는 class</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAddChannelWise_1a7128fd2ac40a5e04fb3744e0fa5b020f"><code>AddChannelWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,std::string pName,int pLoadflag)</code></td>
<td>AddChannelWise의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAddChannelWise_1a872112c4eb7b4533024d1625ba8db35e"><code>~AddChannelWise</code></a><code>()</code></td>
<td>AddChannelWise의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAddChannelWise_1a0e8731f2863b1bd143d9684a3ba52f76"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias)</code></td>
<td>파라미터로 들어온 pInput, pBias를 이용해 맴버 변수들을 초기화 한다</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAddChannelWise_1a273d5b9ebf0c74de8cdd0228fc72c9c7"><code>Delete</code></a><code>()</code></td>
<td>메모리를 헤제하는 Delete 메소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddChannelWise_1a0f81d16022df4519a555fe4b1367b902"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>AddChannelWise의 forwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddChannelWise_1ac03a3c81061ad24b3b693b2b9fd9d96a"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>AddColWise의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAddChannelWise_1a7128fd2ac40a5e04fb3744e0fa5b020f"><code>public inline</code><a href="#classAddChannelWise_1a7128fd2ac40a5e04fb3744e0fa5b020f"><code>AddChannelWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,std::string pName,int pLoadflag)</code></h4>
<p>AddChannelWise의 생성자</p>
<p>pInput, pBias을 Alloc시킨다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pBias</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classAddChannelWise_1a0e8731f2863b1bd143d9684a3ba52f76">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pBias)</a></p>
</li>
</ul>
<h4 id="classAddChannelWise_1a872112c4eb7b4533024d1625ba8db35e"><code>public inline</code><a href="#classAddChannelWise_1a872112c4eb7b4533024d1625ba8db35e"><code>~AddChannelWise</code></a><code>()</code></h4>
<p>AddChannelWise의 소멸자.</p>
<h4 id="classAddChannelWise_1a0e8731f2863b1bd143d9684a3ba52f76"><code>public inline int</code><a href="#classAddChannelWise_1a0e8731f2863b1bd143d9684a3ba52f76"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias)</code></h4>
<p>파라미터로 들어온 pInput, pBias를 이용해 맴버 변수들을 초기화 한다</p>
<p>파라미터로 들어온 pInput, pBias의 Shape정보를 맴버 변수에 저장하고 다른 맴버 변수들은 pInput의 Shape값으로 초기화 한다.</p>
<p>Result값과 gradient값을 저장 할 Tensor를 새로 만든다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>생성</code> 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pBias</code> 더할 <a href="#classOperator">Operator</a>. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddChannelWise_1a273d5b9ebf0c74de8cdd0228fc72c9c7"><code>public inline void</code><a href="#classAddChannelWise_1a273d5b9ebf0c74de8cdd0228fc72c9c7"><code>Delete</code></a><code>()</code></h4>
<p>메모리를 헤제하는 Delete 메소드.</p>
<p>cudnnDescriptor들을 GPU메모리에서 해제하고 포인터를 null로 초기화한다.</p>
<h4 id="classAddChannelWise_1a0f81d16022df4519a555fe4b1367b902"><code>public inline virtual int</code><a href="#classAddChannelWise_1a0f81d16022df4519a555fe4b1367b902"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>AddChannelWise의 forwardPropagate 매소드.</p>
<p>Container에 저장한 Input, bias의 Channel값을 Result에 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddChannelWise_1ac03a3c81061ad24b3b693b2b9fd9d96a"><code>public inline virtual int</code><a href="#classAddChannelWise_1ac03a3c81061ad24b3b693b2b9fd9d96a"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>AddColWise의 BackPropagate 매소드.</p>
<p>Container에 저장한 pInput, pBias의 Gradient값애 계산을 통해 구한 gradient값을 각각 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classAddColWise">class <code>AddColWise</code><a class="headerlink" href="#classAddColWise" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class AddColWise
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p>중 Colunm에만 값을 더하는 class</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAddColWise_1a4da3a66eef3f65f59b668ff69b48e218"><code>AddColWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,std::string pName,int pLoadflag)</code></td>
<td>AddColWise의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAddColWise_1a6eb85611bc474cb5ba59d01219eabc93"><code>~AddColWise</code></a><code>()</code></td>
<td>AddColWise의 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAddColWise_1ac3f9ec702b314d273f50a6849cb9be6b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias)</code></td>
<td>파라미터로 들어온 pInput, pBias를 이용해 맴버 변수들을 초기화 한다</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAddColWise_1a02cc4ac173c8750ffe1212a19dee1652"><code>Delete</code></a><code>()</code></td>
<td>메모리를 헤제하는 Delete 메소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddColWise_1a4b89ea2fdc1baa3622a2fe68db8436a8"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>AddColWise의 forwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAddColWise_1ab6c9363fae11d7aaad2293bc69f8c57d"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>AddColWise의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAddColWise_1a4da3a66eef3f65f59b668ff69b48e218"><code>public inline</code><a href="#classAddColWise_1a4da3a66eef3f65f59b668ff69b48e218"><code>AddColWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,std::string pName,int pLoadflag)</code></h4>
<p>AddColWise의 생성자</p>
<p>pInput, pBias을 Alloc시킨다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pBais</code> Alloc할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classAddColWise_1ac3f9ec702b314d273f50a6849cb9be6b">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pBias)</a></p>
</li>
</ul>
<h4 id="classAddColWise_1a6eb85611bc474cb5ba59d01219eabc93"><code>public inline</code><a href="#classAddColWise_1a6eb85611bc474cb5ba59d01219eabc93"><code>~AddColWise</code></a><code>()</code></h4>
<p>AddColWise의 소멸자</p>
<h4 id="classAddColWise_1ac3f9ec702b314d273f50a6849cb9be6b"><code>public inline int</code><a href="#classAddColWise_1ac3f9ec702b314d273f50a6849cb9be6b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias)</code></h4>
<p>파라미터로 들어온 pInput, pBias를 이용해 맴버 변수들을 초기화 한다</p>
<p>파라미터로 들어온 pInput, pBias의 Shape정보를 맴버 변수에 저장하고 다른 맴버 변수들은 pInput의 Shape값으로 초기화 한다.</p>
<p>Result값과 gradient값을 저장 할 Tensor를 새로 만든다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>생성</code> 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pBias</code> 더할 <a href="#classOperator">Operator</a>. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddColWise_1a02cc4ac173c8750ffe1212a19dee1652"><code>public inline void</code><a href="#classAddColWise_1a02cc4ac173c8750ffe1212a19dee1652"><code>Delete</code></a><code>()</code></h4>
<p>메모리를 헤제하는 Delete 메소드.</p>
<p>cudnnDescriptor들을 GPU메모리에서 해제하고 포인터를 null로 초기화한다.</p>
<h4 id="classAddColWise_1a4b89ea2fdc1baa3622a2fe68db8436a8"><code>public inline virtual int</code><a href="#classAddColWise_1a4b89ea2fdc1baa3622a2fe68db8436a8"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>AddColWise의 forwardPropagate 매소드.</p>
<p>Container에 저장한 Input과 bias의 Colunm값을 서로 더해 result에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classAddColWise_1ab6c9363fae11d7aaad2293bc69f8c57d"><code>public inline virtual int</code><a href="#classAddColWise_1ab6c9363fae11d7aaad2293bc69f8c57d"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>AddColWise의 BackPropagate 매소드.</p>
<p>Container에 저장한 pInput, pBias의 Gradient값에 계산을 통해 구한 gradient값을 각각 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0으로 사용한다. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classAvaragePooling2D">class <code>AvaragePooling2D</code><a class="headerlink" href="#classAvaragePooling2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class AvaragePooling2D
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classAvaragePooling2D_1a5562be05630dade6f325154bab08cf78"><code>AvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAvaragePooling2D_1a8c55c1dd95cda860ac2b1f2a78bab8a8"><code>AvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,int padding,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classAvaragePooling2D_1a5307b5225eb6eed73c0c3a90d7baf4e9"><code>~AvaragePooling2D</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classAvaragePooling2D_1a94be8a4f17e668f11a9453f974318ad3"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int strideRow,int strideCol,int maskRow,int maskCol,int padding1,int padding2)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classAvaragePooling2D_1a13fdef673da9370396f639d611c7cf19"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAvaragePooling2D_1a9f1c1689f694564e669877834a661ec6"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classAvaragePooling2D_1a7ac66b567e2ed27c16e9a501d7cbcf5a"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classAvaragePooling2D_1a5562be05630dade6f325154bab08cf78"><code>public inline</code><a href="#classAvaragePooling2D_1a5562be05630dade6f325154bab08cf78"><code>AvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,std::string pName,int pLoadflag)</code></h4>
<h4 id="classAvaragePooling2D_1a8c55c1dd95cda860ac2b1f2a78bab8a8"><code>public inline</code><a href="#classAvaragePooling2D_1a8c55c1dd95cda860ac2b1f2a78bab8a8"><code>AvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,int padding,std::string pName,int pLoadflag)</code></h4>
<h4 id="classAvaragePooling2D_1a5307b5225eb6eed73c0c3a90d7baf4e9"><code>public inline</code><a href="#classAvaragePooling2D_1a5307b5225eb6eed73c0c3a90d7baf4e9"><code>~AvaragePooling2D</code></a><code>()</code></h4>
<h4 id="classAvaragePooling2D_1a94be8a4f17e668f11a9453f974318ad3"><code>public inline int</code><a href="#classAvaragePooling2D_1a94be8a4f17e668f11a9453f974318ad3"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int strideRow,int strideCol,int maskRow,int maskCol,int padding1,int padding2)</code></h4>
<h4 id="classAvaragePooling2D_1a13fdef673da9370396f639d611c7cf19"><code>public inline void</code><a href="#classAvaragePooling2D_1a13fdef673da9370396f639d611c7cf19"><code>Delete</code></a><code>()</code></h4>
<h4 id="classAvaragePooling2D_1a9f1c1689f694564e669877834a661ec6"><code>public inline virtual int</code><a href="#classAvaragePooling2D_1a9f1c1689f694564e669877834a661ec6"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classAvaragePooling2D_1a7ac66b567e2ed27c16e9a501d7cbcf5a"><code>public inline virtual int</code><a href="#classAvaragePooling2D_1a7ac66b567e2ed27c16e9a501d7cbcf5a"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classBatchNormalize">class <code>BatchNormalize</code><a class="headerlink" href="#classBatchNormalize" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class BatchNormalize
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classBatchNormalize_1a4605ef6bc6c23d61101f1eebc013d5bf"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classBatchNormalize_1aca6d3c52ef215361278126874af0ea15"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pEpsilon,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBatchNormalize_1a76815c0f13105d944722e17476513838"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBatchNormalize_1a3b0cce7d21f6b99f5d70aacb35b08200"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classBatchNormalize_1af44186c9a81c0473bc1101bcc308233e"><code>SetModeTrain</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classBatchNormalize_1acb076b958c2d46e45538b0c04e05bdb1"><code>SetModeAccumulate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classBatchNormalize_1a1d241bfdb2cb113b604aa88765e87c06"><code>SetModeInference</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classBatchNormalize_1aabded28cf8fb2059330a4766f1d273e1"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classBatchNormalize_1a371b4a12a3411b4aa0f0026e256bb063"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pMomentum,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classBatchNormalize_1aa2ca8ff9c4ea80162f304ab3bf1e57e2"><code>~BatchNormalize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classBatchNormalize_1a69a2918f7563e8a754c6f92e8d983292"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pMomentum,double pEpsilon)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBatchNormalize_1ac9945da88b6fdbe32f3e1aa4fda7e631"><code>SetModeTrain</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBatchNormalize_1a01bfe41e2200672f179704ba71c044a0"><code>SetModeAccumulate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBatchNormalize_1a0ecddabe78a70f92f150f83428eecabc"><code>SetModeInference</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classBatchNormalize_1a4605ef6bc6c23d61101f1eebc013d5bf"><code>public inline</code><a href="#classBatchNormalize_1a4605ef6bc6c23d61101f1eebc013d5bf"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,std::string pName)</code></h4>
<h4 id="classBatchNormalize_1aca6d3c52ef215361278126874af0ea15"><code>public inline</code><a href="#classBatchNormalize_1aca6d3c52ef215361278126874af0ea15"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pEpsilon,std::string pName)</code></h4>
<h4 id="classBatchNormalize_1a76815c0f13105d944722e17476513838"><code>public inline virtual int</code><a href="#classBatchNormalize_1a76815c0f13105d944722e17476513838"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classBatchNormalize_1a3b0cce7d21f6b99f5d70aacb35b08200"><code>public inline virtual int</code><a href="#classBatchNormalize_1a3b0cce7d21f6b99f5d70aacb35b08200"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classBatchNormalize_1af44186c9a81c0473bc1101bcc308233e"><code>public inline virtual void</code><a href="#classBatchNormalize_1af44186c9a81c0473bc1101bcc308233e"><code>SetModeTrain</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1acb076b958c2d46e45538b0c04e05bdb1"><code>public inline virtual void</code><a href="#classBatchNormalize_1acb076b958c2d46e45538b0c04e05bdb1"><code>SetModeAccumulate</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1a1d241bfdb2cb113b604aa88765e87c06"><code>public inline virtual void</code><a href="#classBatchNormalize_1a1d241bfdb2cb113b604aa88765e87c06"><code>SetModeInference</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1aabded28cf8fb2059330a4766f1d273e1"><code>public inline</code><a href="#classBatchNormalize_1aabded28cf8fb2059330a4766f1d273e1"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,std::string pName,int pLoadflag)</code></h4>
<h4 id="classBatchNormalize_1a371b4a12a3411b4aa0f0026e256bb063"><code>public inline</code><a href="#classBatchNormalize_1a371b4a12a3411b4aa0f0026e256bb063"><code>BatchNormalize</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pMomentum,std::string pName,int pLoadflag)</code></h4>
<h4 id="classBatchNormalize_1aa2ca8ff9c4ea80162f304ab3bf1e57e2"><code>public inline</code><a href="#classBatchNormalize_1aa2ca8ff9c4ea80162f304ab3bf1e57e2"><code>~BatchNormalize</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1a69a2918f7563e8a754c6f92e8d983292"><code>public inline int</code><a href="#classBatchNormalize_1a69a2918f7563e8a754c6f92e8d983292"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pScale,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pBias,int pIsChannelwise,float pMomentum,double pEpsilon)</code></h4>
<h4 id="classBatchNormalize_1ac9945da88b6fdbe32f3e1aa4fda7e631"><code>public inline virtual int</code><a href="#classBatchNormalize_1ac9945da88b6fdbe32f3e1aa4fda7e631"><code>SetModeTrain</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1a01bfe41e2200672f179704ba71c044a0"><code>public inline virtual int</code><a href="#classBatchNormalize_1a01bfe41e2200672f179704ba71c044a0"><code>SetModeAccumulate</code></a><code>()</code></h4>
<h4 id="classBatchNormalize_1a0ecddabe78a70f92f150f83428eecabc"><code>public inline virtual int</code><a href="#classBatchNormalize_1a0ecddabe78a70f92f150f83428eecabc"><code>SetModeInference</code></a><code>()</code></h4>
<hr />
<h2 id="classBatchNormalizeLayer">class <code>BatchNormalizeLayer</code><a class="headerlink" href="#classBatchNormalizeLayer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class BatchNormalizeLayer
  : public Module&lt; DTYPE &gt;
</code></pre></div>

<p>구성해 Batch Normalization Layer의 기능을 수행하는 모듈을 생성하는 클래스</p>
<p>Operator들을 뉴럴 네트워크의 서브 그래프로 구성해 Batch Normalization Layer의 기능을 수행한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classBatchNormalizeLayer_1ab72f27059f143d70809c44186c3aec2a"><code>BatchNormalizeLayer</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pIsChannelwise,std::string pName)</code></td>
<td><a href="#classBatchNormalizeLayer">BatchNormalizeLayer</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classBatchNormalizeLayer_1a53b3cc13dbea61c9845277bfbc88c935"><code>~BatchNormalizeLayer</code></a><code>()</code></td>
<td><a href="#classBatchNormalizeLayer">BatchNormalizeLayer</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classBatchNormalizeLayer_1ad61e05b3ff8a276a1021671d1e2af814"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pIsChannelwise,std::string pName)</code></td>
<td>Batch Normalize Layer 그래프를 동적으로 할당 및 구성하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classBatchNormalizeLayer_1ab72f27059f143d70809c44186c3aec2a"><code>public inline</code><a href="#classBatchNormalizeLayer_1ab72f27059f143d70809c44186c3aec2a"><code>BatchNormalizeLayer</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pIsChannelwise,std::string pName)</code></h4>
<p><a href="#classBatchNormalizeLayer">BatchNormalizeLayer</a> 클래스 생성자</p>
<p><a href="#classBatchNormalizeLayer">BatchNormalizeLayer</a> 클래스의 Alloc 메소드를 호출한다. 
<strong>See also</strong>: <a href="#classBatchNormalizeLayer_1ad61e05b3ff8a276a1021671d1e2af814">BatchNormalizeLayer<DTYPE>::Alloc(Operator<DTYPE> *pInput, int pIsChannelwise, std::string pName)</a></p>
<h4 id="classBatchNormalizeLayer_1a53b3cc13dbea61c9845277bfbc88c935"><code>public inline virtual</code><a href="#classBatchNormalizeLayer_1a53b3cc13dbea61c9845277bfbc88c935"><code>~BatchNormalizeLayer</code></a><code>()</code></h4>
<p><a href="#classBatchNormalizeLayer">BatchNormalizeLayer</a> 클래스 소멸자</p>
<p>단, 동적 할당 받은 Operator들은 NeuralNetwork에서 할당 해제한다.</p>
<h4 id="classBatchNormalizeLayer_1ad61e05b3ff8a276a1021671d1e2af814"><code>public inline int</code><a href="#classBatchNormalizeLayer_1ad61e05b3ff8a276a1021671d1e2af814"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pIsChannelwise,std::string pName)</code></h4>
<p>Batch Normalize Layer 그래프를 동적으로 할당 및 구성하는 메소드</p>
<p>Input Operator의 Element에 대해 배치 정규화(Batch Normailzation)을 수행한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 해당 Layer의 Input에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pIsChannelWise</code> Column-Wise Normalization 유무, 0일 시 Column-Wise롤 연산, 0이 아닐 시 Channel-Wise로 연산 </p>
</li>
<li>
<p><code>pName</code> Module의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: BatchNormalize<DTYPE>::BatchNormalize(<a href="#classOperator">Operator<DTYPE></a> *pInput, <a href="#classOperator">Operator<DTYPE></a> *pScale, <a href="#classOperator">Operator<DTYPE></a> *pBias, int pIsChannelwise = TRUE, std::string pName = NULL) <a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614">Module<DTYPE>::AnalyzeGraph(Operator<DTYPE> *pResultOperator)</a></p>
<hr />
<h2 id="classBEGAN">class <code>BEGAN</code><a class="headerlink" href="#classBEGAN" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class BEGAN
  : public GAN&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classBEGAN_1a691d96dc6bc0f76f7a45f92b32ec1f0f"><code>BEGAN</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classBEGAN_1a41c615f2d72167b0d308760de9409c6f"><code>~BEGAN</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classBEGAN_1aa4fff3a445d061d3d5011267b1586db6"><code>SetBEGANParameter</code></a><code>(float pK,float pLamda,float pGamma)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1a3fe4d0faae4798618228b458a21a96d5"><code>TrainGeneratorOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1a17c4c345f733cf7eb626bfd893485cac"><code>ComputeGradientOfDiscriminatorAboutRealOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1a8a924de74987dd2d612912fa5dcdb9fc"><code>ComputeGradientOfDiscriminatorAboutFakeOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1acbbbd6c8d4ba0ebefa5c5ad71347a851"><code>TrainGeneratorOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1abbb29ae231c784b87d3272cbe9a38cb1"><code>ComputeGradientOfDiscriminatorAboutRealOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classBEGAN_1a5933ab766907aaf7facf189af99ed7f2"><code>ComputeGradientOfDiscriminatorAboutFakeOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1a12c9a7c35f4b54fe3c5b03191f5ba806"><code>SaveLossX</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1a8b25215b2c15691974500d0bf4a1db63"><code>SaveLossG</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classBEGAN_1a914e5d0a2d6f26e891d0ef03998902f8"><code>MultiplyKOnOutput</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classBEGAN_1a715adb9b5a846c4d3f4f7fbac1f8e59e"><code>MultiplyKOnGradient</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1a152d0737c8d9fb04f94526cfaaebf95b"><code>UpdateK</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1af8769254fa4066ddf34ef9bd89548a8e"><code>GetK</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1ade9b978d04828413c248e6418d23b67c"><code>ComputeConvergenceMeasure</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classBEGAN_1a06ba784c4b1956fd1de5d11ba766fdde"><code>GetConvergenceMeasure</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classBEGAN_1a691d96dc6bc0f76f7a45f92b32ec1f0f"><code>public</code><a href="#classBEGAN_1a691d96dc6bc0f76f7a45f92b32ec1f0f"><code>BEGAN</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a41c615f2d72167b0d308760de9409c6f"><code>public virtual</code><a href="#classBEGAN_1a41c615f2d72167b0d308760de9409c6f"><code>~BEGAN</code></a><code>()</code></h4>
<h4 id="classBEGAN_1aa4fff3a445d061d3d5011267b1586db6"><code>public int</code><a href="#classBEGAN_1aa4fff3a445d061d3d5011267b1586db6"><code>SetBEGANParameter</code></a><code>(float pK,float pLamda,float pGamma)</code></h4>
<h4 id="classBEGAN_1a3fe4d0faae4798618228b458a21a96d5"><code>public virtual int</code><a href="#classBEGAN_1a3fe4d0faae4798618228b458a21a96d5"><code>TrainGeneratorOnCPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a17c4c345f733cf7eb626bfd893485cac"><code>public virtual int</code><a href="#classBEGAN_1a17c4c345f733cf7eb626bfd893485cac"><code>ComputeGradientOfDiscriminatorAboutRealOnCPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a8a924de74987dd2d612912fa5dcdb9fc"><code>public virtual int</code><a href="#classBEGAN_1a8a924de74987dd2d612912fa5dcdb9fc"><code>ComputeGradientOfDiscriminatorAboutFakeOnCPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1acbbbd6c8d4ba0ebefa5c5ad71347a851"><code>public virtual int</code><a href="#classBEGAN_1acbbbd6c8d4ba0ebefa5c5ad71347a851"><code>TrainGeneratorOnGPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1abbb29ae231c784b87d3272cbe9a38cb1"><code>public virtual int</code><a href="#classBEGAN_1abbb29ae231c784b87d3272cbe9a38cb1"><code>ComputeGradientOfDiscriminatorAboutRealOnGPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a5933ab766907aaf7facf189af99ed7f2"><code>public virtual int</code><a href="#classBEGAN_1a5933ab766907aaf7facf189af99ed7f2"><code>ComputeGradientOfDiscriminatorAboutFakeOnGPU</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a12c9a7c35f4b54fe3c5b03191f5ba806"><code>public float</code><a href="#classBEGAN_1a12c9a7c35f4b54fe3c5b03191f5ba806"><code>SaveLossX</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a8b25215b2c15691974500d0bf4a1db63"><code>public float</code><a href="#classBEGAN_1a8b25215b2c15691974500d0bf4a1db63"><code>SaveLossG</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a914e5d0a2d6f26e891d0ef03998902f8"><code>public int</code><a href="#classBEGAN_1a914e5d0a2d6f26e891d0ef03998902f8"><code>MultiplyKOnOutput</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a715adb9b5a846c4d3f4f7fbac1f8e59e"><code>public int</code><a href="#classBEGAN_1a715adb9b5a846c4d3f4f7fbac1f8e59e"><code>MultiplyKOnGradient</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a152d0737c8d9fb04f94526cfaaebf95b"><code>public float</code><a href="#classBEGAN_1a152d0737c8d9fb04f94526cfaaebf95b"><code>UpdateK</code></a><code>()</code></h4>
<h4 id="classBEGAN_1af8769254fa4066ddf34ef9bd89548a8e"><code>public float</code><a href="#classBEGAN_1af8769254fa4066ddf34ef9bd89548a8e"><code>GetK</code></a><code>()</code></h4>
<h4 id="classBEGAN_1ade9b978d04828413c248e6418d23b67c"><code>public float</code><a href="#classBEGAN_1ade9b978d04828413c248e6418d23b67c"><code>ComputeConvergenceMeasure</code></a><code>()</code></h4>
<h4 id="classBEGAN_1a06ba784c4b1956fd1de5d11ba766fdde"><code>public float</code><a href="#classBEGAN_1a06ba784c4b1956fd1de5d11ba766fdde"><code>GetConvergenceMeasure</code></a><code>()</code></h4>
<hr />
<h2 id="classBEGANDiscriminatorLoss">class <code>BEGANDiscriminatorLoss</code><a class="headerlink" href="#classBEGANDiscriminatorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class BEGANDiscriminatorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classBEGANDiscriminatorLoss_1a010715fe26fff2e5e007ed15ea9c5655"><code>BEGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classBEGANDiscriminatorLoss_1a26e2bed92059fa4e06bac852d58cd223"><code>~BEGANDiscriminatorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBEGANDiscriminatorLoss_1a6b019fee5c76d833b057538852d003a1"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classBEGANDiscriminatorLoss_1ab3a4d840369f2f372ac7985f3c05c024"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANDiscriminatorLoss_1ae4ea63a8093be7984d96c1d7c31663bf"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANDiscriminatorLoss_1af0637d48c60d55b356aaed92c8b24401"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classBEGANDiscriminatorLoss_1a010715fe26fff2e5e007ed15ea9c5655"><code>public inline</code><a href="#classBEGANDiscriminatorLoss_1a010715fe26fff2e5e007ed15ea9c5655"><code>BEGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classBEGANDiscriminatorLoss_1a26e2bed92059fa4e06bac852d58cd223"><code>public inline virtual</code><a href="#classBEGANDiscriminatorLoss_1a26e2bed92059fa4e06bac852d58cd223"><code>~BEGANDiscriminatorLoss</code></a><code>()</code></h4>
<h4 id="classBEGANDiscriminatorLoss_1a6b019fee5c76d833b057538852d003a1"><code>public inline virtual int</code><a href="#classBEGANDiscriminatorLoss_1a6b019fee5c76d833b057538852d003a1"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<h4 id="classBEGANDiscriminatorLoss_1ab3a4d840369f2f372ac7985f3c05c024"><code>public inline virtual void</code><a href="#classBEGANDiscriminatorLoss_1ab3a4d840369f2f372ac7985f3c05c024"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classBEGANDiscriminatorLoss_1ae4ea63a8093be7984d96c1d7c31663bf"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANDiscriminatorLoss_1ae4ea63a8093be7984d96c1d7c31663bf"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classBEGANDiscriminatorLoss_1af0637d48c60d55b356aaed92c8b24401"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANDiscriminatorLoss_1af0637d48c60d55b356aaed92c8b24401"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classBEGANGeneratorLoss">class <code>BEGANGeneratorLoss</code><a class="headerlink" href="#classBEGANGeneratorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class BEGANGeneratorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classBEGANGeneratorLoss_1a08d4ff8cf1d6c1928f6d505593b09044"><code>BEGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classBEGANGeneratorLoss_1aa0f955a8e83ec6ad45bd05723b11f949"><code>~BEGANGeneratorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classBEGANGeneratorLoss_1a30b7cddd07e653b0e32db6d995344018"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classBEGANGeneratorLoss_1a0166fb27d354569a87b16c9625a31611"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANGeneratorLoss_1a49c3bcc602a251960dbf5f150a8cd4c3"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANGeneratorLoss_1a1e6802c0db50cc63f1e1537f818d89ad"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classBEGANGeneratorLoss_1a08d4ff8cf1d6c1928f6d505593b09044"><code>public inline</code><a href="#classBEGANGeneratorLoss_1a08d4ff8cf1d6c1928f6d505593b09044"><code>BEGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classBEGANGeneratorLoss_1aa0f955a8e83ec6ad45bd05723b11f949"><code>public inline virtual</code><a href="#classBEGANGeneratorLoss_1aa0f955a8e83ec6ad45bd05723b11f949"><code>~BEGANGeneratorLoss</code></a><code>()</code></h4>
<h4 id="classBEGANGeneratorLoss_1a30b7cddd07e653b0e32db6d995344018"><code>public inline virtual int</code><a href="#classBEGANGeneratorLoss_1a30b7cddd07e653b0e32db6d995344018"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<h4 id="classBEGANGeneratorLoss_1a0166fb27d354569a87b16c9625a31611"><code>public inline virtual void</code><a href="#classBEGANGeneratorLoss_1a0166fb27d354569a87b16c9625a31611"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classBEGANGeneratorLoss_1a49c3bcc602a251960dbf5f150a8cd4c3"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANGeneratorLoss_1a49c3bcc602a251960dbf5f150a8cd4c3"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classBEGANGeneratorLoss_1a1e6802c0db50cc63f1e1537f818d89ad"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classBEGANGeneratorLoss_1a1e6802c0db50cc63f1e1537f818d89ad"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classConcatenateChannelWise">class <code>ConcatenateChannelWise</code><a class="headerlink" href="#classConcatenateChannelWise" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class ConcatenateChannelWise
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classConcatenateChannelWise_1a6b96ab6f8de1e8827f37299eef63d293"><code>ConcatenateChannelWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classConcatenateChannelWise_1a06b00347d6de66d5eae8a4ed178d4909"><code>~ConcatenateChannelWise</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classConcatenateChannelWise_1ae5ac08e3680e10d46d95647eaa1de3fe"><code>Alloc</code></a><code>(int noOperator,...)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classConcatenateChannelWise_1ae37a10c31cf4635de1fae1245b872193"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classConcatenateChannelWise_1a2d4fe7b4d6901c4a2330d5c533c974b2"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classConcatenateChannelWise_1a6b96ab6f8de1e8827f37299eef63d293"><code>public inline</code><a href="#classConcatenateChannelWise_1a6b96ab6f8de1e8827f37299eef63d293"><code>ConcatenateChannelWise</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></h4>
<h4 id="classConcatenateChannelWise_1a06b00347d6de66d5eae8a4ed178d4909"><code>public inline</code><a href="#classConcatenateChannelWise_1a06b00347d6de66d5eae8a4ed178d4909"><code>~ConcatenateChannelWise</code></a><code>()</code></h4>
<h4 id="classConcatenateChannelWise_1ae5ac08e3680e10d46d95647eaa1de3fe"><code>public inline int</code><a href="#classConcatenateChannelWise_1ae5ac08e3680e10d46d95647eaa1de3fe"><code>Alloc</code></a><code>(int noOperator,...)</code></h4>
<h4 id="classConcatenateChannelWise_1ae37a10c31cf4635de1fae1245b872193"><code>public inline virtual int</code><a href="#classConcatenateChannelWise_1ae37a10c31cf4635de1fae1245b872193"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classConcatenateChannelWise_1a2d4fe7b4d6901c4a2330d5c533c974b2"><code>public inline virtual int</code><a href="#classConcatenateChannelWise_1a2d4fe7b4d6901c4a2330d5c533c974b2"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classContainer">class <code>Container</code><a class="headerlink" href="#classContainer" title="Permanent link">&para;</a></h2>
<p>저장하기 위한 Queue에 해당하는 클래스</p>
<p><a href="#classTensor">Tensor</a>, <a href="#classOperator">Operator</a>, <a href="#classTensorholder">Tensorholder</a> 세 가지 클래스에 대한 Queue를 동적으로 할당한다.</p>
<p>기본 queue 구조에 인덱스를 이용한 접근 및 역순으로 접근 등 추가적인 메소드가 구현되어 있다.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classContainer_1ab2bf85021abd93687431712eec397bd6"><code>Container</code></a><code>()</code></td>
<td><a href="#classContainer">Container</a> 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classContainer_1aa842cc3579205a9431569dea02b0976e"><code>~Container</code></a><code>()</code></td>
<td><a href="#classContainer">Container</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classContainer_1ac875fe061a6d4c1137def5251eaef95a"><code>Push</code></a><code>(DTYPE pElement)</code></td>
<td>Queue의 push 메소드</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classContainer_1ad7b9f7d5eb283748a0d31389b487e396"><code>Pop</code></a><code>()</code></td>
<td>Queue의 pop 메소드</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classContainer_1a15c8f4962022d9ad82ffb6c721b672f9"><code>Pop</code></a><code>(DTYPE pElement)</code></td>
<td>Queue에서 Element를 찾아 반환하는 pop 메소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classContainer_1ab86a61645d5fff30cff8062e7988b770"><code>Reverse</code></a><code>()</code></td>
<td>Queue를 역순으로 재할당해주는 메소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classContainer_1a4f113e1ecebcf3a21273aefd26d7bbb5"><code>SetElement</code></a><code>(DTYPE pElement,unsigned int index)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classContainer_1ac0cc8e4e6056e832c4874635ac871c40"><code>GetSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classContainer_1ac4fb1b6458674b9876afb4b1fa18c4a9"><code>GetLast</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline DTYPE *</code><a href="#classContainer_1adbb3e154598ae672e37283a1fb292ba2"><code>GetRawData</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classContainer_1a127e7b9fa3de03c7f7f866190fd1c585"><code>GetElement</code></a><code>(unsigned int index)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline DTYPE &amp;</code><a href="#classContainer_1a884d3c64b1d6556018585569d8f00994"><code>operator[]</code></a><code>(unsigned int index)</code></td>
<td>[]연산자 오버로딩</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classContainer_1ab2bf85021abd93687431712eec397bd6"><code>public inline</code><a href="#classContainer_1ab2bf85021abd93687431712eec397bd6"><code>Container</code></a><code>()</code></h4>
<p><a href="#classContainer">Container</a> 생성자</p>
<p>각 멤버 변수를 초기화하여 <a href="#classContainer">Container</a> 클래스를 생성한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classContainer_1aa842cc3579205a9431569dea02b0976e"><code>public inline virtual</code><a href="#classContainer_1aa842cc3579205a9431569dea02b0976e"><code>~Container</code></a><code>()</code></h4>
<p><a href="#classContainer">Container</a> 클래스 소멸자</p>
<p>해당 <a href="#classContainer">Container</a> 클래스를 위해 동적으로 할당된 메모리 공간을 반환하고 클래스를 소멸한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classContainer_1ac875fe061a6d4c1137def5251eaef95a"><code>public inline int</code><a href="#classContainer_1ac875fe061a6d4c1137def5251eaef95a"><code>Push</code></a><code>(DTYPE pElement)</code></h4>
<p>Queue의 push 메소드</p>
<p>기존의 queue를 할당 해제하고 매개변수로 받은 Element를 마지막에 추가하여 새로운 Queue를 동적으로 할당한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pElement</code> Queue에 추가하고자 하는 변수 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE, 실패 시 FALSE</p>
<h4 id="classContainer_1ad7b9f7d5eb283748a0d31389b487e396"><code>public inline DTYPE</code><a href="#classContainer_1ad7b9f7d5eb283748a0d31389b487e396"><code>Pop</code></a><code>()</code></h4>
<p>Queue의 pop 메소드</p>
<p>기존의 queue를 할당 해제하고 Queue의 첫번째 Element를 반환한 후 새로운 Queue를 동적으로 할당한다. </p>
<h5>Returns</h5>
<p>Queue의 첫번째 Element</p>
<h4 id="classContainer_1a15c8f4962022d9ad82ffb6c721b672f9"><code>public inline DTYPE</code><a href="#classContainer_1a15c8f4962022d9ad82ffb6c721b672f9"><code>Pop</code></a><code>(DTYPE pElement)</code></h4>
<p>Queue에서 Element를 찾아 반환하는 pop 메소드</p>
<p>매개변수로 받은 Element가 Queue에 존재할 경우, 해당 Element를 반환하고 Queue를 새로 동적으로 할당한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pElement</code> Queue에서 찾고자 하는 Element </li>
</ul>
<h5>Returns</h5>
<p>실패 시 NULL, 성공 시 매개변수로 전달받은 Element와 동일한 Queue의 Element</p>
<h4 id="classContainer_1ab86a61645d5fff30cff8062e7988b770"><code>public inline int</code><a href="#classContainer_1ab86a61645d5fff30cff8062e7988b770"><code>Reverse</code></a><code>()</code></h4>
<p>Queue를 역순으로 재할당해주는 메소드</p>
<p>Queue의 Element를 반대 순서로 저장하는 새로운 Queue를 할당하고, 기존의 Queue를 할당 해제한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classContainer_1a4f113e1ecebcf3a21273aefd26d7bbb5"><code>public inline int</code><a href="#classContainer_1a4f113e1ecebcf3a21273aefd26d7bbb5"><code>SetElement</code></a><code>(DTYPE pElement,unsigned int index)</code></h4>
<h4 id="classContainer_1ac0cc8e4e6056e832c4874635ac871c40"><code>public inline int</code><a href="#classContainer_1ac0cc8e4e6056e832c4874635ac871c40"><code>GetSize</code></a><code>()</code></h4>
<h4 id="classContainer_1ac4fb1b6458674b9876afb4b1fa18c4a9"><code>public inline DTYPE</code><a href="#classContainer_1ac4fb1b6458674b9876afb4b1fa18c4a9"><code>GetLast</code></a><code>()</code></h4>
<h4 id="classContainer_1adbb3e154598ae672e37283a1fb292ba2"><code>public inline DTYPE *</code><a href="#classContainer_1adbb3e154598ae672e37283a1fb292ba2"><code>GetRawData</code></a><code>() const</code></h4>
<h4 id="classContainer_1a127e7b9fa3de03c7f7f866190fd1c585"><code>public inline DTYPE</code><a href="#classContainer_1a127e7b9fa3de03c7f7f866190fd1c585"><code>GetElement</code></a><code>(unsigned int index)</code></h4>
<h4 id="classContainer_1a884d3c64b1d6556018585569d8f00994"><code>public inline DTYPE &amp;</code><a href="#classContainer_1a884d3c64b1d6556018585569d8f00994"><code>operator[]</code></a><code>(unsigned int index)</code></h4>
<p>[]연산자 오버로딩</p>
<p>Queue에서 파라미터로 받은 인덱스에 해당하는 ELement를 반환한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>index</code> 찾고자 하는 Queue의 Element의 인덱스 </li>
</ul>
<h5>Returns</h5>
<p>m_aElement[index]</p>
<hr />
<h2 id="classConvolution2D">class <code>Convolution2D</code><a class="headerlink" href="#classConvolution2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Convolution2D
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classConvolution2D_1a5beb3b40bafb285ae8e3263090750629"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,std::string pName,int pLoadflag)</code></td>
<td>Convolution2D의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classConvolution2D_1abe5ba6af6d5f937406afdcaa38f8f523"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding,std::string pName,int pLoadflag)</code></td>
<td>Convolution2D의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classConvolution2D_1ade843fe630f0761b08c2f9c8cd6700c3"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2,std::string pName,int pLoadflag)</code></td>
<td>Convolution2D의 생성자.</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classConvolution2D_1a594f73f7e54af4986fb38f65f0b47d86"><code>~Convolution2D</code></a><code>()</code></td>
<td>Convolution2D의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2)</code></td>
<td>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2으로 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classConvolution2D_1a138e61e8ddf41736599591d1fcbef660"><code>Delete</code></a><code>()</code></td>
<td>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classConvolution2D_1af6fb380cb816f05f6be1d373a5a38646"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Convolution2D의 ForwardPropagate 메소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classConvolution2D_1ad191ef030ffcbc1c49fc19701bc76ac4"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>CONVOLUTION_2D의 BackPropagate 메소드.</td>
</tr>
<tr>
<td><code>public inline int *</code><a href="#classConvolution2D_1a16d798fd391ebf68199013aa1c95d02c"><code>GetStrideList</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int *</code><a href="#classConvolution2D_1a8f2665a6a9a2ad89ecd60d0119188968"><code>GetPaddingList</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classConvolution2D_1a5beb3b40bafb285ae8e3263090750629"><code>public inline</code><a href="#classConvolution2D_1a5beb3b40bafb285ae8e3263090750629"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,std::string pName,int pLoadflag)</code></h4>
<p>Convolution2D의 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Convolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> Convolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classConvolution2D_1abe5ba6af6d5f937406afdcaa38f8f523"><code>public inline</code><a href="#classConvolution2D_1abe5ba6af6d5f937406afdcaa38f8f523"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding,std::string pName,int pLoadflag)</code></h4>
<p>Convolution2D의 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2, padding로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Convolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> Convolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding</code> padding 할 값. height, width 모두 이 값으로 한다. </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classConvolution2D_1ade843fe630f0761b08c2f9c8cd6700c3"><code>public inline</code><a href="#classConvolution2D_1ade843fe630f0761b08c2f9c8cd6700c3"><code>Convolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2,std::string pName,int pLoadflag)</code></h4>
<p>Convolution2D의 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Convolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> Convolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding1</code> height padding값 </p>
</li>
<li>
<p><code>padding2</code> width padding값 </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classConvolution2D_1a594f73f7e54af4986fb38f65f0b47d86"><code>public inline virtual</code><a href="#classConvolution2D_1a594f73f7e54af4986fb38f65f0b47d86"><code>~Convolution2D</code></a><code>()</code></h4>
<p>Convolution2D의 소멸자.</p>
<p>Delete매소드를 사용해 GPU에 할당했던 값들을 해제한다. void <a href="#classConvolution2D_1a138e61e8ddf41736599591d1fcbef660">Delete()</a></p>
<h4 id="classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af"><code>public inline int</code><a href="#classConvolution2D_1a50def34cf16da197fbbff0f5d51df8af"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2)</code></h4>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2으로 맴버 변수들을 초기화 한다.</p>
<p>pInput과 pWeight의 Shape과 stride, padding값으로 output으로 Result와 Delta로 사용 할 Tensor의 Shape을 정의한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Convolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> Convolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding1</code> height padding값 </p>
</li>
<li>
<p><code>padding2</code> width padding값</p>
</li>
</ul>
<h4 id="classConvolution2D_1a138e61e8ddf41736599591d1fcbef660"><code>public inline void</code><a href="#classConvolution2D_1a138e61e8ddf41736599591d1fcbef660"><code>Delete</code></a><code>()</code></h4>
<p>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</p>
<p>inputTensorDesc, outputTensorDesc,deltaDesc, inputDeltaDesc, convDesc, filterDesc,filterDeltaDesc들을 삭제하고 NULL로 초기화한다.</p>
<p>cudnn연산을 위해 할당 했던 메모리들을 해제시킨다.</p>
<h4 id="classConvolution2D_1af6fb380cb816f05f6be1d373a5a38646"><code>public inline virtual int</code><a href="#classConvolution2D_1af6fb380cb816f05f6be1d373a5a38646"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Convolution2D의 ForwardPropagate 메소드.</p>
<p>weight(filter size = rowsizeOfWeight * colsizeOfWeight)와 input의 곱한 값을 result에 더해 넣는다.</p>
<p>이때 m_stride값들 만큼 이동하며 result를 계산한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classConvolution2D_1ad191ef030ffcbc1c49fc19701bc76ac4"><code>public inline virtual int</code><a href="#classConvolution2D_1ad191ef030ffcbc1c49fc19701bc76ac4"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>CONVOLUTION_2D의 BackPropagate 메소드.</p>
<p>Convolution의 미분 값(weight * this_delta, input * this_delta)을 계산하여 input_delta와 weight_gradient에 각각 더해 넣는다.</p>
<p>이때 m_stride값들 만큼 이동하며 미분 값을 넣을 위치를 계산한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classConvolution2D_1a16d798fd391ebf68199013aa1c95d02c"><code>public inline int *</code><a href="#classConvolution2D_1a16d798fd391ebf68199013aa1c95d02c"><code>GetStrideList</code></a><code>()</code></h4>
<h4 id="classConvolution2D_1a8f2665a6a9a2ad89ecd60d0119188968"><code>public inline int *</code><a href="#classConvolution2D_1a8f2665a6a9a2ad89ecd60d0119188968"><code>GetPaddingList</code></a><code>()</code></h4>
<hr />
<h2 id="classConvolutionLayer2D">class <code>ConvolutionLayer2D</code><a class="headerlink" href="#classConvolutionLayer2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class ConvolutionLayer2D
  : public Module&lt; DTYPE &gt;
</code></pre></div>

<p>구성해 2-Dimensional Convolution Layer의 기능을 수행하는 모듈을 생성하는 클래스</p>
<p>Operator들을 뉴럴 네트워크의 서브 그래프로 구성해 2-Dimensional convolution Layer의 기능을 수행한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classConvolutionLayer2D_1a0a51514f4250ab566ff1a29ede2846c0"><code>ConvolutionLayer2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPadding,int use_bias,std::string pName)</code></td>
<td><a href="#classConvolutionLayer2D">ConvolutionLayer2D</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classConvolutionLayer2D_1a12099a1799e812c7de9341844518e105"><code>~ConvolutionLayer2D</code></a><code>()</code></td>
<td><a href="#classConvolutionLayer2D">ConvolutionLayer2D</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classConvolutionLayer2D_1a6d951dcc0de4424e417ea0eba30d48ba"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPaddingRow,int pPaddingCol,int use_bias,std::string pName)</code></td>
<td>2D convolution Layer 그래프를 동적으로 할당 및 구성하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classConvolutionLayer2D_1a0a51514f4250ab566ff1a29ede2846c0"><code>public inline</code><a href="#classConvolutionLayer2D_1a0a51514f4250ab566ff1a29ede2846c0"><code>ConvolutionLayer2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPadding,int use_bias,std::string pName)</code></h4>
<p><a href="#classConvolutionLayer2D">ConvolutionLayer2D</a> 클래스 생성자</p>
<p>ConvouutionLayer2D 클래스의 Alloc 함수를 호출한다. 
<strong>See also</strong>: Convolution2D<DTYPE>::Alloc(Operator<DTYPE> *pInput, int pNumInputChannel, int pNumOutputChannel, int pNumKernelRow, int pNumKernelCol, int pStrideRow, int pStrideCol, int pPaddingRow, int pPaddingCol, int use_bias, std::string pName)</p>
<h4 id="classConvolutionLayer2D_1a12099a1799e812c7de9341844518e105"><code>public inline virtual</code><a href="#classConvolutionLayer2D_1a12099a1799e812c7de9341844518e105"><code>~ConvolutionLayer2D</code></a><code>()</code></h4>
<p><a href="#classConvolutionLayer2D">ConvolutionLayer2D</a> 클래스 소멸자</p>
<p>단, 동적 할당 받은 Operator들은 NeuralNetwork에서 할당 해제한다.</p>
<h4 id="classConvolutionLayer2D_1a6d951dcc0de4424e417ea0eba30d48ba"><code>public inline int</code><a href="#classConvolutionLayer2D_1a6d951dcc0de4424e417ea0eba30d48ba"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPaddingRow,int pPaddingCol,int use_bias,std::string pName)</code></h4>
<p>2D convolution Layer 그래프를 동적으로 할당 및 구성하는 메소드</p>
<p>Input Operator의 Element에 대해 2D Convolution을 수행한다.</p>
<p>Input Operator의 Element에 대해 Weight를 이용해 2차원 합성 곱(2D Convolution)을 수행하고 Bias가 존재할 시 Bias를 합(Column Wise Addition)해 Output Operator로 내보내는 layer를 구성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 해당 Layer의 Input에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pNumInputChannel</code> 해당 Layer의 Input Operator의 Channel의 갯수, Input Channel에 대한 Dimension </p>
</li>
<li>
<p><code>pNumOutputChannel</code> 해당 Layer의 Output Operator의 Channel의 갯수, Output Channel에 대한 Dimension </p>
</li>
<li>
<p><code>pNumKernelRow</code> 2D Convolution Layer 커널의 Row Size </p>
</li>
<li>
<p><code>pNumKernelCol</code> 2D Convolution Layer 커널의 Column Size </p>
</li>
<li>
<p><code>pStrideRow</code> 2D Convolution Layer의 Row Stride Size </p>
</li>
<li>
<p><code>pStrideCol</code> 2D Convolution Layer의 Column Stride Size </p>
</li>
<li>
<p><code>pPaddingRow</code> 2D Convolution Layer의 Row Padding 값 </p>
</li>
<li>
<p><code>pPaddingCol</code> 2D Convolution Layer의 Column Padding 값 </p>
</li>
<li>
<p><code>use_bias</code> Bias 사용 유무, 0일 시 사용 안 함, 0이 아닐 시 사용 </p>
</li>
<li>
<p><code>pName</code> Module의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: <a href="#classConvolution2D_1a5beb3b40bafb285ae8e3263090750629">Convolution2D<DTYPE>::Convolution2D</a>(<a href="#classOperator">Operator<DTYPE></a> *pInput, <a href="#classOperator">Operator<DTYPE></a> *pWeight, int stride1, int stride2, std::string pName = "NO NAME") AddColWise<DTYPE>::AddColWise(Operator<DTYPE> *pInput, Operator<DTYPE> *pBias, std::string pName) <a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614">Module<DTYPE>::AnalyzeGraph(Operator<DTYPE> *pResultOperator)</a></p>
<hr />
<h2 id="classCrossEntropy">class <code>CrossEntropy</code><a class="headerlink" href="#classCrossEntropy" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class CrossEntropy
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<p>Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</p>
<p>Cross Entropy 계산식을 이용해 뉴럴 네트워크의 순전파를 통해 계산된 출력 Tensor와 레이블 값의 손실 함수를 계산한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classCrossEntropy_1a9a33d1185ee453c393860c3a1552f628"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,int epsilon)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classCrossEntropy_1af539d0934955e572dfa338c911ca213f"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classCrossEntropy_1a23d0632092775d81e85add781638f148"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,int epsilon,std::string pName)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classCrossEntropy_1a20e18d255067837dda38df8ff884df27"><code>~CrossEntropy</code></a><code>()</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,int epsilon)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a> Lossfunction의 멤버 변수들을 동적 할당하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classCrossEntropy_1a4d4f5ad7e88301644ab173ef75b5eee9"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classCrossEntropy_1addeb5ba89138297799b21d118ede3602"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classCrossEntropy_1a9a33d1185ee453c393860c3a1552f628"><code>public inline</code><a href="#classCrossEntropy_1a9a33d1185ee453c393860c3a1552f628"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,int epsilon)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 epsilon을 매개변수로 전달하여 <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>epsilon</code> 더미 변수, 값을 미 지정시 1e-6f로 초기화 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a></p>
<h4 id="classCrossEntropy_1af539d0934955e572dfa338c911ca213f"><code>public inline</code><a href="#classCrossEntropy_1af539d0934955e572dfa338c911ca213f"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 1e-6f에 해당하는 epsilon 값을 매개변수로 전달하여 <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a></p>
<h4 id="classCrossEntropy_1a23d0632092775d81e85add781638f148"><code>public inline</code><a href="#classCrossEntropy_1a23d0632092775d81e85add781638f148"><code>CrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,int epsilon,std::string pName)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 epsilon을 매개변수로 전달하여 <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>epsilon</code> 더미 변수 </p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5">CrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, int epsilon)</a></p>
<h4 id="classCrossEntropy_1a20e18d255067837dda38df8ff884df27"><code>public inline</code><a href="#classCrossEntropy_1a20e18d255067837dda38df8ff884df27"><code>~CrossEntropy</code></a><code>()</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5"><code>public inline virtual int</code><a href="#classCrossEntropy_1a54c779f83f3af7e1f74528289a7614a5"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,int epsilon)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a> Lossfunction의 멤버 변수들을 동적 할당하는 메소드</p>
<p>매개변수로 전달받은 Operator를 Input Operator에 할당하고 초기화 된 Result 텐서를 동적으로 할당 및 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 입력에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>epsilon</code> 더미 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classCrossEntropy_1a4d4f5ad7e88301644ab173ef75b5eee9"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classCrossEntropy_1a4d4f5ad7e88301644ab173ef75b5eee9"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 순전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 결과 값을 레이블 값과 비교해 Cross Entropy를 구한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>뉴럴 네트워크의 결과 값에 대한 Cross Entropy</p>
<h4 id="classCrossEntropy_1addeb5ba89138297799b21d118ede3602"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classCrossEntropy_1addeb5ba89138297799b21d118ede3602"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 역전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 <a href="#classCrossEntropy">CrossEntropy</a> LossFunction에 대한 입력 Tensor의 Gradient를 계산한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classDataLoader">class <code>DataLoader</code><a class="headerlink" href="#classDataLoader" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classDataLoader_1ab068b9fb61b022430a5fd4e357c48b00"><code>DataLoader</code></a><code>(</code><a href="#classDataset"><code>Dataset</code></a><code>&lt; DTYPE &gt; * dataset,int batchSize,int useShuffle,int numOfWorker,int dropLast)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classDataLoader_1a75bed33b2668a7262ed3d6576a6dd9e8"><code>~DataLoader</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataLoader_1ab56c7b34da2522ee04b0880d092193e4"><code>StartProcess</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataLoader_1a2353547121b6b941c92464c1a42c6a3c"><code>StopProcess</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataLoader_1ab5eacdd0affb0529681673d816b94fea"><code>DistributeIdxOfData2Thread</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classDataLoader_1a2dff81a1f0ebe728999458424d15f315"><code>MakeAllOfIndex</code></a><code>(std::vector&lt; int &gt; * pAllOfIndex)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classDataLoader_1a046f99f587d7046763b1df5c30f075e8"><code>DataPreprocess</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataLoader_1a1e59af7e80cd086051f503088952d87d"><code>Push2IdxBuffer</code></a><code>(std::vector&lt; int &gt; * setOfIdx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public std::vector&lt; int &gt; *</code><a href="#classDataLoader_1aab365477975ac3753f058fb936bf2e65"><code>GetIdxSetFromIdxBuffer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classDataLoader_1a66ab19bddbe95dd2ccc2b6b610267c83"><code>Concatenate</code></a><code>(std::queue&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; &amp; setOfData)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataLoader_1a79ec4b21d32eb4a0753ac3ecc1f5b4a2"><code>Push2GlobalBuffer</code></a><code>(std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; * preprocessedData)</code></td>
<td></td>
</tr>
<tr>
<td><code>public std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataLoader_1a283d78594c4007d4ee4dfce688e94ccf"><code>GetDataFromGlobalBuffer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classDataLoader_1ac1127611ca1991c89448b107ac1db10a"><code>GetBatchSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classDataLoader_1a00f4ea62ec8d47d157ff7f0728cf7e80"><code>GetWorkingSignal</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classDataLoader_1a89fffabc92f8592855ab4d32fc6f3b30"><code>GetNumOfEachDatasetMember</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classDataset"><code>Dataset</code></a><code>&lt; DTYPE &gt; *</code><a href="#classDataLoader_1a0880559eeabd33ada6e4ca43af4b0a0f"><code>GetDataset</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classDataLoader_1ab068b9fb61b022430a5fd4e357c48b00"><code>public</code><a href="#classDataLoader_1ab068b9fb61b022430a5fd4e357c48b00"><code>DataLoader</code></a><code>(</code><a href="#classDataset"><code>Dataset</code></a><code>&lt; DTYPE &gt; * dataset,int batchSize,int useShuffle,int numOfWorker,int dropLast)</code></h4>
<h4 id="classDataLoader_1a75bed33b2668a7262ed3d6576a6dd9e8"><code>public virtual</code><a href="#classDataLoader_1a75bed33b2668a7262ed3d6576a6dd9e8"><code>~DataLoader</code></a><code>()</code></h4>
<h4 id="classDataLoader_1ab56c7b34da2522ee04b0880d092193e4"><code>public void</code><a href="#classDataLoader_1ab56c7b34da2522ee04b0880d092193e4"><code>StartProcess</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a2353547121b6b941c92464c1a42c6a3c"><code>public void</code><a href="#classDataLoader_1a2353547121b6b941c92464c1a42c6a3c"><code>StopProcess</code></a><code>()</code></h4>
<h4 id="classDataLoader_1ab5eacdd0affb0529681673d816b94fea"><code>public void</code><a href="#classDataLoader_1ab5eacdd0affb0529681673d816b94fea"><code>DistributeIdxOfData2Thread</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a2dff81a1f0ebe728999458424d15f315"><code>public virtual void</code><a href="#classDataLoader_1a2dff81a1f0ebe728999458424d15f315"><code>MakeAllOfIndex</code></a><code>(std::vector&lt; int &gt; * pAllOfIndex)</code></h4>
<h4 id="classDataLoader_1a046f99f587d7046763b1df5c30f075e8"><code>public virtual void</code><a href="#classDataLoader_1a046f99f587d7046763b1df5c30f075e8"><code>DataPreprocess</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a1e59af7e80cd086051f503088952d87d"><code>public void</code><a href="#classDataLoader_1a1e59af7e80cd086051f503088952d87d"><code>Push2IdxBuffer</code></a><code>(std::vector&lt; int &gt; * setOfIdx)</code></h4>
<h4 id="classDataLoader_1aab365477975ac3753f058fb936bf2e65"><code>public std::vector&lt; int &gt; *</code><a href="#classDataLoader_1aab365477975ac3753f058fb936bf2e65"><code>GetIdxSetFromIdxBuffer</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a66ab19bddbe95dd2ccc2b6b610267c83"><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classDataLoader_1a66ab19bddbe95dd2ccc2b6b610267c83"><code>Concatenate</code></a><code>(std::queue&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; &amp; setOfData)</code></h4>
<h4 id="classDataLoader_1a79ec4b21d32eb4a0753ac3ecc1f5b4a2"><code>public void</code><a href="#classDataLoader_1a79ec4b21d32eb4a0753ac3ecc1f5b4a2"><code>Push2GlobalBuffer</code></a><code>(std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; * preprocessedData)</code></h4>
<h4 id="classDataLoader_1a283d78594c4007d4ee4dfce688e94ccf"><code>public std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataLoader_1a283d78594c4007d4ee4dfce688e94ccf"><code>GetDataFromGlobalBuffer</code></a><code>()</code></h4>
<h4 id="classDataLoader_1ac1127611ca1991c89448b107ac1db10a"><code>public inline int</code><a href="#classDataLoader_1ac1127611ca1991c89448b107ac1db10a"><code>GetBatchSize</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a00f4ea62ec8d47d157ff7f0728cf7e80"><code>public inline int</code><a href="#classDataLoader_1a00f4ea62ec8d47d157ff7f0728cf7e80"><code>GetWorkingSignal</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a89fffabc92f8592855ab4d32fc6f3b30"><code>public inline int</code><a href="#classDataLoader_1a89fffabc92f8592855ab4d32fc6f3b30"><code>GetNumOfEachDatasetMember</code></a><code>()</code></h4>
<h4 id="classDataLoader_1a0880559eeabd33ada6e4ca43af4b0a0f"><code>public inline</code><a href="#classDataset"><code>Dataset</code></a><code>&lt; DTYPE &gt; *</code><a href="#classDataLoader_1a0880559eeabd33ada6e4ca43af4b0a0f"><code>GetDataset</code></a><code>()</code></h4>
<hr />
<h2 id="classDataset">class <code>Dataset</code><a class="headerlink" href="#classDataset" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classDataset_1a117a5cf499442026ec65539e86d323b8"><code>Dataset</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classDataset_1ab4ca1cb7864616d827a224972852dc02"><code>~Dataset</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classDataset_1ad83a7518034d146d0ffffcdff5456fb8"><code>Alloc</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classDataset_1a94111198dbd5b5ba10c4aea5669b98a4"><code>Dealloc</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1add9bbd1292520996a0d53661e9fe2274"><code>GetData</code></a><code>(int idx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1af63feeb777bbfd323364d8728eb5bd94"><code>GetDataOfPositiveLabel</code></a><code>(int anchorIdx,int * pPosIdx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1afd3328c1f081932195e8470ec3942b72"><code>GetDataOfNegativeLabel</code></a><code>(int anchorIdx,int * pNegIdx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataset_1a00dda88a3e668d0c09047053e9521e6c"><code>SetLabel</code></a><code>(const int * pLabel,int noLabel)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classDataset_1a75923ba054ba36b97c91aaed509b3be9"><code>SetLabel</code></a><code>(const unsigned char * pLabel,int noLabel)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDataset_1a7a80be63f47b9e7f6251f07b2e06b842"><code>GetLabel</code></a><code>(int idx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDataset_1afde2f4837773a5cf14a2088a7337d1d5"><code>GetLength</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classDataset_1a0ed8c212dde5a144aa47d1fe15efa9e0"><code>GetNumOfDatasetMember</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classDataset_1adf6ba25290bc6e809c41c6f01292ce44"><code>CopyData</code></a><code>(int idx,DTYPE * pDest)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classDataset_1a0a23ae14b56a165779ef50163ed55387"><code>SetPosNegIndices</code></a><code>(std::vector&lt; int &gt; * pvPosIndex,std::vector&lt; int &gt; * pvNegIndex)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline std::vector&lt; int &gt; &amp;</code><a href="#classDataset_1a5b4fee175817ab07ac6fbe9c3b41d079"><code>GetPositiveIndices</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline std::vector&lt; int &gt; &amp;</code><a href="#classDataset_1a41c487f8ec2b455e389f99f25d78ea9c"><code>GetNegativeIndices</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDataset_1ac15d95710ec3ad2fcb29137d53041da4"><code>GetPositiveIndex</code></a><code>(int idx)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDataset_1a2163594d7e797e4188e251157e6f01c5"><code>GetNegativeIndex</code></a><code>(int idx)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classDataset_1a117a5cf499442026ec65539e86d323b8"><code>public</code><a href="#classDataset_1a117a5cf499442026ec65539e86d323b8"><code>Dataset</code></a><code>()</code></h4>
<h4 id="classDataset_1ab4ca1cb7864616d827a224972852dc02"><code>public virtual</code><a href="#classDataset_1ab4ca1cb7864616d827a224972852dc02"><code>~Dataset</code></a><code>()</code></h4>
<h4 id="classDataset_1ad83a7518034d146d0ffffcdff5456fb8"><code>public virtual void</code><a href="#classDataset_1ad83a7518034d146d0ffffcdff5456fb8"><code>Alloc</code></a><code>()</code></h4>
<h4 id="classDataset_1a94111198dbd5b5ba10c4aea5669b98a4"><code>public virtual void</code><a href="#classDataset_1a94111198dbd5b5ba10c4aea5669b98a4"><code>Dealloc</code></a><code>()</code></h4>
<h4 id="classDataset_1add9bbd1292520996a0d53661e9fe2274"><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1add9bbd1292520996a0d53661e9fe2274"><code>GetData</code></a><code>(int idx)</code></h4>
<h4 id="classDataset_1af63feeb777bbfd323364d8728eb5bd94"><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1af63feeb777bbfd323364d8728eb5bd94"><code>GetDataOfPositiveLabel</code></a><code>(int anchorIdx,int * pPosIdx)</code></h4>
<h4 id="classDataset_1afd3328c1f081932195e8470ec3942b72"><code>public virtual std::vector&lt;</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classDataset_1afd3328c1f081932195e8470ec3942b72"><code>GetDataOfNegativeLabel</code></a><code>(int anchorIdx,int * pNegIdx)</code></h4>
<h4 id="classDataset_1a00dda88a3e668d0c09047053e9521e6c"><code>public void</code><a href="#classDataset_1a00dda88a3e668d0c09047053e9521e6c"><code>SetLabel</code></a><code>(const int * pLabel,int noLabel)</code></h4>
<h4 id="classDataset_1a75923ba054ba36b97c91aaed509b3be9"><code>public void</code><a href="#classDataset_1a75923ba054ba36b97c91aaed509b3be9"><code>SetLabel</code></a><code>(const unsigned char * pLabel,int noLabel)</code></h4>
<h4 id="classDataset_1a7a80be63f47b9e7f6251f07b2e06b842"><code>public inline virtual int</code><a href="#classDataset_1a7a80be63f47b9e7f6251f07b2e06b842"><code>GetLabel</code></a><code>(int idx)</code></h4>
<h4 id="classDataset_1afde2f4837773a5cf14a2088a7337d1d5"><code>public inline virtual int</code><a href="#classDataset_1afde2f4837773a5cf14a2088a7337d1d5"><code>GetLength</code></a><code>()</code></h4>
<h4 id="classDataset_1a0ed8c212dde5a144aa47d1fe15efa9e0"><code>public int</code><a href="#classDataset_1a0ed8c212dde5a144aa47d1fe15efa9e0"><code>GetNumOfDatasetMember</code></a><code>()</code></h4>
<h4 id="classDataset_1adf6ba25290bc6e809c41c6f01292ce44"><code>public inline virtual void</code><a href="#classDataset_1adf6ba25290bc6e809c41c6f01292ce44"><code>CopyData</code></a><code>(int idx,DTYPE * pDest)</code></h4>
<h4 id="classDataset_1a0a23ae14b56a165779ef50163ed55387"><code>public inline virtual void</code><a href="#classDataset_1a0a23ae14b56a165779ef50163ed55387"><code>SetPosNegIndices</code></a><code>(std::vector&lt; int &gt; * pvPosIndex,std::vector&lt; int &gt; * pvNegIndex)</code></h4>
<h4 id="classDataset_1a5b4fee175817ab07ac6fbe9c3b41d079"><code>public inline std::vector&lt; int &gt; &amp;</code><a href="#classDataset_1a5b4fee175817ab07ac6fbe9c3b41d079"><code>GetPositiveIndices</code></a><code>()</code></h4>
<h4 id="classDataset_1a41c487f8ec2b455e389f99f25d78ea9c"><code>public inline std::vector&lt; int &gt; &amp;</code><a href="#classDataset_1a41c487f8ec2b455e389f99f25d78ea9c"><code>GetNegativeIndices</code></a><code>()</code></h4>
<h4 id="classDataset_1ac15d95710ec3ad2fcb29137d53041da4"><code>public inline virtual int</code><a href="#classDataset_1ac15d95710ec3ad2fcb29137d53041da4"><code>GetPositiveIndex</code></a><code>(int idx)</code></h4>
<h4 id="classDataset_1a2163594d7e797e4188e251157e6f01c5"><code>public inline virtual int</code><a href="#classDataset_1a2163594d7e797e4188e251157e6f01c5"><code>GetNegativeIndex</code></a><code>(int idx)</code></h4>
<hr />
<h2 id="classDropout">class <code>Dropout</code><a class="headerlink" href="#classDropout" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Dropout
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classDropout_1acb7090ba8045011c8c5175e83fcdeb30"><code>Dropout</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classDropout_1abd51138fedaeb265c1584d0ea14a7cba"><code>Dropout</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float pDroprate,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classDropout_1afad2e18e52d939e6763e020b6d07ead2"><code>~Dropout</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classDropout_1a5c30a5d6b102a293aca2085dce7cc55b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float pDroprate,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classDropout_1adc02e8a3518aa6950eb6d9b86499ce5b"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDropout_1ad9a0170b88f230007ecc496a12de3f84"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classDropout_1ad501c062c1975206e8854f22881ddf14"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classDropout_1acb7090ba8045011c8c5175e83fcdeb30"><code>public inline</code><a href="#classDropout_1acb7090ba8045011c8c5175e83fcdeb30"><code>Dropout</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<h4 id="classDropout_1abd51138fedaeb265c1584d0ea14a7cba"><code>public inline</code><a href="#classDropout_1abd51138fedaeb265c1584d0ea14a7cba"><code>Dropout</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float pDroprate,std::string pName,int pLoadflag)</code></h4>
<h4 id="classDropout_1afad2e18e52d939e6763e020b6d07ead2"><code>public inline</code><a href="#classDropout_1afad2e18e52d939e6763e020b6d07ead2"><code>~Dropout</code></a><code>()</code></h4>
<h4 id="classDropout_1a5c30a5d6b102a293aca2085dce7cc55b"><code>public inline int</code><a href="#classDropout_1a5c30a5d6b102a293aca2085dce7cc55b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float pDroprate,int pLoadflag)</code></h4>
<h4 id="classDropout_1adc02e8a3518aa6950eb6d9b86499ce5b"><code>public inline void</code><a href="#classDropout_1adc02e8a3518aa6950eb6d9b86499ce5b"><code>Delete</code></a><code>()</code></h4>
<h4 id="classDropout_1ad9a0170b88f230007ecc496a12de3f84"><code>public inline virtual int</code><a href="#classDropout_1ad9a0170b88f230007ecc496a12de3f84"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classDropout_1ad501c062c1975206e8854f22881ddf14"><code>public inline virtual int</code><a href="#classDropout_1ad501c062c1975206e8854f22881ddf14"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classFewShotClassifier">class <code>FewShotClassifier</code><a class="headerlink" href="#classFewShotClassifier" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classFewShotClassifier_1afd4cd751b6242a6c83315d1213d04831"><code>FewShotClassifier</code></a><code>(int inputDim,int featureDim,const std::vector&lt; std::string &gt; vClassName,</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; float &gt; * pNN,int noRef,int * pRefLabel,float * pRefSample,int batchSize)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classFewShotClassifier_1a5e1cf99445c4675a49a7e4fa53d7d699"><code>FewShotClassifier</code></a><code>(int inputDim,int featureDim,const std::vector&lt; std::string &gt; vClassName,</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; float &gt; * pNN,</code><a href="#classKNearestNeighbor"><code>KNearestNeighbor</code></a><code>* kNN)</code></td>
<td></td>
</tr>
<tr>
<td><code>public std::string</code><a href="#classFewShotClassifier_1a27fd015fe4d3231caaf67e26c774423a"><code>Recognize</code></a><code>(float * pInputSample,int k)</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classFewShotClassifier_1aeff452a2a72d74fb557a41f7e1f8ed28"><code>GetAccuracy</code></a><code>(int noTestSample,float * pTestSample,int * pLabel)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classFewShotClassifier_1ad7cbd965fb4147a540b5bb18febba51f"><code>AddReference</code></a><code>(const char * className,float * pRefSample)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classFewShotClassifier_1acfd408b46029fa1a3815ed7d49e40e6d"><code>FindClass</code></a><code>(const char * className)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classFewShotClassifier_1afd4cd751b6242a6c83315d1213d04831"><code>public</code><a href="#classFewShotClassifier_1afd4cd751b6242a6c83315d1213d04831"><code>FewShotClassifier</code></a><code>(int inputDim,int featureDim,const std::vector&lt; std::string &gt; vClassName,</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; float &gt; * pNN,int noRef,int * pRefLabel,float * pRefSample,int batchSize)</code></h4>
<h4 id="classFewShotClassifier_1a5e1cf99445c4675a49a7e4fa53d7d699"><code>public</code><a href="#classFewShotClassifier_1a5e1cf99445c4675a49a7e4fa53d7d699"><code>FewShotClassifier</code></a><code>(int inputDim,int featureDim,const std::vector&lt; std::string &gt; vClassName,</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; float &gt; * pNN,</code><a href="#classKNearestNeighbor"><code>KNearestNeighbor</code></a><code>* kNN)</code></h4>
<h4 id="classFewShotClassifier_1a27fd015fe4d3231caaf67e26c774423a"><code>public std::string</code><a href="#classFewShotClassifier_1a27fd015fe4d3231caaf67e26c774423a"><code>Recognize</code></a><code>(float * pInputSample,int k)</code></h4>
<h4 id="classFewShotClassifier_1aeff452a2a72d74fb557a41f7e1f8ed28"><code>public float</code><a href="#classFewShotClassifier_1aeff452a2a72d74fb557a41f7e1f8ed28"><code>GetAccuracy</code></a><code>(int noTestSample,float * pTestSample,int * pLabel)</code></h4>
<h4 id="classFewShotClassifier_1ad7cbd965fb4147a540b5bb18febba51f"><code>public void</code><a href="#classFewShotClassifier_1ad7cbd965fb4147a540b5bb18febba51f"><code>AddReference</code></a><code>(const char * className,float * pRefSample)</code></h4>
<h4 id="classFewShotClassifier_1acfd408b46029fa1a3815ed7d49e40e6d"><code>public int</code><a href="#classFewShotClassifier_1acfd408b46029fa1a3815ed7d49e40e6d"><code>FindClass</code></a><code>(const char * className)</code></h4>
<hr />
<h2 id="classGAN">class <code>GAN</code><a class="headerlink" href="#classGAN" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class GAN
  : public NeuralNetwork&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classGAN_1a485a7890354d931d2f727384ee8060b5"><code>GAN</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classGAN_1aa674ca6ad1fe8645591604d00e58f5b4"><code>~GAN</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a5ced95eb64ce34d1e99b5cd2e184cf65"><code>AllocLabel</code></a><code>(float plabelValue)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a5590e634d5d8d33283e85b413624b098"><code>SetGenerator</code></a><code>(</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; * pGen)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a198740b018110795a33f089709314375"><code>SetDiscriminator</code></a><code>(</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a8fcc2c8654b1498fc48b6089ad0a5696"><code>SetLabel</code></a><code>(</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; * pLabel)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1aff8a0cd54c63493358af350961463508"><code>SetSwitch</code></a><code>(</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; * pSwitch)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classGAN_1a6eaf5392784f585c644d5d575fa17a88"><code>SetGANLossFunctions</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pGenLoss,</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1ace1f80bbd25e498ad1911ecc671575ca"><code>SetGeneratorLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pGenLoss)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1ac20136c40e6ca3d8ce640f180a2441f4"><code>SetDiscriminatorLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classGAN_1ae7f2b5c594fc3007a33b1d7147e52dd1"><code>SetGANOptimizers</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pGenOpt,</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pDiscOpt)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a8dafa4e173ed888890075b78dac86e17"><code>SetGeneratorOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pGenOpt)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a73ba54c2e5013968c7bd0ac371c4e811"><code>SetDiscriminatorOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pDiscOpt)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a6148b66565f745bbcbc338d09d6a388a"><code>GetGenerator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a44a2ead7ceb083fe3d5d53e6636d0c05"><code>GetDiscriminator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a26458184b7d1b3689c4e17340f3e07f9"><code>GetLabel</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1af70967bb4f3c2b44b55792989207e45b"><code>GetSwitch</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a3e47203aa534111947de22551b273594"><code>GetGeneratorLossFunction</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a055ebf9b70adc7c523e8bb2cae1b9eb7"><code>GetDiscriminatorLossFunction</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a7cff900e1cd5c3e71a5ba4334a18c339"><code>GetGeneratorOptimizer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a6c9800fcc6750f705cba67d9f231725c"><code>GetDiscriminatorOptimizer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a28df20395095ad5004b6c22ec68c54d1"><code>TrainGenerator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a632348aaf9b03bed27eb83d754910a67"><code>TrainDiscriminator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1aab6f7efa0aad6be17bbe1e2f4aba3c8b"><code>Generate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1a5ad0a83d17e35d5b76b9b7bf360338db"><code>TrainGeneratorOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1a1f1f8f8070e7b50534fb77f0802829dc"><code>TrainDiscriminatorOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1af04453ffb96138c654d6cf408e389061"><code>ComputeGradientOfDiscriminatorAboutRealOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1a5c99dea104a9a1287267d6292b09b293"><code>ComputeGradientOfDiscriminatorAboutFakeOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a928c6f99e06d061e29a2640f6fd9829b"><code>GenerateOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1a9ddd1d82f0466c2cd523585d12848721"><code>TrainGeneratorOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1aa7cb8914285ebe663d48a7b3be1acefc"><code>TrainDiscriminatorOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1acf9d6cbad00941f035f97860664359d7"><code>ComputeGradientOfDiscriminatorAboutRealOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classGAN_1a12205964f1bcf665fcdcc3ce325829f2"><code>ComputeGradientOfDiscriminatorAboutFakeOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1ab4c605b6b642843d63c3a754a99d5456"><code>GenerateOnGPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a6fbb3bef953a3ed847093e96ca73a1b8"><code>ResetParameterGradient</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1ae88e2a427b7bc8c29318545e73749c93"><code>ResetGeneratorLossFunctionResult</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a0de84743bff6ee5885e9d73a7fde5890"><code>ResetGeneratorLossFunctionGradient</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a86bce2e2539bed246eab6f96a6d3d940"><code>ResetDiscriminatorLossFunctionResult</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classGAN_1a803492a2eec163d90a55cb98d5daaccb"><code>ResetDiscriminatorLossFunctionGradient</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classGAN_1a2991d95a56c002de500944a8a52f57c0"><code>Clip</code></a><code>(float min,float max)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classGAN_1a485a7890354d931d2f727384ee8060b5"><code>public</code><a href="#classGAN_1a485a7890354d931d2f727384ee8060b5"><code>GAN</code></a><code>()</code></h4>
<h4 id="classGAN_1aa674ca6ad1fe8645591604d00e58f5b4"><code>public virtual</code><a href="#classGAN_1aa674ca6ad1fe8645591604d00e58f5b4"><code>~GAN</code></a><code>()</code></h4>
<h4 id="classGAN_1a5ced95eb64ce34d1e99b5cd2e184cf65"><code>public int</code><a href="#classGAN_1a5ced95eb64ce34d1e99b5cd2e184cf65"><code>AllocLabel</code></a><code>(float plabelValue)</code></h4>
<h4 id="classGAN_1a5590e634d5d8d33283e85b413624b098"><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a5590e634d5d8d33283e85b413624b098"><code>SetGenerator</code></a><code>(</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; * pGen)</code></h4>
<h4 id="classGAN_1a198740b018110795a33f089709314375"><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a198740b018110795a33f089709314375"><code>SetDiscriminator</code></a><code>(</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></h4>
<h4 id="classGAN_1a8fcc2c8654b1498fc48b6089ad0a5696"><code>public</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a8fcc2c8654b1498fc48b6089ad0a5696"><code>SetLabel</code></a><code>(</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; * pLabel)</code></h4>
<h4 id="classGAN_1aff8a0cd54c63493358af350961463508"><code>public</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1aff8a0cd54c63493358af350961463508"><code>SetSwitch</code></a><code>(</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; * pSwitch)</code></h4>
<h4 id="classGAN_1a6eaf5392784f585c644d5d575fa17a88"><code>public void</code><a href="#classGAN_1a6eaf5392784f585c644d5d575fa17a88"><code>SetGANLossFunctions</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pGenLoss,</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></h4>
<h4 id="classGAN_1ace1f80bbd25e498ad1911ecc671575ca"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1ace1f80bbd25e498ad1911ecc671575ca"><code>SetGeneratorLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pGenLoss)</code></h4>
<h4 id="classGAN_1ac20136c40e6ca3d8ce640f180a2441f4"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1ac20136c40e6ca3d8ce640f180a2441f4"><code>SetDiscriminatorLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pDiscLoss)</code></h4>
<h4 id="classGAN_1ae7f2b5c594fc3007a33b1d7147e52dd1"><code>public void</code><a href="#classGAN_1ae7f2b5c594fc3007a33b1d7147e52dd1"><code>SetGANOptimizers</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pGenOpt,</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pDiscOpt)</code></h4>
<h4 id="classGAN_1a8dafa4e173ed888890075b78dac86e17"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a8dafa4e173ed888890075b78dac86e17"><code>SetGeneratorOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pGenOpt)</code></h4>
<h4 id="classGAN_1a73ba54c2e5013968c7bd0ac371c4e811"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a73ba54c2e5013968c7bd0ac371c4e811"><code>SetDiscriminatorOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pDiscOpt)</code></h4>
<h4 id="classGAN_1a6148b66565f745bbcbc338d09d6a388a"><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a6148b66565f745bbcbc338d09d6a388a"><code>GetGenerator</code></a><code>()</code></h4>
<h4 id="classGAN_1a44a2ead7ceb083fe3d5d53e6636d0c05"><code>public</code><a href="#classNeuralNetwork"><code>NeuralNetwork</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a44a2ead7ceb083fe3d5d53e6636d0c05"><code>GetDiscriminator</code></a><code>()</code></h4>
<h4 id="classGAN_1a26458184b7d1b3689c4e17340f3e07f9"><code>public</code><a href="#classTensorholder"><code>Tensorholder</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a26458184b7d1b3689c4e17340f3e07f9"><code>GetLabel</code></a><code>()</code></h4>
<h4 id="classGAN_1af70967bb4f3c2b44b55792989207e45b"><code>public</code><a href="#classSwitch"><code>Switch</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1af70967bb4f3c2b44b55792989207e45b"><code>GetSwitch</code></a><code>()</code></h4>
<h4 id="classGAN_1a3e47203aa534111947de22551b273594"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a3e47203aa534111947de22551b273594"><code>GetGeneratorLossFunction</code></a><code>()</code></h4>
<h4 id="classGAN_1a055ebf9b70adc7c523e8bb2cae1b9eb7"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a055ebf9b70adc7c523e8bb2cae1b9eb7"><code>GetDiscriminatorLossFunction</code></a><code>()</code></h4>
<h4 id="classGAN_1a7cff900e1cd5c3e71a5ba4334a18c339"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a7cff900e1cd5c3e71a5ba4334a18c339"><code>GetGeneratorOptimizer</code></a><code>()</code></h4>
<h4 id="classGAN_1a6c9800fcc6750f705cba67d9f231725c"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGAN_1a6c9800fcc6750f705cba67d9f231725c"><code>GetDiscriminatorOptimizer</code></a><code>()</code></h4>
<h4 id="classGAN_1a28df20395095ad5004b6c22ec68c54d1"><code>public int</code><a href="#classGAN_1a28df20395095ad5004b6c22ec68c54d1"><code>TrainGenerator</code></a><code>()</code></h4>
<h4 id="classGAN_1a632348aaf9b03bed27eb83d754910a67"><code>public int</code><a href="#classGAN_1a632348aaf9b03bed27eb83d754910a67"><code>TrainDiscriminator</code></a><code>()</code></h4>
<h4 id="classGAN_1aab6f7efa0aad6be17bbe1e2f4aba3c8b"><code>public int</code><a href="#classGAN_1aab6f7efa0aad6be17bbe1e2f4aba3c8b"><code>Generate</code></a><code>()</code></h4>
<h4 id="classGAN_1a5ad0a83d17e35d5b76b9b7bf360338db"><code>public virtual int</code><a href="#classGAN_1a5ad0a83d17e35d5b76b9b7bf360338db"><code>TrainGeneratorOnCPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a1f1f8f8070e7b50534fb77f0802829dc"><code>public virtual int</code><a href="#classGAN_1a1f1f8f8070e7b50534fb77f0802829dc"><code>TrainDiscriminatorOnCPU</code></a><code>()</code></h4>
<h4 id="classGAN_1af04453ffb96138c654d6cf408e389061"><code>public virtual int</code><a href="#classGAN_1af04453ffb96138c654d6cf408e389061"><code>ComputeGradientOfDiscriminatorAboutRealOnCPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a5c99dea104a9a1287267d6292b09b293"><code>public virtual int</code><a href="#classGAN_1a5c99dea104a9a1287267d6292b09b293"><code>ComputeGradientOfDiscriminatorAboutFakeOnCPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a928c6f99e06d061e29a2640f6fd9829b"><code>public int</code><a href="#classGAN_1a928c6f99e06d061e29a2640f6fd9829b"><code>GenerateOnCPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a9ddd1d82f0466c2cd523585d12848721"><code>public virtual int</code><a href="#classGAN_1a9ddd1d82f0466c2cd523585d12848721"><code>TrainGeneratorOnGPU</code></a><code>()</code></h4>
<h4 id="classGAN_1aa7cb8914285ebe663d48a7b3be1acefc"><code>public virtual int</code><a href="#classGAN_1aa7cb8914285ebe663d48a7b3be1acefc"><code>TrainDiscriminatorOnGPU</code></a><code>()</code></h4>
<h4 id="classGAN_1acf9d6cbad00941f035f97860664359d7"><code>public virtual int</code><a href="#classGAN_1acf9d6cbad00941f035f97860664359d7"><code>ComputeGradientOfDiscriminatorAboutRealOnGPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a12205964f1bcf665fcdcc3ce325829f2"><code>public virtual int</code><a href="#classGAN_1a12205964f1bcf665fcdcc3ce325829f2"><code>ComputeGradientOfDiscriminatorAboutFakeOnGPU</code></a><code>()</code></h4>
<h4 id="classGAN_1ab4c605b6b642843d63c3a754a99d5456"><code>public int</code><a href="#classGAN_1ab4c605b6b642843d63c3a754a99d5456"><code>GenerateOnGPU</code></a><code>()</code></h4>
<h4 id="classGAN_1a6fbb3bef953a3ed847093e96ca73a1b8"><code>public int</code><a href="#classGAN_1a6fbb3bef953a3ed847093e96ca73a1b8"><code>ResetParameterGradient</code></a><code>()</code></h4>
<h4 id="classGAN_1ae88e2a427b7bc8c29318545e73749c93"><code>public int</code><a href="#classGAN_1ae88e2a427b7bc8c29318545e73749c93"><code>ResetGeneratorLossFunctionResult</code></a><code>()</code></h4>
<h4 id="classGAN_1a0de84743bff6ee5885e9d73a7fde5890"><code>public int</code><a href="#classGAN_1a0de84743bff6ee5885e9d73a7fde5890"><code>ResetGeneratorLossFunctionGradient</code></a><code>()</code></h4>
<h4 id="classGAN_1a86bce2e2539bed246eab6f96a6d3d940"><code>public int</code><a href="#classGAN_1a86bce2e2539bed246eab6f96a6d3d940"><code>ResetDiscriminatorLossFunctionResult</code></a><code>()</code></h4>
<h4 id="classGAN_1a803492a2eec163d90a55cb98d5daaccb"><code>public int</code><a href="#classGAN_1a803492a2eec163d90a55cb98d5daaccb"><code>ResetDiscriminatorLossFunctionGradient</code></a><code>()</code></h4>
<h4 id="classGAN_1a2991d95a56c002de500944a8a52f57c0"><code>public void</code><a href="#classGAN_1a2991d95a56c002de500944a8a52f57c0"><code>Clip</code></a><code>(float min,float max)</code></h4>
<hr />
<h2 id="classGaussianNoiseGenerator">class <code>GaussianNoiseGenerator</code><a class="headerlink" href="#classGaussianNoiseGenerator" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class GaussianNoiseGenerator
  : public NoiseGenerator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac5b197b17864d63111ede68afc20bfca"><code>GaussianNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float mean,float stddev,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac526f687dfa847d0c9b8ac17a457f3b7"><code>GaussianNoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,float mean,float stddev,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac7387087fc9be62988c7a3d972a62643"><code>GaussianNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float mean,float stddev,float pTrunc,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGaussianNoiseGenerator_1a0d4f06510cdba07c74cd1cec48229c14"><code>GaussianNoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,float mean,float stddev,float pTrunc,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGaussianNoiseGenerator_1a8d8787c2fa17c5b4b5a495a9490cd2cf"><code>~GaussianNoiseGenerator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classGaussianNoiseGenerator_1ab22477bf3d686066759dc98d0f449e34"><code>StartProduce</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classGaussianNoiseGenerator_1ad1419cb933b92e8ad1faca250c54284d"><code>StopProduce</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGaussianNoiseGenerator_1a06b812ccb68081bb4d0c9e6912ebdc17"><code>GenerateNoise</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGaussianNoiseGenerator_1ac72a2a61640a48ae92d5828297d697d0"><code>AddNoise2Buffer</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * noise)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGaussianNoiseGenerator_1a774f3131654d374ce5dd158d6db468fa"><code>GetNoiseFromBuffer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGaussianNoiseGenerator_1a03d74cffd843533fbfc230e0d9d912fe"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGaussianNoiseGenerator_1aeaddb74aeb0ccd9bbd24c0fd04570dab"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classGaussianNoiseGenerator_1ac5b197b17864d63111ede68afc20bfca"><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac5b197b17864d63111ede68afc20bfca"><code>GaussianNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float mean,float stddev,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></h4>
<h4 id="classGaussianNoiseGenerator_1ac526f687dfa847d0c9b8ac17a457f3b7"><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac526f687dfa847d0c9b8ac17a457f3b7"><code>GaussianNoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,float mean,float stddev,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></h4>
<h4 id="classGaussianNoiseGenerator_1ac7387087fc9be62988c7a3d972a62643"><code>public inline</code><a href="#classGaussianNoiseGenerator_1ac7387087fc9be62988c7a3d972a62643"><code>GaussianNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float mean,float stddev,float pTrunc,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></h4>
<h4 id="classGaussianNoiseGenerator_1a0d4f06510cdba07c74cd1cec48229c14"><code>public inline</code><a href="#classGaussianNoiseGenerator_1a0d4f06510cdba07c74cd1cec48229c14"><code>GaussianNoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,float mean,float stddev,float pTrunc,IsTruncated pTruncated,IsUseTime pAnswer,std::string pName)</code></h4>
<h4 id="classGaussianNoiseGenerator_1a8d8787c2fa17c5b4b5a495a9490cd2cf"><code>public inline</code><a href="#classGaussianNoiseGenerator_1a8d8787c2fa17c5b4b5a495a9490cd2cf"><code>~GaussianNoiseGenerator</code></a><code>()</code></h4>
<h4 id="classGaussianNoiseGenerator_1ab22477bf3d686066759dc98d0f449e34"><code>public inline void</code><a href="#classGaussianNoiseGenerator_1ab22477bf3d686066759dc98d0f449e34"><code>StartProduce</code></a><code>()</code></h4>
<h4 id="classGaussianNoiseGenerator_1ad1419cb933b92e8ad1faca250c54284d"><code>public inline void</code><a href="#classGaussianNoiseGenerator_1ad1419cb933b92e8ad1faca250c54284d"><code>StopProduce</code></a><code>()</code></h4>
<h4 id="classGaussianNoiseGenerator_1a06b812ccb68081bb4d0c9e6912ebdc17"><code>public inline int</code><a href="#classGaussianNoiseGenerator_1a06b812ccb68081bb4d0c9e6912ebdc17"><code>GenerateNoise</code></a><code>()</code></h4>
<h4 id="classGaussianNoiseGenerator_1ac72a2a61640a48ae92d5828297d697d0"><code>public inline int</code><a href="#classGaussianNoiseGenerator_1ac72a2a61640a48ae92d5828297d697d0"><code>AddNoise2Buffer</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * noise)</code></h4>
<h4 id="classGaussianNoiseGenerator_1a774f3131654d374ce5dd158d6db468fa"><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classGaussianNoiseGenerator_1a774f3131654d374ce5dd158d6db468fa"><code>GetNoiseFromBuffer</code></a><code>()</code></h4>
<h4 id="classGaussianNoiseGenerator_1a03d74cffd843533fbfc230e0d9d912fe"><code>public inline virtual int</code><a href="#classGaussianNoiseGenerator_1a03d74cffd843533fbfc230e0d9d912fe"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classGaussianNoiseGenerator_1aeaddb74aeb0ccd9bbd24c0fd04570dab"><code>public inline virtual int</code><a href="#classGaussianNoiseGenerator_1aeaddb74aeb0ccd9bbd24c0fd04570dab"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classGlobalAvaragePooling2D">class <code>GlobalAvaragePooling2D</code><a class="headerlink" href="#classGlobalAvaragePooling2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class GlobalAvaragePooling2D
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p>Row * Colunm 공간을 GlobalAvaragePooling하는 클래스.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classGlobalAvaragePooling2D_1a9e1592091dd62880912d9d258c7363ad"><code>GlobalAvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td>GlobalAvaragePooling2D의 생성자.</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classGlobalAvaragePooling2D_1aeec236ca89e621890df159b51b19e90b"><code>~GlobalAvaragePooling2D</code></a><code>()</code></td>
<td>GlobalAvaragePooling2D의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGlobalAvaragePooling2D_1a263d8a716c132862970c1b0b081139ae"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGlobalAvaragePooling2D_1ae506cb847b78140a1ee89812992aca97"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>GlobalAvaragePooling2D의 ForwardPropagate 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGlobalAvaragePooling2D_1aa80e1155774c758544558dcc91a260a9"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>GlobalAvaragePooling2D의 BackPropagate 매소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classGlobalAvaragePooling2D_1a9e1592091dd62880912d9d258c7363ad"><code>public inline</code><a href="#classGlobalAvaragePooling2D_1a9e1592091dd62880912d9d258c7363ad"><code>GlobalAvaragePooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<p>GlobalAvaragePooling2D의 생성자.</p>
<p>파라미터로 받은 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> GlobalAvaragePooling2D할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classGlobalAvaragePooling2D_1a263d8a716c132862970c1b0b081139ae">Alloc(Operator<DTYPE> *pInput)</a>.</p>
</li>
</ul>
<h4 id="classGlobalAvaragePooling2D_1aeec236ca89e621890df159b51b19e90b"><code>public inline virtual</code><a href="#classGlobalAvaragePooling2D_1aeec236ca89e621890df159b51b19e90b"><code>~GlobalAvaragePooling2D</code></a><code>()</code></h4>
<p>GlobalAvaragePooling2D의 소멸자.</p>
<h4 id="classGlobalAvaragePooling2D_1a263d8a716c132862970c1b0b081139ae"><code>public inline int</code><a href="#classGlobalAvaragePooling2D_1a263d8a716c132862970c1b0b081139ae"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<p>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classGlobalAvaragePooling2D_1ae506cb847b78140a1ee89812992aca97"><code>public inline virtual int</code><a href="#classGlobalAvaragePooling2D_1ae506cb847b78140a1ee89812992aca97"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>GlobalAvaragePooling2D의 ForwardPropagate 매소드</p>
<p>input의 row, col상의 값들들 모두 더하고 m_divisor로 나눈 값을 result Tensor에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classGlobalAvaragePooling2D_1aa80e1155774c758544558dcc91a260a9"><code>public inline virtual int</code><a href="#classGlobalAvaragePooling2D_1aa80e1155774c758544558dcc91a260a9"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>GlobalAvaragePooling2D의 BackPropagate 매소드</p>
<p>Input_grad에 계산한 Gradient / m_divisor 한 값을 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classGradientDescentOptimizer">class <code>GradientDescentOptimizer</code><a class="headerlink" href="#classGradientDescentOptimizer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class GradientDescentOptimizer
  : public Optimizer&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classGradientDescentOptimizer_1a308ba6cac844c89e54471859d5da6285"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></td>
<td>GradientDescentOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGradientDescentOptimizer_1a41d48f02cf8465c2ffde25f47198d930"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,OptimizeDirection pOptimizeDirection)</code></td>
<td>GradientDescentOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGradientDescentOptimizer_1a04ff84018ebe89fbb5fa8a1bdbfb428e"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td>GradientDescentOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classGradientDescentOptimizer_1af4344616b07632306e678037ce6c89bb"><code>~GradientDescentOptimizer</code></a><code>()</code></td>
<td>GradientDescentOptimizer의 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGradientDescentOptimizer_1ab968000d204c52e6cb349204ddbc4cd1"><code>Alloc</code></a><code>()</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGradientDescentOptimizer_1a252fb90356ce7f3bcdd7770d078f2501"><code>Alloc</code></a><code>(float momentum)</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGradientDescentOptimizer_1af4758fdc5cd03534a82846cea2969dd3"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classGradientDescentOptimizer_1a3f91a71f3153a5add223200092cced67"><code>InitializeAttributeForGPU</code></a><code>(unsigned int idOfDevice)</code></td>
<td>m_aaVelocity내부의 Tensor의 device를 idOfDevice번째 GPU로 바꾼다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGradientDescentOptimizer_1ae6fde8288f07c36b625fb2772a4154d3"><code>UpdateParameter</code></a><code>()</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classGradientDescentOptimizer_1ae9ee1f4f549d532d5011ce6ac6848976"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classGradientDescentOptimizer_1a5f8c15ae8c990f306f36c287f05d258e"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pVelocity)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classGradientDescentOptimizer_1a308ba6cac844c89e54471859d5da6285"><code>public inline</code><a href="#classGradientDescentOptimizer_1a308ba6cac844c89e54471859d5da6285"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p>GradientDescentOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1ab968000d204c52e6cb349204ddbc4cd1">Alloc()</a></p>
<h4 id="classGradientDescentOptimizer_1a41d48f02cf8465c2ffde25f47198d930"><code>public inline</code><a href="#classGradientDescentOptimizer_1a41d48f02cf8465c2ffde25f47198d930"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,OptimizeDirection pOptimizeDirection)</code></h4>
<p>GradientDescentOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 momentum값을 파라미터로 하는 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameterContainer</code> </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>momentum</code> Optimize의 momentum </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1a252fb90356ce7f3bcdd7770d078f2501">Alloc(float momentum)</a></p>
<h4 id="classGradientDescentOptimizer_1a04ff84018ebe89fbb5fa8a1bdbfb428e"><code>public inline</code><a href="#classGradientDescentOptimizer_1a04ff84018ebe89fbb5fa8a1bdbfb428e"><code>GradientDescentOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p>GradientDescentOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 momentum값을 파라미터로 하는 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameterContainer</code> </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>momentum</code> Optimize의 momentum </p>
</li>
<li>
<p><code>weightDecayRate</code> @paramp OptimizeDirection Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1a252fb90356ce7f3bcdd7770d078f2501">Alloc(float momentum)</a></p>
<h4 id="classGradientDescentOptimizer_1af4344616b07632306e678037ce6c89bb"><code>public inline</code><a href="#classGradientDescentOptimizer_1af4344616b07632306e678037ce6c89bb"><code>~GradientDescentOptimizer</code></a><code>()</code></h4>
<p>GradientDescentOptimizer의 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classGradientDescentOptimizer_1ab968000d204c52e6cb349204ddbc4cd1"><code>public inline int</code><a href="#classGradientDescentOptimizer_1ab968000d204c52e6cb349204ddbc4cd1"><code>Alloc</code></a><code>()</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_ppParameter와 m_numOfParameter를 초기화한다. </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: <a href="#classContainer">Container</a>&lt;<a href="#classOperator">Operator<DTYPE></a> <em>&gt;</em> GetTrainableTensor() </p>
<p><strong>See also</strong>: int GetTrainableTensorDegree()</p>
<h4 id="classGradientDescentOptimizer_1a252fb90356ce7f3bcdd7770d078f2501"><code>public inline int</code><a href="#classGradientDescentOptimizer_1a252fb90356ce7f3bcdd7770d078f2501"><code>Alloc</code></a><code>(float momentum)</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_aaVelocity, m_momentum를 초기화 한다.</p>
<p>m_aaVelocity에 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다. </p>
<h5>Parameters</h5>
<ul>
<li><code>momentum</code> Optimizer의 monentum값 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1ab968000d204c52e6cb349204ddbc4cd1">Alloc()</a></p>
<h4 id="classGradientDescentOptimizer_1af4758fdc5cd03534a82846cea2969dd3"><code>public inline int</code><a href="#classGradientDescentOptimizer_1af4758fdc5cd03534a82846cea2969dd3"><code>Delete</code></a><code>()</code></h4>
<h4 id="classGradientDescentOptimizer_1a3f91a71f3153a5add223200092cced67"><code>public inline void</code><a href="#classGradientDescentOptimizer_1a3f91a71f3153a5add223200092cced67"><code>InitializeAttributeForGPU</code></a><code>(unsigned int idOfDevice)</code></h4>
<p>m_aaVelocity내부의 Tensor의 device를 idOfDevice번째 GPU로 바꾼다.</p>
<h5>Parameters</h5>
<ul>
<li><code>idOfDevice</code> 사용 하는 GPU번호</li>
</ul>
<h4 id="classGradientDescentOptimizer_1ae6fde8288f07c36b625fb2772a4154d3"><code>public inline virtual int</code><a href="#classGradientDescentOptimizer_1ae6fde8288f07c36b625fb2772a4154d3"><code>UpdateParameter</code></a><code>()</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_momentum값에 따라 다른 UpdataParameter를 호출한다. </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1ae9ee1f4f549d532d5011ce6ac6848976">UpdateParameter(Operator<DTYPE> *pParameter)</a></p>
<p><strong>See also</strong>: int <a href="#classGradientDescentOptimizer_1a5f8c15ae8c990f306f36c287f05d258e">UpdateParameter(Operator<DTYPE> *pParameter, Tensor<DTYPE> *pVelocity)</a></p>
<h4 id="classGradientDescentOptimizer_1ae9ee1f4f549d532d5011ce6ac6848976"><code>public inline virtual int</code><a href="#classGradientDescentOptimizer_1ae9ee1f4f549d532d5011ce6ac6848976"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>Parameter안에 있는 Tensor의 새로 계산된 gradinet값과 learning_rate의 곱, weightDecayRate와 기존 weight(trainable_date)의 곱으로 weight(trainable_date)값을 업데이트한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classGradientDescentOptimizer_1a5f8c15ae8c990f306f36c287f05d258e"><code>public inline int</code><a href="#classGradientDescentOptimizer_1a5f8c15ae8c990f306f36c287f05d258e"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pVelocity)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>Parameter안에 있는 Tensor의 새로 계산된 gradinet값과 learning_rate의 곱, weightDecayRate와 기존 weight(trainable_date)의 곱으로 weight(trainable_date)값을 업데이트한다.</p>
<p>momentum과 pVelocity의 곱과 learnung_rate와 gradient의 곱으로 pVelocity의 값을 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pVelocity</code> 업데이트 할 pVelocity </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<hr />
<h2 id="classHingeLoss">class <code>HingeLoss</code><a class="headerlink" href="#classHingeLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class HingeLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<p>Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</p>
<p>Hinge Loss 계산 식을 이용해 뉴럴 네트워크의 순전파를 통해 계산된 출력 Tensor와 레이블 값의 손실 함수를 계산한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classHingeLoss_1a1fd8f684e9fc55fa6f520cc6d9e95240"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,float theta)</code></td>
<td><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classHingeLoss_1af5cf855a84b382ca3948dbd9218d1279"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classHingeLoss_1a332c2d14aa13dea8833d244f91bfa87c"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,float theta,std::string pName)</code></td>
<td><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classHingeLoss_1a27cb9c3fcce4bc2eee68cb5a921d1b87"><code>~HingeLoss</code></a><code>()</code></td>
<td><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,float theta)</code></td>
<td><a href="#classHingeLoss">HingeLoss</a> Lossfunction의 멤버 변수들을 동적 할당하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classHingeLoss_1a38f635376808e0609ebb99daa09354f2"><code>Delete</code></a><code>()</code></td>
<td><a href="#classLossFunction">LossFunction</a> 클래스의 메모리를 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classHingeLoss_1ad839f1997f80de41ca4da2282b85e0f9"><code>ForwardPropagate</code></a><code>(int timeIdx)</code></td>
<td>GPU 동작 모드에서의 <a href="#classHingeLoss">HingeLoss</a> LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classHingeLoss_1abc6ab97e970a292e9611b9ec2739a9f3"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>GPU 동작 모드에서의 <a href="#classHingeLoss">HingeLoss</a> LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classHingeLoss_1a1fd8f684e9fc55fa6f520cc6d9e95240"><code>public inline</code><a href="#classHingeLoss_1a1fd8f684e9fc55fa6f520cc6d9e95240"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,float theta)</code></h4>
<p><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 theta을 매개변수로 전달하여 <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>theta</code> alloc 메소드의 theta 값으로 전달할 파라미터, 값을 지정하지 않을 시 1.f로 초기화 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a></p>
<h4 id="classHingeLoss_1af5cf855a84b382ca3948dbd9218d1279"><code>public inline</code><a href="#classHingeLoss_1af5cf855a84b382ca3948dbd9218d1279"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<p><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 1.f에 해당하는 theta 값 매개변수로 전달하여 <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a></p>
<h4 id="classHingeLoss_1a332c2d14aa13dea8833d244f91bfa87c"><code>public inline</code><a href="#classHingeLoss_1a332c2d14aa13dea8833d244f91bfa87c"><code>HingeLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,float theta,std::string pName)</code></h4>
<p><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 theta을 매개변수로 전달하여 <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>theta</code> alloc 메소드의 theta 값으로 전달할 파라미터 </p>
</li>
</ul>
<p><strong>See also</strong>: <a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936">HingeLoss<DTYPE>::Alloc(Operator<DTYPE> *pOperator, float theta)</a></p>
<h4 id="classHingeLoss_1a27cb9c3fcce4bc2eee68cb5a921d1b87"><code>public inline</code><a href="#classHingeLoss_1a27cb9c3fcce4bc2eee68cb5a921d1b87"><code>~HingeLoss</code></a><code>()</code></h4>
<p><a href="#classHingeLoss">HingeLoss</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936"><code>public inline int</code><a href="#classHingeLoss_1ad279a4a7cf77d9d22029049f5227e936"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,float theta)</code></h4>
<p><a href="#classHingeLoss">HingeLoss</a> Lossfunction의 멤버 변수들을 동적 할당하는 메소드</p>
<p>매개변수로 전달받은 Operator를 Input Operator에 할당하고 초기화 된 Result 텐서를 동적으로 할당 및 생성한다.</p>
<p>역전파를 위한 인덱스 더미 텐서를 동적으로 할당 및 생성하고 theta 값을 초기화한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 입력에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>theta</code> LossFunction의 멤버 변수 theta에 할당할 값 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classHingeLoss_1a38f635376808e0609ebb99daa09354f2"><code>public inline virtual void</code><a href="#classHingeLoss_1a38f635376808e0609ebb99daa09354f2"><code>Delete</code></a><code>()</code></h4>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 메모리를 할당 해제하는 메소드</p>
<p>Index for BackPropagation Tensor가 존재할 경우 Tensor의 메모리를 할당 해제하고 0으로 초기화한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classHingeLoss_1ad839f1997f80de41ca4da2282b85e0f9"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classHingeLoss_1ad839f1997f80de41ca4da2282b85e0f9"><code>ForwardPropagate</code></a><code>(int timeIdx)</code></h4>
<p>GPU 동작 모드에서의 <a href="#classHingeLoss">HingeLoss</a> LossFunction의 순전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 결과 값을 레이블 값과 비교해 Hinge Loss 값을 구한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>timeIdx</code> Time 축의 인덱스, 미지정 시 0으로 초기화 </li>
</ul>
<h5>Returns</h5>
<p>뉴럴 네트워크 결과 값에 대한 Hinge Loss</p>
<h4 id="classHingeLoss_1abc6ab97e970a292e9611b9ec2739a9f3"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classHingeLoss_1abc6ab97e970a292e9611b9ec2739a9f3"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>GPU 동작 모드에서의 <a href="#classHingeLoss">HingeLoss</a> LossFunction의 역전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 <a href="#classHingeLoss">HingeLoss</a> LossFunction에 대한 입력 Tensor의 Gradient를 계산한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTIme</code> Time 축의 인덱스, 미지정 시 0으로 초기화 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classKNearestNeighbor">class <code>KNearestNeighbor</code><a class="headerlink" href="#classKNearestNeighbor" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classKNearestNeighbor_1addce391444a16e29943d4f366107ea21"><code>KNearestNeighbor</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classKNearestNeighbor_1ada5e2880030688a4b2bad199eb017f65"><code>KNearestNeighbor</code></a><code>(int dim,int noClass,int noRef,int * pRefLabel,float * pRefVector)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classKNearestNeighbor_1ab54b4b3a500a79b9c4656f55ca1b43ba"><code>~KNearestNeighbor</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classKNearestNeighbor_1aec217b766f1a70bb1e5743a99a737b4a"><code>AddReference</code></a><code>(int label,float * pRefVector)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classKNearestNeighbor_1a6f3d5f4a8ea89282e79d742950b842f0"><code>Recognize</code></a><code>(float * pInput,int k)</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classKNearestNeighbor_1a032c332fb53270577542c5bc1eb2588d"><code>GetAccuracy</code></a><code>(int noTestSamples,int * pTestLabels,float * pTestVectors,int k)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classKNearestNeighbor_1addce391444a16e29943d4f366107ea21"><code>public inline</code><a href="#classKNearestNeighbor_1addce391444a16e29943d4f366107ea21"><code>KNearestNeighbor</code></a><code>()</code></h4>
<h4 id="classKNearestNeighbor_1ada5e2880030688a4b2bad199eb017f65"><code>public</code><a href="#classKNearestNeighbor_1ada5e2880030688a4b2bad199eb017f65"><code>KNearestNeighbor</code></a><code>(int dim,int noClass,int noRef,int * pRefLabel,float * pRefVector)</code></h4>
<h4 id="classKNearestNeighbor_1ab54b4b3a500a79b9c4656f55ca1b43ba"><code>public virtual</code><a href="#classKNearestNeighbor_1ab54b4b3a500a79b9c4656f55ca1b43ba"><code>~KNearestNeighbor</code></a><code>()</code></h4>
<h4 id="classKNearestNeighbor_1aec217b766f1a70bb1e5743a99a737b4a"><code>public void</code><a href="#classKNearestNeighbor_1aec217b766f1a70bb1e5743a99a737b4a"><code>AddReference</code></a><code>(int label,float * pRefVector)</code></h4>
<h4 id="classKNearestNeighbor_1a6f3d5f4a8ea89282e79d742950b842f0"><code>public int</code><a href="#classKNearestNeighbor_1a6f3d5f4a8ea89282e79d742950b842f0"><code>Recognize</code></a><code>(float * pInput,int k)</code></h4>
<h4 id="classKNearestNeighbor_1a032c332fb53270577542c5bc1eb2588d"><code>public float</code><a href="#classKNearestNeighbor_1a032c332fb53270577542c5bc1eb2588d"><code>GetAccuracy</code></a><code>(int noTestSamples,int * pTestLabels,float * pTestVectors,int k)</code></h4>
<hr />
<h2 id="classLinear">class <code>Linear</code><a class="headerlink" href="#classLinear" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Linear
  : public Module&lt; DTYPE &gt;
</code></pre></div>

<p>구성해 fully connected layer의 기능을 수행하는 모듈을 생성하는 클래스</p>
<p>Operator들을 뉴럴 네트워크의 서브 그래프로 구성해 fully connected layer의 기능을 수행한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classLinear_1aa748db4f994e9ced4e6727ed28859864"><code>Linear</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputCol,int pNumOutputCol,int use_bias,std::string pName)</code></td>
<td><a href="#classLinear">Linear</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classLinear_1a93788848749be1d68d444bd40d8d9bc1"><code>~Linear</code></a><code>()</code></td>
<td><a href="#classLinear">Linear</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classLinear_1a83d01a67c02c7d09c34129bd900366e0"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputCol,int pNumOutputCol,int use_bias,std::string pName)</code></td>
<td><a href="#classLinear">Linear(Fully Connected)</a> Layer 그래프를 동적으로 할당 및 구성하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classLinear_1aa748db4f994e9ced4e6727ed28859864"><code>public inline</code><a href="#classLinear_1aa748db4f994e9ced4e6727ed28859864"><code>Linear</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputCol,int pNumOutputCol,int use_bias,std::string pName)</code></h4>
<p><a href="#classLinear">Linear</a> 클래스 생성자</p>
<p><a href="#classLinear">Linear</a> 클래스의 Alloc 메소드를 호출한다. 
<strong>See also</strong>: linear<DTYPE>::Alloc(Operator<DTYPE> *pInput, int pNumInputCol, int pNumOutputCol, int use_bias, std::string pName)</p>
<h4 id="classLinear_1a93788848749be1d68d444bd40d8d9bc1"><code>public inline virtual</code><a href="#classLinear_1a93788848749be1d68d444bd40d8d9bc1"><code>~Linear</code></a><code>()</code></h4>
<p><a href="#classLinear">Linear</a> 클래스 소멸자</p>
<p>단, 동적 할당 받은 Operator들은 NeuralNetwork에서 할당 해제한다.</p>
<h4 id="classLinear_1a83d01a67c02c7d09c34129bd900366e0"><code>public inline int</code><a href="#classLinear_1a83d01a67c02c7d09c34129bd900366e0"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputCol,int pNumOutputCol,int use_bias,std::string pName)</code></h4>
<p><a href="#classLinear">Linear(Fully Connected)</a> Layer 그래프를 동적으로 할당 및 구성하는 메소드</p>
<p>Input Operator의 Element에 대해 Weight를 이용해 행렬 곱(Matrix Multiplication)을 수행하고 Bias가 존재할 시 Bias를 합(Column Wise Addition)해 Output Operator로 내보내는 layer를 구성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 해당 Layer의 Input에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pNumInputCol</code> 해당 Layer의 Input Operator의 Column의 갯수, Input Column에 대한 Dimension </p>
</li>
<li>
<p><code>pNumOutputCol</code> 해당 Layer의 Output Operator의 Column의 갯수, Output Column에 대한 Dimension </p>
</li>
<li>
<p><code>use_bias</code> Bias 사용 유무, 0일 시 사용 안 함, 0이 아닐 시 사용 </p>
</li>
<li>
<p><code>pName</code> Module의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: MatMul<DTYPE>::MatMul(Operator<DTYPE> *pWeight, Operator<DTYPE> *pInput, std::string pName) AddColWise<DTYPE>::AddColWise(Operator<DTYPE> *pInput, Operator<DTYPE> *pBias, std::string pName) <a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614">Module<DTYPE>::AnalyzeGraph(Operator<DTYPE> *pResultOperator)</a></p>
<hr />
<h2 id="classLongArray">class <code>LongArray</code><a class="headerlink" href="#classLongArray" title="Permanent link">&para;</a></h2>
<p>데이터를 저장하고 관리하는 클래스.</p>
<p>학습에 사용 될 Tensor의 맴버변수 중 LongArray를 정의하기 위한 클래스.</p>
<p>실질적으로 Tensor클래스의 데이터를 저장하고 관리하기위한 클래스.</p>
<p>데이터를 초기화하고 CPU와 GPU간 데이터의 이동을 가능하게 한다.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classLongArray_1a0e448aa621a5a40584f4db3bee5f27b3"><code>LongArray</code></a><code>(unsigned int pCapacity)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLongArray_1a0ee04422fc600f9b2d577f6679e131f5"><code>LongArray</code></a><code>(unsigned int pTimeSize,unsigned int pCapacityPerTime)</code></td>
<td>입력받은 TimeSize와 Capacity크기의 LongArray를 Alloc하는 생성자.</td>
</tr>
<tr>
<td><code>public</code><a href="#classLongArray_1a8ba08c4e2db06cf8077b543f4133c341"><code>LongArray</code></a><code>(</code><a href="#classLongArray"><code>LongArray</code></a><code>* pLongArray)</code></td>
<td>LongArray를 deep copy하는 메소드.</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classLongArray_1a99b9382548ea2c7eb2864b8fc6834fbf"><code>~LongArray</code></a><code>()</code></td>
<td>LongArray의 소멸자.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1aac066a7a3124bd3faf5790cb1cd3a775"><code>GetCapacity</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1a2fdf38f3b567651e109e237a32354479"><code>GetTimeSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1a8a76e2170c3fd845c5d4a4264d818347"><code>GetCapacityPerTime</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public DTYPE</code><a href="#classLongArray_1a891727ff9e896eece172ca0f5f91c682"><code>GetElement</code></a><code>(unsigned int index)</code></td>
<td>LongArray의 특정 원소의 값을 반환하는 메소드.</td>
</tr>
<tr>
<td><code>public DTYPE &amp;</code><a href="#classLongArray_1ac589b2d62373ff5b107869f4d6438773"><code>operator[]</code></a><code>(unsigned int index)</code></td>
<td>[]연산자 Overloading</td>
</tr>
<tr>
<td><code>public Device</code><a href="#classLongArray_1a390aa49da495a88a8180bcc829790471"><code>GetDevice</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1a7ea4aa2f04851aa209017b6401f2b35f"><code>GetDeviceID</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public DTYPE *</code><a href="#classLongArray_1a488167dabfb50194e2af76e31745d73a"><code>GetCPULongArray</code></a><code>(unsigned int pTime)</code></td>
<td>m_aaHostLongArray중 pTime에 있는 LongArray를 반환하는 메소드.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf"><code>SetDeviceCPU</code></a><code>()</code></td>
<td>LongArray의 m_Device를 CPU로 바꾸는 메소드.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1ac4039a1f176738fc44ef8f8c28aa0d50"><code>Save</code></a><code>(FILE * fp)</code></td>
<td>LongArray의 데이터를 파일에 저장하는 메소드.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classLongArray_1a76e8e08d27340622fb9a82603da15bd4"><code>Load</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classLongArray_1a0e448aa621a5a40584f4db3bee5f27b3"><code>public</code><a href="#classLongArray_1a0e448aa621a5a40584f4db3bee5f27b3"><code>LongArray</code></a><code>(unsigned int pCapacity)</code></h4>
<h4 id="classLongArray_1a0ee04422fc600f9b2d577f6679e131f5"><code>public</code><a href="#classLongArray_1a0ee04422fc600f9b2d577f6679e131f5"><code>LongArray</code></a><code>(unsigned int pTimeSize,unsigned int pCapacityPerTime)</code></h4>
<p>입력받은 TimeSize와 Capacity크기의 LongArray를 Alloc하는 생성자.</p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pTimeSize</code> Alloc할 LongArray의 TimeSize </p>
</li>
<li>
<p><code>pCapacity</code> Alloc할 LongArray의 Capacity </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음. </p>
<p><strong>See also</strong>: LongArray<DTYPE>::Alloc(unsigned int pTimeSize, unsigned int pCapacityPerTime)</p>
<h4 id="classLongArray_1a8ba08c4e2db06cf8077b543f4133c341"><code>public</code><a href="#classLongArray_1a8ba08c4e2db06cf8077b543f4133c341"><code>LongArray</code></a><code>(</code><a href="#classLongArray"><code>LongArray</code></a><code>* pLongArray)</code></h4>
<p>LongArray를 deep copy하는 메소드.</p>
<h5>Parameters</h5>
<ul>
<li><code>*pLongArray</code> deep copy할 대상 <a href="#classLongArray">LongArray</a></li>
</ul>
<h5>Returns</h5>
<p>없음. </p>
<p><strong>See also</strong>: LongArray<DTYPE>::Alloc(LongArray *pLongArray)</p>
<h4 id="classLongArray_1a99b9382548ea2c7eb2864b8fc6834fbf"><code>public virtual</code><a href="#classLongArray_1a99b9382548ea2c7eb2864b8fc6834fbf"><code>~LongArray</code></a><code>()</code></h4>
<p>LongArray의 소멸자.</p>
<p>Delete를 사용하여 해당 LongArray를 메모리에서 삭제한다 </p>
<h5>Returns</h5>
<p>없음. </p>
<p><strong>See also</strong>: void LongArray<DTYPE>::Delete()</p>
<h4 id="classLongArray_1aac066a7a3124bd3faf5790cb1cd3a775"><code>public int</code><a href="#classLongArray_1aac066a7a3124bd3faf5790cb1cd3a775"><code>GetCapacity</code></a><code>()</code></h4>
<h4 id="classLongArray_1a2fdf38f3b567651e109e237a32354479"><code>public int</code><a href="#classLongArray_1a2fdf38f3b567651e109e237a32354479"><code>GetTimeSize</code></a><code>()</code></h4>
<h4 id="classLongArray_1a8a76e2170c3fd845c5d4a4264d818347"><code>public int</code><a href="#classLongArray_1a8a76e2170c3fd845c5d4a4264d818347"><code>GetCapacityPerTime</code></a><code>()</code></h4>
<h4 id="classLongArray_1a891727ff9e896eece172ca0f5f91c682"><code>public DTYPE</code><a href="#classLongArray_1a891727ff9e896eece172ca0f5f91c682"><code>GetElement</code></a><code>(unsigned int index)</code></h4>
<p>LongArray의 특정 원소의 값을 반환하는 메소드.</p>
<p>메모리에 있는 LongArray데이터 중 index번째 있는 원소의 값을 반환한다.</p>
<p>단, m_Device가 GPU이면 바로 값을 꺼내올 수 없기 때문에 CPU로 바꿔 준 후 값을 찾아 반환한다. </p>
<h5>Returns</h5>
<p>m_aaHostLongArray[index / m_CapacityPerTime][index % m_CapacityPerTime] </p>
<p><strong>See also</strong>: <a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf">LongArray<DTYPE>::SetDeviceCPU()</a></p>
<h4 id="classLongArray_1ac589b2d62373ff5b107869f4d6438773"><code>public DTYPE &amp;</code><a href="#classLongArray_1ac589b2d62373ff5b107869f4d6438773"><code>operator[]</code></a><code>(unsigned int index)</code></h4>
<p>[]연산자 Overloading</p>
<p>m_aLongArray의 특정 위치에 있는 값을 return할 수 있게 한다.</p>
<p>단, m_Device가 GPU일 시 CPU로 바꿔 준 후 값을 찾아 반환한다.</p>
<p>GetElement와 다르게 주소값을 반환하기 때문에 LongArray의 값을 변경 할 수 있다. 
<strong>See also</strong>: <a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf">LongArray<DTYPE>::SetDeviceCPU()</a></p>
<h4 id="classLongArray_1a390aa49da495a88a8180bcc829790471"><code>public Device</code><a href="#classLongArray_1a390aa49da495a88a8180bcc829790471"><code>GetDevice</code></a><code>()</code></h4>
<h4 id="classLongArray_1a7ea4aa2f04851aa209017b6401f2b35f"><code>public int</code><a href="#classLongArray_1a7ea4aa2f04851aa209017b6401f2b35f"><code>GetDeviceID</code></a><code>()</code></h4>
<h4 id="classLongArray_1a488167dabfb50194e2af76e31745d73a"><code>public DTYPE *</code><a href="#classLongArray_1a488167dabfb50194e2af76e31745d73a"><code>GetCPULongArray</code></a><code>(unsigned int pTime)</code></h4>
<p>m_aaHostLongArray중 pTime에 있는 LongArray를 반환하는 메소드.</p>
<p>m_CapacityOfLongArray를 m_TimeSize로 나눈 LongArray블럭 중 pTime번째의 LongArray블럭을 반환한다.</p>
<p>단, m_Device가 GPU일 시 CPU로 바꿔 준 후 값을 찾아 반환한다. </p>
<h5>Returns</h5>
<p>m_aaHostLongArray[pTime] </p>
<p><strong>See also</strong>: <a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf">LongArray<DTYPE>::SetDeviceCPU()</a></p>
<h4 id="classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf"><code>public int</code><a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf"><code>SetDeviceCPU</code></a><code>()</code></h4>
<p>LongArray의 m_Device를 CPU로 바꾸는 메소드.</p>
<p>m_Device를 CPU로 바꾼다. CUDNN이 있을 경우 GPU 메모리의 값들을 CPU메모리로 복사한다. </p>
<h5>Returns</h5>
<p>없음. </p>
<p><strong>See also</strong>: MemcpyGPU2CPU()</p>
<h4 id="classLongArray_1ac4039a1f176738fc44ef8f8c28aa0d50"><code>public int</code><a href="#classLongArray_1ac4039a1f176738fc44ef8f8c28aa0d50"><code>Save</code></a><code>(FILE * fp)</code></h4>
<p>LongArray의 데이터를 파일에 저장하는 메소드.</p>
<p>fwrite함수를 통해 *fileForSave가 가리키는 파일에 LongArray데이터를 쓴다.</p>
<p>단, m_Device가 GPU일 시 CPU로 바꿔 준 후 값을 찾아 반환한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>*fileForSave</code> 데이터를 저장할 file을 가리는 포인터. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE. </p>
<p><strong>See also</strong>: <a href="#classLongArray_1a7a6546122e528c6f8934f08eefd1d9bf">LongArray<DTYPE>::SetDeviceCPU()</a></p>
<h4 id="classLongArray_1a76e8e08d27340622fb9a82603da15bd4"><code>public int</code><a href="#classLongArray_1a76e8e08d27340622fb9a82603da15bd4"><code>Load</code></a><code>(FILE * fp)</code></h4>
<hr />
<h2 id="classLossFunction">class <code>LossFunction</code><a class="headerlink" href="#classLossFunction" title="Permanent link">&para;</a></h2>
<p>손실 함수를 계산하는 클래스</p>
<p>뉴럴 네트워크의 순전파를 통해 계산된 출력 Tensor와 레이블 값을 비교해 손실 함수를 계산한다.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classLossFunction_1ad16b1ebac0244fcf6f527e541f0b022d"><code>LossFunction</code></a><code>(std::string pName)</code></td>
<td><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction_1a233884fd7efa12ecd4603188ad5dc17b"><code>LossFunction</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classLossFunction_1a6cae767962d4470457484f25a95dea7d"><code>~LossFunction</code></a><code>()</code></td>
<td><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classLossFunction_1ab391c591298aac6501a3ad2d69e4b2cd"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel)</code></td>
<td>LossFunction의 입력과 레이블을 지정하는 메소드</td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classLossFunction_1af1b7c7d302fdeb47d33a256c76132f7d"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public void</code><a href="#classLossFunction_1a6360d14472a61345a94190e04fb5ca70"><code>SetResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classLossFunction_1ab18d973fabc53cf0b7b7c611e491be39"><code>SetGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a157997c23d30330f3a1787c4e0494906"><code>GetResult</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a91617741dcdf4d23564fdc76c142c967"><code>GetGradient</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1aedc2dee597a08ae40d53450a49c60aa5"><code>GetOperator</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a771cbf18cc9665a59ea3d85f05362f60"><code>GetTensor</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1abebca5aa479892712d16950432a50634"><code>GetLabel</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public std::string</code><a href="#classLossFunction_1a52036df919c793a38c67a86752e245ce"><code>GetName</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual Device</code><a href="#classLossFunction_1a4d86b502935a77de60b41e4988224ae3"><code>GetDevice</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classLossFunction_1a1498adc80e7109b4f3c1e4c3c5a97e88"><code>GetDeviceID</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a8a564ed18072bb56e6c00c0538d93d2f"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a26a756b17dab553a0759f2cc6ffcfa3b"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public DTYPE &amp;</code><a href="#classLossFunction_1a7ab1c185e2a902f8d1baf05b4300d21f"><code>operator[]</code></a><code>(unsigned int index)</code></td>
<td>[] 연산자 오버로딩</td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classLossFunction_1aada7f95e69a5fd68aeeb0e92a5856032"><code>SetDeviceCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classLossFunction_1a218be336d4c24afd3ca91ee58ea600e0"><code>ResetResult</code></a><code>()</code></td>
<td>Result 텐서의 ELement를 0으로 초기화하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classLossFunction_1a3c75534f1638c50c062ae129e322aee0"><code>ResetGradient</code></a><code>()</code></td>
<td>Gradient 텐서의 ELement를 0으로 초기화하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classLossFunction_1ad16b1ebac0244fcf6f527e541f0b022d"><code>public</code><a href="#classLossFunction_1ad16b1ebac0244fcf6f527e541f0b022d"><code>LossFunction</code></a><code>(std::string pName)</code></h4>
<p><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p>LossFunction의 멤버 변수 포인터들을 NULL값으로 초기화하고, 매개변수로 받은 스트링을 m_name에 저장하고, m_Device를 CPU로 초기화한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pName</code> m_name에 할당할 LossFunction의 이름, 값을 전달하지 않을 시 "NO NAME"으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classLossFunction_1a233884fd7efa12ecd4603188ad5dc17b"><code>public</code><a href="#classLossFunction_1a233884fd7efa12ecd4603188ad5dc17b"><code>LossFunction</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<p><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p>LossFunction의 멤버 변수 포인터들을 NULL값으로 초기화하고, 매개변수로 받은 스트링을 m_name에 저장하고, m_Device를 CPU로 초기화한다.</p>
<p>pOperator와 pLabel을 매개변수로 <a href="#classLossFunction_1ab391c591298aac6501a3ad2d69e4b2cd">LossFunction<DTYPE>::Alloc(Operator<DTYPE> *pOperator, Operator<DTYPE> *pLabel)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> Alloc 메소드의 매개변수로 전달할 LossFunction의 입력에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> Alloc 메소드의 매개변수로 전달할 LossFunction의 입력에 해당하는 레이블 </p>
</li>
<li>
<p><code>pName</code> m_name에 할당할 LossFunction의 이름, 값을 전달하지 않을 시 "NO NAME"으로 초기화 됨 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classLossFunction_1a6cae767962d4470457484f25a95dea7d"><code>public virtual</code><a href="#classLossFunction_1a6cae767962d4470457484f25a95dea7d"><code>~LossFunction</code></a><code>()</code></h4>
<p><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</p>
<p><a href="#classLossFunction_1af1b7c7d302fdeb47d33a256c76132f7d">LossFunction<DTYPE>::Delete()</a> 메소드를 호출하고 클래스를 소멸시킨다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classLossFunction_1ab391c591298aac6501a3ad2d69e4b2cd"><code>public virtual int</code><a href="#classLossFunction_1ab391c591298aac6501a3ad2d69e4b2cd"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel)</code></h4>
<p>LossFunction의 입력과 레이블을 지정하는 메소드</p>
<p>매개변수로 전달받은 Operator와 Operator의 Result 포인터 값과 레이블 값을 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> LossFunction의 입력이 되는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>plabel</code> LossFunction의 입력이 되는 레이블 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classLossFunction_1af1b7c7d302fdeb47d33a256c76132f7d"><code>public virtual void</code><a href="#classLossFunction_1af1b7c7d302fdeb47d33a256c76132f7d"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classLossFunction_1a6360d14472a61345a94190e04fb5ca70"><code>public void</code><a href="#classLossFunction_1a6360d14472a61345a94190e04fb5ca70"><code>SetResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classLossFunction_1ab18d973fabc53cf0b7b7c611e491be39"><code>public void</code><a href="#classLossFunction_1ab18d973fabc53cf0b7b7c611e491be39"><code>SetGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classLossFunction_1a157997c23d30330f3a1787c4e0494906"><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a157997c23d30330f3a1787c4e0494906"><code>GetResult</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1a91617741dcdf4d23564fdc76c142c967"><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a91617741dcdf4d23564fdc76c142c967"><code>GetGradient</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1aedc2dee597a08ae40d53450a49c60aa5"><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1aedc2dee597a08ae40d53450a49c60aa5"><code>GetOperator</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1a771cbf18cc9665a59ea3d85f05362f60"><code>public</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a771cbf18cc9665a59ea3d85f05362f60"><code>GetTensor</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1abebca5aa479892712d16950432a50634"><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1abebca5aa479892712d16950432a50634"><code>GetLabel</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1a52036df919c793a38c67a86752e245ce"><code>public std::string</code><a href="#classLossFunction_1a52036df919c793a38c67a86752e245ce"><code>GetName</code></a><code>() const</code></h4>
<h4 id="classLossFunction_1a4d86b502935a77de60b41e4988224ae3"><code>public virtual Device</code><a href="#classLossFunction_1a4d86b502935a77de60b41e4988224ae3"><code>GetDevice</code></a><code>()</code></h4>
<h4 id="classLossFunction_1a1498adc80e7109b4f3c1e4c3c5a97e88"><code>public virtual int</code><a href="#classLossFunction_1a1498adc80e7109b4f3c1e4c3c5a97e88"><code>GetDeviceID</code></a><code>()</code></h4>
<h4 id="classLossFunction_1a8a564ed18072bb56e6c00c0538d93d2f"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a8a564ed18072bb56e6c00c0538d93d2f"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classLossFunction_1a26a756b17dab553a0759f2cc6ffcfa3b"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classLossFunction_1a26a756b17dab553a0759f2cc6ffcfa3b"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classLossFunction_1a7ab1c185e2a902f8d1baf05b4300d21f"><code>public DTYPE &amp;</code><a href="#classLossFunction_1a7ab1c185e2a902f8d1baf05b4300d21f"><code>operator[]</code></a><code>(unsigned int index)</code></h4>
<p>[] 연산자 오버로딩</p>
<p>매개변수로 전달받은 index 값 매개변수로 전달하여 Result 텐서에서 []연산자 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>index</code> Tensor의 [] 연산자 메소드에 매개변수로 전달할 인덱스 값 </li>
</ul>
<h5>Returns</h5>
<p>(*m_aResult)[index] </p>
<p><strong>See also</strong>: Tensor<DTYPE>::operator<a href="unsigned int index"></a></p>
<h4 id="classLossFunction_1aada7f95e69a5fd68aeeb0e92a5856032"><code>public virtual void</code><a href="#classLossFunction_1aada7f95e69a5fd68aeeb0e92a5856032"><code>SetDeviceCPU</code></a><code>()</code></h4>
<h4 id="classLossFunction_1a218be336d4c24afd3ca91ee58ea600e0"><code>public int</code><a href="#classLossFunction_1a218be336d4c24afd3ca91ee58ea600e0"><code>ResetResult</code></a><code>()</code></h4>
<p>Result 텐서의 ELement를 0으로 초기화하는 메소드</p>
<p>Result 텐서의 Device 멤버 변수가 CPU인 경우 CPU 메모리에서 초기화하고, CPU인 경우 GPU 메모리에서 초기화한다. </p>
<h5>Returns</h5>
<p>Result 텐서의 Device 멤버 변수가 Invalid한 값을 가지고 있는 경우 FALSE를 그 외의 경우 TRUE를 반환한다.</p>
<h4 id="classLossFunction_1a3c75534f1638c50c062ae129e322aee0"><code>public int</code><a href="#classLossFunction_1a3c75534f1638c50c062ae129e322aee0"><code>ResetGradient</code></a><code>()</code></h4>
<p>Gradient 텐서의 ELement를 0으로 초기화하는 메소드</p>
<p>Gradient 텐서의 Device 멤버 변수가 CPU인 경우 CPU 메모리에서 초기화하고, CPU인 경우 GPU 메모리에서 초기화한다. </p>
<h5>Returns</h5>
<p>Gradient 텐서의 Device 멤버 변수가 Invalid한 값을 가지고 있는 경우 FALSE를 그 외의 경우 TRUE를 반환한다.</p>
<hr />
<h2 id="classLRelu">class <code>LRelu</code><a class="headerlink" href="#classLRelu" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class LRelu
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classLRelu_1a890bd4b4423289342bf76cd8dec4ded2"><code>LRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope,int pLoadflag)</code></td>
<td>LRelu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classLRelu_1a4703113933cac094b879ba9dedb4bc36"><code>LRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope,std::string pName,int pLoadflag)</code></td>
<td>LRelu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classLRelu_1af07aac4e93018681985799014b5c19b4"><code>~LRelu</code></a><code>()</code></td>
<td>LRelu의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classLRelu_1af51d676679f90ed10690e0920e03c459"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope)</code></td>
<td>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classLRelu_1a61814364f8bfe1c0297e0ebb1727aef8"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classLRelu_1a9c7970df9d473b47301d42ffe3838c1b"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LRelu의 ForwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classLRelu_1a8322f90cae9c6c0c704fc8ad87a3c2e5"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LRelu의 BackPropagate매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classLRelu_1a890bd4b4423289342bf76cd8dec4ded2"><code>public inline</code><a href="#classLRelu_1a890bd4b4423289342bf76cd8dec4ded2"><code>LRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope,int pLoadflag)</code></h4>
<p>LRelu의 생성자.</p>
<p>파라미터로 받은 pInput, negativeSlope으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>negativeSlope</code> 입력값이 음수일 경우 사용하는 기울기 int <a href="#classLRelu_1af51d676679f90ed10690e0920e03c459">Alloc(Operator<DTYPE> *pInput, float negativeSlope)</a></p>
</li>
</ul>
<h4 id="classLRelu_1a4703113933cac094b879ba9dedb4bc36"><code>public inline</code><a href="#classLRelu_1a4703113933cac094b879ba9dedb4bc36"><code>LRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope,std::string pName,int pLoadflag)</code></h4>
<p>LRelu의 생성자.</p>
<p>파라미터로 받은 pInput, negativeSlope으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>negativeSlope</code> 입력값이 음수일 경우 사용하는 기울기 </p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classLRelu_1af51d676679f90ed10690e0920e03c459">Alloc(Operator<DTYPE> *pInput, float negativeSlope)</a></p>
</li>
</ul>
<h4 id="classLRelu_1af07aac4e93018681985799014b5c19b4"><code>public inline</code><a href="#classLRelu_1af07aac4e93018681985799014b5c19b4"><code>~LRelu</code></a><code>()</code></h4>
<p>LRelu의 소멸자.</p>
<p><strong>See also</strong>: void Delete()</p>
<h4 id="classLRelu_1af51d676679f90ed10690e0920e03c459"><code>public inline int</code><a href="#classLRelu_1af51d676679f90ed10690e0920e03c459"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,float negativeSlope)</code></h4>
<p>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다.</p>
<p>negativeSlope은 m_negativeSlope에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 생성할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>negativeSlope</code> 입력값이 음수일 경우 사용하는 기울기 </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classLRelu_1a61814364f8bfe1c0297e0ebb1727aef8"><code>public inline void</code><a href="#classLRelu_1a61814364f8bfe1c0297e0ebb1727aef8"><code>Delete</code></a><code>()</code></h4>
<h4 id="classLRelu_1a9c7970df9d473b47301d42ffe3838c1b"><code>public inline virtual int</code><a href="#classLRelu_1a9c7970df9d473b47301d42ffe3838c1b"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LRelu의 ForwardPropagate 매소드.</p>
<p>input의 Tensor값들 중 0.f이상의 값은 그대로 result에 저장하고,</p>
<p>0.f미만의 값은 m_negativeSlope을 곱한 후 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classLRelu_1a8322f90cae9c6c0c704fc8ad87a3c2e5"><code>public inline virtual int</code><a href="#classLRelu_1a8322f90cae9c6c0c704fc8ad87a3c2e5"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LRelu의 BackPropagate매소드.</p>
<p>result값이 0보다 클 경우 input_delta에 더하고,</p>
<p>0보다 작을 경우 input_delta에 m_negativeSlope을 곱한 후 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classMatMul">class <code>MatMul</code><a class="headerlink" href="#classMatMul" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class MatMul
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classMatMul_1afd77f3abc4bc600c045b74a634952ae8"><code>MatMul</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td>MatMul의 생성자.</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classMatMul_1a3c436539092d145a8bd89a91285094f5"><code>~MatMul</code></a><code>()</code></td>
<td>MatMul의 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classMatMul_1aad34ca11b1ed37b103381f8ef204bef2"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td>파라미터로 받은 pWeight, pInput으로 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classMatMul_1a45113c61efe47376cb0751d4a1106568"><code>Delete</code></a><code>()</code></td>
<td>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classMatMul_1a44c66bf3826370257a718bf974a2af68"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>MatMul의 ForwardPropagate매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classMatMul_1aebaeb2eee8735a3bdb1c7f2bc64a96a8"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>MatMul의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classMatMul_1afd77f3abc4bc600c045b74a634952ae8"><code>public inline</code><a href="#classMatMul_1afd77f3abc4bc600c045b74a634952ae8"><code>MatMul</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<p>MatMul의 생성자.</p>
<p>파라미터로 받은 pWeight와 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pWeight</code> MatMul할 weight. </p>
</li>
<li>
<p><code>pInput</code> Matmul할 input <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classMatMul_1aad34ca11b1ed37b103381f8ef204bef2">Alloc(Operator<DTYPE> *pWeight, Operator<DTYPE> *pInput)</a></p>
</li>
</ul>
<h4 id="classMatMul_1a3c436539092d145a8bd89a91285094f5"><code>public inline virtual</code><a href="#classMatMul_1a3c436539092d145a8bd89a91285094f5"><code>~MatMul</code></a><code>()</code></h4>
<p>MatMul의 소멸자</p>
<p>Delete매소드를 사용해 GPU에 할당했던 값들을 해제한다. void <a href="#classMatMul_1a45113c61efe47376cb0751d4a1106568">Delete()</a></p>
<h4 id="classMatMul_1aad34ca11b1ed37b103381f8ef204bef2"><code>public inline int</code><a href="#classMatMul_1aad34ca11b1ed37b103381f8ef204bef2"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<p>파라미터로 받은 pWeight, pInput으로 맴버 변수들을 초기화 한다.</p>
<p>timesize, batchsize, channelsize, row_size는 pInput의 Shape과 같게, colsize는 pWeight와 같게 초기화한다.</p>
<p>input x weight을 하기 때문에 rowsize는 pInput의 Shape을, colsize는 pWeight의 Shape을 받는다.</p>
<p>Result와 Delta를 저장하기 위해 input의 rowsize, weight의 colsize를 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pWeight</code> MatMul할 weight. </p>
</li>
<li>
<p><code>pInput</code> Matmul할 input <a href="#classOperator">Operator</a>. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classMatMul_1a45113c61efe47376cb0751d4a1106568"><code>public inline void</code><a href="#classMatMul_1a45113c61efe47376cb0751d4a1106568"><code>Delete</code></a><code>()</code></h4>
<p>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</p>
<p>inputTensorDesc, outputTensorDesc,deltaDesc, inputDeltaDesc, convDesc, filterDesc,filterDeltaDesc들을 삭제하고 NULL로 초기화한다.</p>
<p>m_devWorkSpace, m_dataDevWorkSpace, m_filterDevWorkSpace들이 가리키는 메모리를 해제한다.</p>
<h4 id="classMatMul_1a44c66bf3826370257a718bf974a2af68"><code>public inline virtual int</code><a href="#classMatMul_1a44c66bf3826370257a718bf974a2af68"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>MatMul의 ForwardPropagate매소드.</p>
<p>weight의 각 row의 값들과 input의 Colunm의 각 값들을 곱하여 result에 더한다.</p>
<p>[2 x 3] x [3 x 1]일때 3이 hiddensize </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classMatMul_1aebaeb2eee8735a3bdb1c7f2bc64a96a8"><code>public inline virtual int</code><a href="#classMatMul_1aebaeb2eee8735a3bdb1c7f2bc64a96a8"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>MatMul의 BackPropagate 매소드.</p>
<p>input_delta에 weight * this_delta값을 더해주고,</p>
<p>weight_gradient에는 input * this_delta값을 더해준다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classMaxpooling2D">class <code>Maxpooling2D</code><a class="headerlink" href="#classMaxpooling2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Maxpooling2D
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classMaxpooling2D_1a884f8b84ac999382d21ee08b3e040d17"><code>Maxpooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,std::string pName,int pLoadflag)</code></td>
<td>Maxpooling2D의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classMaxpooling2D_1a9ab7589f765b6e90625e0b7ff28120e9"><code>Maxpooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,int padding,std::string pName,int pLoadflag)</code></td>
<td>Maxpooling2D의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classMaxpooling2D_1a90ae8c88a3734949c60293a1c5f1a166"><code>~Maxpooling2D</code></a><code>()</code></td>
<td>Maxpooling2D의 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classMaxpooling2D_1adcff3829a9ac557ba6e1e5852696d8d8"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int strideRow,int strideCol,int maskRow,int maskCol,int padding1,int padding2)</code></td>
<td>파라미터로 받은 변수로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classMaxpooling2D_1a28058438060f1727637d4ad12b1b3fb7"><code>Delete</code></a><code>()</code></td>
<td>Delete 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classMaxpooling2D_1ac70d30d579150b568f3c24e9a35ce81f"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Maxpooling2D의 ForwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classMaxpooling2D_1ad9fbf7ae3ead0362607d12116c0e8bfe"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>Maxpooling2D의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classMaxpooling2D_1a884f8b84ac999382d21ee08b3e040d17"><code>public inline</code><a href="#classMaxpooling2D_1a884f8b84ac999382d21ee08b3e040d17"><code>Maxpooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,std::string pName,int pLoadflag)</code></h4>
<p>Maxpooling2D의 생성자</p>
<p>파라미터로 받은 pInput, strideRow, strideCol, maskRow, maskCol으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Maxpooling2D할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>maskRow</code> Filter의 Row size </p>
</li>
<li>
<p><code>maskCol</code> Filter의 Colunm size </p>
</li>
<li>
<p><code>strideRow</code> Row stirde값 </p>
</li>
<li>
<p><code>strideCol</code> Colunm stride값 </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름</p>
</li>
</ul>
<h4 id="classMaxpooling2D_1a9ab7589f765b6e90625e0b7ff28120e9"><code>public inline</code><a href="#classMaxpooling2D_1a9ab7589f765b6e90625e0b7ff28120e9"><code>Maxpooling2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int maskRow,int maskCol,int strideRow,int strideCol,int padding,std::string pName,int pLoadflag)</code></h4>
<p>Maxpooling2D의 생성자</p>
<p>파라미터로 받은 pInput, strideRow, strideCol, maskRow, maskCol으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Maxpooling2D할 대상 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>maskRow</code> Filter의 Row size </p>
</li>
<li>
<p><code>maskCol</code> Filter의 Colunm size </p>
</li>
<li>
<p><code>strideRow</code> Row stirde값 </p>
</li>
<li>
<p><code>strideCol</code> Colunm stride값 </p>
</li>
<li>
<p><code>padding</code> padding size </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름</p>
</li>
</ul>
<h4 id="classMaxpooling2D_1a90ae8c88a3734949c60293a1c5f1a166"><code>public inline</code><a href="#classMaxpooling2D_1a90ae8c88a3734949c60293a1c5f1a166"><code>~Maxpooling2D</code></a><code>()</code></h4>
<p>Maxpooling2D의 소멸자</p>
<h4 id="classMaxpooling2D_1adcff3829a9ac557ba6e1e5852696d8d8"><code>public inline int</code><a href="#classMaxpooling2D_1adcff3829a9ac557ba6e1e5852696d8d8"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int strideRow,int strideCol,int maskRow,int maskCol,int padding1,int padding2)</code></h4>
<p>파라미터로 받은 변수로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다.</p>
<p>m_stride, m_mask, m_padding값들을 초기화 하고 rowsize, colsize를 결정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>strideRow</code> Row stirde값. </p>
</li>
<li>
<p><code>strideCol</code> Colunm stride값. </p>
</li>
<li>
<p><code>maskRow</code> Filter의 Row size. </p>
</li>
<li>
<p><code>maskCol</code> Filter의 Colunm size. </p>
</li>
<li>
<p><code>padding1</code> row_padding 값. </p>
</li>
<li>
<p><code>padding2</code> col_padding 값. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classMaxpooling2D_1a28058438060f1727637d4ad12b1b3fb7"><code>public inline void</code><a href="#classMaxpooling2D_1a28058438060f1727637d4ad12b1b3fb7"><code>Delete</code></a><code>()</code></h4>
<p>Delete 메소드</p>
<p>cudnnDescriptor들을 GPU메모리에서 해제하고 포인터를 null로 초기화한다.</p>
<h4 id="classMaxpooling2D_1ac70d30d579150b568f3c24e9a35ce81f"><code>public inline virtual int</code><a href="#classMaxpooling2D_1ac70d30d579150b568f3c24e9a35ce81f"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Maxpooling2D의 ForwardPropagate 매소드.</p>
<p>Filter(temprow * tempcol)의 범위 중 가장 큰 값을 result에 저장하고, index는 indexOfMaxInput에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classMaxpooling2D_1ad9fbf7ae3ead0362607d12116c0e8bfe"><code>public inline virtual int</code><a href="#classMaxpooling2D_1ad9fbf7ae3ead0362607d12116c0e8bfe"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>Maxpooling2D의 BackPropagate 매소드.</p>
<p>계산한 delta값을 input_delta에 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classModule">class <code>Module</code><a class="headerlink" href="#classModule" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Module
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p>구성해 모듈화하는 클래스</p>
<p>Operator들을 뉴럴 네트워크의 서브 그래프로 구성해 단일 Operator로서 할 수 없는 기능들을 수행하게 한다</p>
<p>Module은 하나의 Operator처럼 뉴럴 네트워크 안에서 작동한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classModule_1ab8bf888e5ed0b51674053f4f3012b777"><code>Module</code></a><code>(std::string pName)</code></td>
<td><a href="#classModule">Module</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classModule_1a45761c15cc79e282993449230e534884"><code>~Module</code></a><code>()</code></td>
<td><a href="#classModule">Module</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a99353f5e7c249dcc0ce475c46998f962"><code>SetInput</code></a><code>(int pNumOfInput,...)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a4cf759005542d3d8b0f4d69636fa03c7"><code>SetInput</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a6ecb67a59936e89ad89eced365697213"><code>SetParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a823107d07bf30b0e83c9f08ec96db88c"><code>SetExecutableOperater</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pExecutableOperater)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classModule_1ae04c0f219dfa387c73a460a8ed5fe523"><code>IsInput</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td>해당 Operator가 Module의 Input인지 확인하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classModule_1a8e3d501cd75cb65608108d0eef9c6c7c"><code>IsValid</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td>해당 Operator의 Output Operator들이 모듈 그래프에 중복으로 포함되는 지 확인하는 메소드</td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614"><code>AnalyzeGraph</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pResultOperator)</code></td>
<td>학습 가능한 형태로 모듈 그래프를 구성해주는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classModule_1aab82adebc4238c1ebe731a47c975ba92"><code>FeedInputTensor</code></a><code>(int pNumOfInput,...)</code></td>
<td>신경망에 Input 리스트를 추가하는 메소드</td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1aa32d7ec18eb178a4ad00009bc71b98fa"><code>GetExcutableOperatorContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classModule_1ad47616271ad57492c19e937f4d9bb539"><code>GetNumOfExcutableOperator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1acbe814aa648ece32c4f6ea5f4421bdf0"><code>GetResult</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1aad4a03f8d46feda2213d5285ce00a1de"><code>GetResultContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a599a20137470952839e61b0860dc7109"><code>GetGradient</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1afdcf83fc8ccbcf6a5f77cd95799ec4d3"><code>GetGradientContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a14084c16219f9e53908427229702a3d8"><code>GetDelta</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1ae9735791ddce3b989262c825e2078f70"><code>GetDeltaContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1a6aff064f12e13edc59a8b6c12d6d7af8"><code>GetParameterContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1a5bd36cbe8d7bb82ba7dc93a84a37948b"><code>GetParameter</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1ac1224ac02d8c0d36f739a17232bb64da"><code>SetIsTensorholder</code></a><code>(int pIsParameter)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a32a996291f7465b8596ebe61f18f682a"><code>SetIsTrainable</code></a><code>(int pIsTrainable)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a746ba9e663c2b56854c26a53cb5bd554"><code>SetModeTrain</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a93d4a4c2cc70fc27f1c7e9d98451fa0e"><code>SetModeAccumulate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a5fadf1f06188eeaa07f59f23b094e098"><code>SetModeInference</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a1bea4bd0b2831e0c21696998393cc263"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>모듈 그래프의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a561a89214a6252632cbc507ef6e35b58"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>모듈 그래프의 역전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a3f82395e6c6063bc8d70cf1e0fe48260"><code>ResetResult</code></a><code>()</code></td>
<td>연산에 참여하는 Operator들의 Result Container를 초기화시킨다.</td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a498ecc0aebdc2e1d47d15ed1d3a34190"><code>ResetGradient</code></a><code>()</code></td>
<td>연산에 참여하는 Operator들의 Gradient Container를 초기화시킨다.</td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classModule_1a1fe0649b5922714869c9727e6e48af86"><code>PrintInformation</code></a><code>(int level)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classModule_1a002890bc0726abfe5807ed7fdc2b7009"><code>SetDeviceCPU</code></a><code>()</code></td>
<td>모듈 그래프 학습에 사용되는 장치를 CPU로 전환하는 메소드</td>
</tr>
<tr>
<td><code>public void</code><a href="#classModule_1afebb7db4c54e6405cb2a9fabf7ec4014"><code>SetDeviceCPUOnModule</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1ab932898db0934f08b11e58c527a21d3e"><code>Save</code></a><code>(char * nameOfFile)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a533bb3a09eaaf78f468a8714f5897dd4"><code>Load</code></a><code>(char * nameOfFile)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a8d201e11894e203c26443830059247f4"><code>Save</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1ae72b4ff6dca516608f7e86cedc707b97"><code>Load</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1a4e7ab899a27e1f29c16d12e12ce51c5f"><code>SaveComponents</code></a><code>(char * nameOfDir)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classModule_1af089e75acd169b00241e3b33b9406da5"><code>LoadComponents</code></a><code>(char * nameOfDir)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classModule_1ab8bf888e5ed0b51674053f4f3012b777"><code>public</code><a href="#classModule_1ab8bf888e5ed0b51674053f4f3012b777"><code>Module</code></a><code>(std::string pName)</code></h4>
<p><a href="#classModule">Module</a> 클래스 생성자</p>
<p>각 멤버 변수들을 초기화하고 <a href="#classModule">Module</a> 클래스를 생성한다.</p>
<p>각 포인터들을 NULL 값으로, 각 정수 타입 변수들은 0으로 초기화하고 Module<DTYPE>::Alloc() 메소드를 호출한다. 
<strong>See also</strong>: Module<DTYPE>::Alloc() </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classModule_1a45761c15cc79e282993449230e534884"><code>public virtual</code><a href="#classModule_1a45761c15cc79e282993449230e534884"><code>~Module</code></a><code>()</code></h4>
<p><a href="#classModule">Module</a> 클래스 소멸자</p>
<p>동적으로 할당 받은 <a href="#classModule">Module</a> 클래스의 멤버 변수들을 할당 해제하고 클래스를 소멸시킨다. </p>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Module<DTYPE>::Delete()</p>
<h4 id="classModule_1a99353f5e7c249dcc0ce475c46998f962"><code>public virtual int</code><a href="#classModule_1a99353f5e7c249dcc0ce475c46998f962"><code>SetInput</code></a><code>(int pNumOfInput,...)</code></h4>
<h4 id="classModule_1a4cf759005542d3d8b0f4d69636fa03c7"><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a4cf759005542d3d8b0f4d69636fa03c7"><code>SetInput</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<h4 id="classModule_1a6ecb67a59936e89ad89eced365697213"><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a6ecb67a59936e89ad89eced365697213"><code>SetParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<h4 id="classModule_1a823107d07bf30b0e83c9f08ec96db88c"><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a823107d07bf30b0e83c9f08ec96db88c"><code>SetExecutableOperater</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pExecutableOperater)</code></h4>
<h4 id="classModule_1ae04c0f219dfa387c73a460a8ed5fe523"><code>public int</code><a href="#classModule_1ae04c0f219dfa387c73a460a8ed5fe523"><code>IsInput</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<p>해당 Operator가 Module의 Input인지 확인하는 메소드</p>
<p>매개변수로 받은 Operator가 Module의 Input Container에 포함되어 있는 지 확인한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pOperator</code> Input 여부를 확인하고자 하는 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>Input container에 포함되어 있는 경우 TRUE, 포함되어 있지 않는 경우 FALSE를 반환한다.</p>
<h4 id="classModule_1a8e3d501cd75cb65608108d0eef9c6c7c"><code>public int</code><a href="#classModule_1a8e3d501cd75cb65608108d0eef9c6c7c"><code>IsValid</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<p>해당 Operator의 Output Operator들이 모듈 그래프에 중복으로 포함되는 지 확인하는 메소드</p>
<p>해당 Operator의 Output container 멤버 변수에 담겨 있는 Operator들이 Module의 Excutable <a href="#classOperator">Operator</a> container에 중복되어 포함되어 있는 지 여부를 확인한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pOperator</code> Output <a href="#classContainer">Container</a> 멤버 변수가 Excutable <a href="#classOperator">Operator</a> Container에 포함되어 있는 지 확인하고자 하는 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>해당 Operator의 Output <a href="#classContainer">Container</a> 멤버 변수가 Excutable <a href="#classOperator">Operator</a> Container에 중복되어 포함되어 있으면 TRUE를 아니면 FALSE를 반환한다.</p>
<h4 id="classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614"><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614"><code>AnalyzeGraph</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pResultOperator)</code></h4>
<p>학습 가능한 형태로 모듈 그래프를 구성해주는 메소드</p>
<p>모듈의 Output에 해당하는 Operator를 매개변수로 받아 너비 우선 탐색으로 모듈 그래프를 구성한다.</p>
<p>매개변수로 받은 모듈의 Output에 해당하는 Operator를 시작으로 모듈의 Input에 해당하는 Operator까지 역순으로, Operator가 Input <a href="#classTensor">Tensor</a> 및 학습 파라미터인 경우 <a href="#classModule">Module</a> 클래스의 Input <a href="#classContainer">Container</a> 멤버 변수에 추가하고 나머지 경우에는 <a href="#classModule">Module</a> 클래스의 Excutable <a href="#classOperator">Operator</a><a href="#classContainer">Container</a> 멤버 변수에 추가한다.</p>
<p><a href="#classNeuralNetwork">NeuralNetwork</a> 클래스의 Excutable <a href="#classOperator">Operator</a><a href="#classContainer">Container</a> 멤버 변수에 Operator들이 모두 추가되면 Container를 역순으로 변경한다.</p>
<p><a href="#classOperator">Operator</a> 탐색 순서는 너비 우선 탐색을 따르며, 매개변수로 받은 Output Operator부터 해당 Operator의 Input <a href="#classOperator">Operator</a> 리스트를 너비 우선 탐색 방식을 이용해 순서대로 진행한다.</p>
<p>각 Operator들은 <a href="#classModule_1a8e3d501cd75cb65608108d0eef9c6c7c">Module<DTYPE>::IsValid(Operator<DTYPE> *pOperator)</a> 메소드를 이용하여 모듈 그래프 안에서의 중복 여부를 확인하며 중복되는 경우 그래프에 추가하지 않는다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pResultOperator</code> 그래프를 구성하고자 하는 신경망의 Output에 해당하는 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>매개변수로 받은 그래프를 구성하고자 하는 신경망의 Output에 해당하는 <a href="#classOperator">Operator</a></p>
<h4 id="classModule_1aab82adebc4238c1ebe731a47c975ba92"><code>public int</code><a href="#classModule_1aab82adebc4238c1ebe731a47c975ba92"><code>FeedInputTensor</code></a><code>(int pNumOfInput,...)</code></h4>
<p>신경망에 Input 리스트를 추가하는 메소드</p>
<p>매개변수로 받은 Tensor들을 순서대로 NeuralNetwork의 Input Container에 담겨 있는 Operator들의 Result로 설정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pNumOfInput</code> Input Container에 추가하고 싶은 Tensor들의 개수 </p>
</li>
<li>
<p><code>...</code> Input Container에 추가하고 싶은 Tensor들의 리스트 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: Operator<DTYPE>::SetResult(Tensor<DTYPE> *pTensor)</p>
<h4 id="classModule_1aa32d7ec18eb178a4ad00009bc71b98fa"><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1aa32d7ec18eb178a4ad00009bc71b98fa"><code>GetExcutableOperatorContainer</code></a><code>()</code></h4>
<h4 id="classModule_1ad47616271ad57492c19e937f4d9bb539"><code>public int</code><a href="#classModule_1ad47616271ad57492c19e937f4d9bb539"><code>GetNumOfExcutableOperator</code></a><code>()</code></h4>
<h4 id="classModule_1acbe814aa648ece32c4f6ea5f4421bdf0"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1acbe814aa648ece32c4f6ea5f4421bdf0"><code>GetResult</code></a><code>() const</code></h4>
<h4 id="classModule_1aad4a03f8d46feda2213d5285ce00a1de"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1aad4a03f8d46feda2213d5285ce00a1de"><code>GetResultContainer</code></a><code>()</code></h4>
<h4 id="classModule_1a599a20137470952839e61b0860dc7109"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a599a20137470952839e61b0860dc7109"><code>GetGradient</code></a><code>() const</code></h4>
<h4 id="classModule_1afdcf83fc8ccbcf6a5f77cd95799ec4d3"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1afdcf83fc8ccbcf6a5f77cd95799ec4d3"><code>GetGradientContainer</code></a><code>()</code></h4>
<h4 id="classModule_1a14084c16219f9e53908427229702a3d8"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classModule_1a14084c16219f9e53908427229702a3d8"><code>GetDelta</code></a><code>() const</code></h4>
<h4 id="classModule_1ae9735791ddce3b989262c825e2078f70"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1ae9735791ddce3b989262c825e2078f70"><code>GetDeltaContainer</code></a><code>()</code></h4>
<h4 id="classModule_1a6aff064f12e13edc59a8b6c12d6d7af8"><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1a6aff064f12e13edc59a8b6c12d6d7af8"><code>GetParameterContainer</code></a><code>()</code></h4>
<h4 id="classModule_1a5bd36cbe8d7bb82ba7dc93a84a37948b"><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classModule_1a5bd36cbe8d7bb82ba7dc93a84a37948b"><code>GetParameter</code></a><code>()</code></h4>
<h4 id="classModule_1ac1224ac02d8c0d36f739a17232bb64da"><code>public virtual int</code><a href="#classModule_1ac1224ac02d8c0d36f739a17232bb64da"><code>SetIsTensorholder</code></a><code>(int pIsParameter)</code></h4>
<h4 id="classModule_1a32a996291f7465b8596ebe61f18f682a"><code>public virtual int</code><a href="#classModule_1a32a996291f7465b8596ebe61f18f682a"><code>SetIsTrainable</code></a><code>(int pIsTrainable)</code></h4>
<h4 id="classModule_1a746ba9e663c2b56854c26a53cb5bd554"><code>public virtual int</code><a href="#classModule_1a746ba9e663c2b56854c26a53cb5bd554"><code>SetModeTrain</code></a><code>()</code></h4>
<h4 id="classModule_1a93d4a4c2cc70fc27f1c7e9d98451fa0e"><code>public virtual int</code><a href="#classModule_1a93d4a4c2cc70fc27f1c7e9d98451fa0e"><code>SetModeAccumulate</code></a><code>()</code></h4>
<h4 id="classModule_1a5fadf1f06188eeaa07f59f23b094e098"><code>public virtual int</code><a href="#classModule_1a5fadf1f06188eeaa07f59f23b094e098"><code>SetModeInference</code></a><code>()</code></h4>
<h4 id="classModule_1a1bea4bd0b2831e0c21696998393cc263"><code>public virtual int</code><a href="#classModule_1a1bea4bd0b2831e0c21696998393cc263"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>모듈 그래프의 순전파를 수행하는 메소드</p>
<p>Excutable <a href="#classOperator">Operator</a> Container의 각 Operator들에서 Operator<DTYPE>::ForwardPropagate(int pTime) 메소드를 순서대로 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 각 ForwardPropagate 메소드에 전달할 Time의 인덱스 </li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classModule_1a561a89214a6252632cbc507ef6e35b58"><code>public virtual int</code><a href="#classModule_1a561a89214a6252632cbc507ef6e35b58"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>모듈 그래프의 역전파를 수행하는 메소드</p>
<p>역순으로 Excutable <a href="#classOperator">Operator</a> Container의 각 Operator들에서 Operator<DTYPE>::ForwardPropagate(int pTime) 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 각 ForwardPropagate 메소드에 전달할 Time의 인덱스 </li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classModule_1a3f82395e6c6063bc8d70cf1e0fe48260"><code>public virtual int</code><a href="#classModule_1a3f82395e6c6063bc8d70cf1e0fe48260"><code>ResetResult</code></a><code>()</code></h4>
<p>연산에 참여하는 Operator들의 Result Container를 초기화시킨다.</p>
<p>Excutable <a href="#classOperator">Operator</a> Container에 포함되어 있는 각 Operator들에서 Operator<DTYPE>::ResetResult() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classModule_1a498ecc0aebdc2e1d47d15ed1d3a34190"><code>public virtual int</code><a href="#classModule_1a498ecc0aebdc2e1d47d15ed1d3a34190"><code>ResetGradient</code></a><code>()</code></h4>
<p>연산에 참여하는 Operator들의 Gradient Container를 초기화시킨다.</p>
<p>Excutable <a href="#classOperator">Operator</a> Container에 포함되어 있는 각 Operator들에서 Operator<DTYPE>::ResetGradient() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classModule_1a1fe0649b5922714869c9727e6e48af86"><code>public virtual void</code><a href="#classModule_1a1fe0649b5922714869c9727e6e48af86"><code>PrintInformation</code></a><code>(int level)</code></h4>
<h4 id="classModule_1a002890bc0726abfe5807ed7fdc2b7009"><code>public virtual void</code><a href="#classModule_1a002890bc0726abfe5807ed7fdc2b7009"><code>SetDeviceCPU</code></a><code>()</code></h4>
<p>모듈 그래프 학습에 사용되는 장치를 CPU로 전환하는 메소드</p>
<p>Module의 Device 멤버변수를 CPU로 전환하고, Excutable <a href="#classOperator">Operator</a> Container의 각 Operator들에서 Operator<DTYPE>::SetDeviceCPU() 메소드를 순서대로 호출한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classModule_1afebb7db4c54e6405cb2a9fabf7ec4014"><code>public void</code><a href="#classModule_1afebb7db4c54e6405cb2a9fabf7ec4014"><code>SetDeviceCPUOnModule</code></a><code>()</code></h4>
<h4 id="classModule_1ab932898db0934f08b11e58c527a21d3e"><code>public virtual int</code><a href="#classModule_1ab932898db0934f08b11e58c527a21d3e"><code>Save</code></a><code>(char * nameOfFile)</code></h4>
<h4 id="classModule_1a533bb3a09eaaf78f468a8714f5897dd4"><code>public virtual int</code><a href="#classModule_1a533bb3a09eaaf78f468a8714f5897dd4"><code>Load</code></a><code>(char * nameOfFile)</code></h4>
<h4 id="classModule_1a8d201e11894e203c26443830059247f4"><code>public virtual int</code><a href="#classModule_1a8d201e11894e203c26443830059247f4"><code>Save</code></a><code>(FILE * fp)</code></h4>
<h4 id="classModule_1ae72b4ff6dca516608f7e86cedc707b97"><code>public virtual int</code><a href="#classModule_1ae72b4ff6dca516608f7e86cedc707b97"><code>Load</code></a><code>(FILE * fp)</code></h4>
<h4 id="classModule_1a4e7ab899a27e1f29c16d12e12ce51c5f"><code>public virtual int</code><a href="#classModule_1a4e7ab899a27e1f29c16d12e12ce51c5f"><code>SaveComponents</code></a><code>(char * nameOfDir)</code></h4>
<h4 id="classModule_1af089e75acd169b00241e3b33b9406da5"><code>public virtual int</code><a href="#classModule_1af089e75acd169b00241e3b33b9406da5"><code>LoadComponents</code></a><code>(char * nameOfDir)</code></h4>
<hr />
<h2 id="classMSE">class <code>MSE</code><a class="headerlink" href="#classMSE" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class MSE
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<p>Squared Error) Metric를 이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</p>
<p><a href="#classMSE">MSE(Mean Squared Error)</a> 계산 식을 이용해 뉴럴 네트워크의 순전파를 통해 계산된 출력 Tensor와 레이블 값의 손실 함수를 계산한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classMSE_1abb2d56ecf64d8e9d173912bba69e1e41"><code>MSE</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td><a href="#classMSE">MSE(Mean Squared Error)</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classMSE_1a1fa27e77c38d0cfaf93317494d5f71c2"><code>~MSE</code></a><code>()</code></td>
<td><a href="#classMSE">MSE(Mean Squared Error)</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classMSE_1a70cb2a38095ef6da239ccee54d8464b6"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 멤버 변수들을 동적 할당하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classMSE_1ae6cc6fffb56cc7ff699718451d446140"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classMSE_1a90e2d9b6a762af5caaf9da8e8f611e80"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 역전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classMSE_1a2259437b634090e2e74f44254f5276d8"><code>Error</code></a><code>(DTYPE pred,DTYPE ans)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classMSE_1abb2d56ecf64d8e9d173912bba69e1e41"><code>public inline</code><a href="#classMSE_1abb2d56ecf64d8e9d173912bba69e1e41"><code>MSE</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<p><a href="#classMSE">MSE(Mean Squared Error)</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator를 매개변수로 전달하여 <a href="#classMSE_1a70cb2a38095ef6da239ccee54d8464b6">MSE<DTYPE>::Alloc(Operator<DTYPE> *pOperator)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classMSE_1a70cb2a38095ef6da239ccee54d8464b6">MSE<DTYPE>::Alloc(Operator<DTYPE> *pOperator)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classMSE_1a70cb2a38095ef6da239ccee54d8464b6">MSE<DTYPE>::Alloc(Operator<DTYPE> *pOperator)</a></p>
<h4 id="classMSE_1a1fa27e77c38d0cfaf93317494d5f71c2"><code>public inline virtual</code><a href="#classMSE_1a1fa27e77c38d0cfaf93317494d5f71c2"><code>~MSE</code></a><code>()</code></h4>
<p><a href="#classMSE">MSE(Mean Squared Error)</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classMSE_1a70cb2a38095ef6da239ccee54d8464b6"><code>public inline virtual int</code><a href="#classMSE_1a70cb2a38095ef6da239ccee54d8464b6"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<p><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 멤버 변수들을 동적 할당하는 메소드</p>
<p>매개변수로 전달받은 Operator를 Input Operator에 할당하고 초기화 된 Result 텐서를 동적으로 할당 및 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pOperator</code> <a href="#classMSE">MSE</a> LossFunction의 입력에 해당하는 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classMSE_1ae6cc6fffb56cc7ff699718451d446140"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classMSE_1ae6cc6fffb56cc7ff699718451d446140"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 순전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 결과 값을 레이블 값과 비교해 Mse(Mean Squared Error)를 구한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>뉴럴 네트워크의 결과 값에 대한 <a href="#classMSE">MSE(Mean Squared Error)</a></p>
<h4 id="classMSE_1a90e2d9b6a762af5caaf9da8e8f611e80"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classMSE_1a90e2d9b6a762af5caaf9da8e8f611e80"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classMSE">MSE(Mean Squared Error)</a> LossFunction의 역전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 <a href="#classMSE">MSE(Mean Squared Error)</a>에 대한 입력 Tensor의 Gradient를 계산한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classMSE_1a2259437b634090e2e74f44254f5276d8"><code>public inline DTYPE</code><a href="#classMSE_1a2259437b634090e2e74f44254f5276d8"><code>Error</code></a><code>(DTYPE pred,DTYPE ans)</code></h4>
<hr />
<h2 id="classNagOptimizer">class <code>NagOptimizer</code><a class="headerlink" href="#classNagOptimizer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class NagOptimizer
  : public Optimizer&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classNagOptimizer_1a750cdedf0a089eb87691a76ce6e0969b"><code>NagOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,OptimizeDirection pOptimizeDirection)</code></td>
<td>NagOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classNagOptimizer_1a990cfcecd6d15f27cb0574e58fd44913"><code>NagOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td>NagOptimizer의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classNagOptimizer_1afc95f34429bdd9679b1bfc13e291e5ed"><code>~NagOptimizer</code></a><code>()</code></td>
<td>NagOptimizer의 소멸자</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classNagOptimizer_1a42d3725f2f08127b154dcab46a9c970c"><code>Delete</code></a><code>()</code></td>
<td>Optimizer의 Delete 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classNagOptimizer_1a1eb291e54867352b01ca57c3da27d14b"><code>Alloc</code></a><code>(float momentum)</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classNagOptimizer_1aeb0295ed90b6752805136838910d2ce5"><code>UpdateParameter</code></a><code>()</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classNagOptimizer_1a58a02e3959b18c588ff7629766375c3d"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td>UpdateParameter default 함수</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classNagOptimizer_1a4ac96ef206ce18f94570dfb6373b259f"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pVelocity)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classNagOptimizer_1a750cdedf0a089eb87691a76ce6e0969b"><code>public inline</code><a href="#classNagOptimizer_1a750cdedf0a089eb87691a76ce6e0969b"><code>NagOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,OptimizeDirection pOptimizeDirection)</code></h4>
<p>NagOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>momentum</code> step size 조정 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(momentum)</p>
<h4 id="classNagOptimizer_1a990cfcecd6d15f27cb0574e58fd44913"><code>public inline</code><a href="#classNagOptimizer_1a990cfcecd6d15f27cb0574e58fd44913"><code>NagOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float momentum,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p>NagOptimizer의 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>m_momentum</code> step size 조정 값 </p>
</li>
<li>
<p><code>weightDecayRate</code> 가중치 매개변수가 클 때 패널티를 부과하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(momentum)</p>
<h4 id="classNagOptimizer_1afc95f34429bdd9679b1bfc13e291e5ed"><code>public inline</code><a href="#classNagOptimizer_1afc95f34429bdd9679b1bfc13e291e5ed"><code>~NagOptimizer</code></a><code>()</code></h4>
<p>NagOptimizer의 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classNagOptimizer_1a42d3725f2f08127b154dcab46a9c970c"><code>public inline virtual void</code><a href="#classNagOptimizer_1a42d3725f2f08127b154dcab46a9c970c"><code>Delete</code></a><code>()</code></h4>
<p>Optimizer의 Delete 매소드</p>
<p>맴버 변수 m_aaVelocity의 메모리 할당을 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classNagOptimizer_1a1eb291e54867352b01ca57c3da27d14b"><code>public inline int</code><a href="#classNagOptimizer_1a1eb291e54867352b01ca57c3da27d14b"><code>Alloc</code></a><code>(float momentum)</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_ppParameter, m_numOfParameter, m_aaVelocity를 초기화한다.</p>
<p>m_aaVelocity를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다. </p>
<h5>Parameters</h5>
<ul>
<li><code>m_momentum</code> step size 조정 값 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: <a href="#classContainer">Container</a>&lt;<a href="#classOperator">Operator<DTYPE></a> <em>&gt;</em> GetTrainableTensor() </p>
<p><strong>See also</strong>: int GetTrainableTensorDegree()</p>
<h4 id="classNagOptimizer_1aeb0295ed90b6752805136838910d2ce5"><code>public inline virtual int</code><a href="#classNagOptimizer_1aeb0295ed90b6752805136838910d2ce5"><code>UpdateParameter</code></a><code>()</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_momentum 유무에 따라 UpdateParameter 호출과 에러 메세지 호출 </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classNagOptimizer_1aeb0295ed90b6752805136838910d2ce5">UpdateParameter</a>((<a href="#classOperator">Operator<DTYPE></a> *pParameter, <a href="#classTensor">Tensor<DTYPE></a> *pVelocity)</p>
<h4 id="classNagOptimizer_1a58a02e3959b18c588ff7629766375c3d"><code>public inline virtual int</code><a href="#classNagOptimizer_1a58a02e3959b18c588ff7629766375c3d"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<p>UpdateParameter default 함수</p>
<h5>Parameters</h5>
<ul>
<li><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classNagOptimizer_1a4ac96ef206ce18f94570dfb6373b259f"><code>public inline int</code><a href="#classNagOptimizer_1a4ac96ef206ce18f94570dfb6373b259f"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pVelocity)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>prev_Velocity 텐서 생성 후 현재 pVelocity 저장</p>
<p>pVelocity를 Update 한다.</p>
<p>m_momentum 값으로 조정된 prev_Velocity와 pVelocity의 연산으로 파라미터 Update</p>
<p>학습 초반 부, pFirstMomentum, pFirstVelocity는 0으로 biased 상태이므로 이를 unbiased 해주는 연산하여 업데이트 한다.</p>
<p>signed_learning_rate와 pUnbiasedMomentum곱을 root가 적용된 pUnbiasedVelocity와 m_epsilon으로 나눈 값으로 weight(trainable_data)를 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pVelocity</code> 업데이트 할 pVelocity </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<hr />
<h2 id="classNeuralNetwork">class <code>NeuralNetwork</code><a class="headerlink" href="#classNeuralNetwork" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class NeuralNetwork
  : public Module&lt; DTYPE &gt;
</code></pre></div>

<p>모델 생성, 학습 및 평가를 총괄하는 클래스</p>
<p><a href="#classOperator">Operator</a>, <a href="#classModule">Module</a>, Loss Function, <a href="#classOptimizer">Optimizer</a> 클래스를 생성 및 활용해 뉴럴 네트워크를 구성하고 학습시킨다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classNeuralNetwork_1a20d3f6e11c5829f2cd33a5201d730f15"><code>NeuralNetwork</code></a><code>()</code></td>
<td><a href="#classNeuralNetwork">NeuralNetwork</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classNeuralNetwork_1a3a18db7bfba7c6b8c00cd8c3c227b9cf"><code>~NeuralNetwork</code></a><code>()</code></td>
<td><a href="#classNeuralNetwork">NeuralNetwork</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a0f17e2c4a002186a336bb1c80e789a03"><code>SetLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pLossFunction)</code></td>
<td>특정 Loss Function을 매개 변수로 받아 이를 신경망의 Loss Function로 지정해주는 메소드</td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a8324e148cc31f3fbb81667287bb4ee61"><code>SetOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pOptimizer)</code></td>
<td>특정 Optimizer를 매개 변수로 받아 이를 신경망의 Optimizer로 지정해주는 메소드</td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a47ed18a44570c4868339187aebe0e3c9"><code>GetResultOperator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1aa00549772d4d9b5555cc123cd463638d"><code>GetResult</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1ad54e92ce0198b90a4fba80c8f0fe4258"><code>GetLossFunction</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a98292f1272832febf221f2660673b60c"><code>GetOptimizer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classNeuralNetwork_1a58c83f661d1afc455fa6a848d238e823"><code>SetDeviceCPU</code></a><code>()</code></td>
<td>신경망 그래프 학습에 사용되는 장치를 CPU로 전환하는 메소드</td>
</tr>
<tr>
<td><code>public void</code><a href="#classNeuralNetwork_1a411566bb635a12dbbb67fa38af7eb10f"><code>SetDeviceCPUOnNeuralNetwork</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a9f60df7d21b76fc1a194bfc7f5857ebd"><code>Train</code></a><code>()</code></td>
<td>신경망의 학습을 진행하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1ad38d080bc60559e6f37ac3006dea1bb6"><code>Test</code></a><code>()</code></td>
<td>신경망의 테스트를 진행하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a6527833265b19ba3d2aaf755ea0fdfa3"><code>TrainOnCPU</code></a><code>()</code></td>
<td>CPU를 활용해 신경망을 학습시키는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a16bd0b041c7055340b0ef11bc95a59bf"><code>TestOnCPU</code></a><code>()</code></td>
<td>CPU를 활용해 신경망을 테스트하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1ac6a18d638c34093a325ef4e09dbc2978"><code>TrainOnGPU</code></a><code>()</code></td>
<td>GPU를 활용해 신경망을 학습시키는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1afcdc8ca3b16f063b4d67c3e4b72d5ee0"><code>TestOnGPU</code></a><code>()</code></td>
<td>GPU를 활용해 신경망을 테스트하는 메소드</td>
</tr>
<tr>
<td><code>public float</code><a href="#classNeuralNetwork_1a3562597ed1ba1d43eae487a699bcf91a"><code>GetAccuracy</code></a><code>(int numOfClass)</code></td>
<td>분류(Classification)를 위해 학습된 신경망의 Top 1 Accuracy를 계산하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a82da1af0e953ca99fff74684802dcd33"><code>GetMaxIndex</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * data,int ba,int ti,int numOfClass)</code></td>
<td>Tensor의 LongArray의 Element들 중 가장 큰 값의 인덱스를 계산해 반환하는 메소드</td>
</tr>
<tr>
<td><code>public float</code><a href="#classNeuralNetwork_1a8b2e1e719ed1429aed9f425d228937fb"><code>GetTop5Accuracy</code></a><code>(int numOfClass)</code></td>
<td>분류(Classification)를 위해 학습된 신경망의 Top 5 Accuracy를 계산하는 메소드</td>
</tr>
<tr>
<td><code>public void</code><a href="#classNeuralNetwork_1aa068fb156df1718020f9ada53eb2cb38"><code>GetTop5Index</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * data,int * top5Index,int ba,int ti,int numOfClass)</code></td>
<td>Tensor의 LongArray의 Element들 중 가장 큰 다섯 개 값에 대한 인덱스를 계산해 반환하는 메소드</td>
</tr>
<tr>
<td><code>public float</code><a href="#classNeuralNetwork_1af33f9fefe93bbaf0dc87f5fac6632539"><code>GetLoss</code></a><code>()</code></td>
<td>데이터에 대해 학습된 신경망의 평균 Loss를 계산하여 반환하는 메소드</td>
</tr>
<tr>
<td><code>public void</code><a href="#classNeuralNetwork_1a8c2e90c65b99b7da8a4cf1ee70c7d479"><code>PrintGraphInformation</code></a><code>()</code></td>
<td>신경망 그래프의 각 구성 요소에 대해 정보를 출력하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278"><code>ResetLossFunctionResult</code></a><code>()</code></td>
<td>LossFunction의 Result Tensor를 초기화시킨다.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a5e3c7ae5f4717a80089ccb89772394d3"><code>ResetLossFunctionGradient</code></a><code>()</code></td>
<td>LossFunction의 Gradient Tensor를 초기화시킨다.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classNeuralNetwork_1a4cb542f78efa4472bdcd317aa79087d6"><code>ResetParameterGradient</code></a><code>()</code></td>
<td>Optimizer의 Gradient와 Parameter들의 Gradient를 초기화시킨다.</td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a28f8478e6b84704f11b52cfa6c291a81"><code>SearchOperator</code></a><code>(std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classNeuralNetwork_1abb8436142f9031d3c7385b5a7f274442"><code>InputToFeature</code></a><code>(int inDim,int noSample,float * pSamples,int outDim,float * pFeatures,int batchSize)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classNeuralNetwork_1a20d3f6e11c5829f2cd33a5201d730f15"><code>public</code><a href="#classNeuralNetwork_1a20d3f6e11c5829f2cd33a5201d730f15"><code>NeuralNetwork</code></a><code>()</code></h4>
<p><a href="#classNeuralNetwork">NeuralNetwork</a> 클래스 생성자</p>
<p>각 멤버 변수들을 초기화하고 <a href="#classNeuralNetwork">NeuralNetwork</a> 클래스를 생성한다.</p>
<p>각 포인터들을 NULL 값으로, 각 정수 타입 변수들은 0으로, Device는 CPU로 초기화하고 NeuralNetwork<DTYPE>::Alloc() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::Alloc()</p>
<h4 id="classNeuralNetwork_1a3a18db7bfba7c6b8c00cd8c3c227b9cf"><code>public virtual</code><a href="#classNeuralNetwork_1a3a18db7bfba7c6b8c00cd8c3c227b9cf"><code>~NeuralNetwork</code></a><code>()</code></h4>
<p><a href="#classNeuralNetwork">NeuralNetwork</a> 클래스 소멸자</p>
<p>동적으로 할당 받은 <a href="#classNeuralNetwork">NeuralNetwork</a> 클래스의 멤버 변수들을 할당 해제하고 클래스를 소멸시킨다. </p>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::Delete()</p>
<h4 id="classNeuralNetwork_1a0f17e2c4a002186a336bb1c80e789a03"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a0f17e2c4a002186a336bb1c80e789a03"><code>SetLossFunction</code></a><code>(</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; * pLossFunction)</code></h4>
<p>특정 Loss Function을 매개 변수로 받아 이를 신경망의 Loss Function로 지정해주는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pLossFunction</code> 신경망의 Loss Function로 지정하고자 하는 Loss Function </li>
</ul>
<h5>Returns</h5>
<p>매개변수로 받은 Loss Function</p>
<h4 id="classNeuralNetwork_1a8324e148cc31f3fbb81667287bb4ee61"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a8324e148cc31f3fbb81667287bb4ee61"><code>SetOptimizer</code></a><code>(</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; * pOptimizer)</code></h4>
<p>특정 Optimizer를 매개 변수로 받아 이를 신경망의 Optimizer로 지정해주는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pLossFunction</code> 신경망의 Optimizer로 지정하고자 하는 <a href="#classOptimizer">Optimizer</a></li>
</ul>
<h5>Returns</h5>
<p>매개변수로 받은 <a href="#classOptimizer">Optimizer</a></p>
<h4 id="classNeuralNetwork_1a47ed18a44570c4868339187aebe0e3c9"><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a47ed18a44570c4868339187aebe0e3c9"><code>GetResultOperator</code></a><code>()</code></h4>
<h4 id="classNeuralNetwork_1aa00549772d4d9b5555cc123cd463638d"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1aa00549772d4d9b5555cc123cd463638d"><code>GetResult</code></a><code>()</code></h4>
<h4 id="classNeuralNetwork_1ad54e92ce0198b90a4fba80c8f0fe4258"><code>public</code><a href="#classLossFunction"><code>LossFunction</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1ad54e92ce0198b90a4fba80c8f0fe4258"><code>GetLossFunction</code></a><code>()</code></h4>
<h4 id="classNeuralNetwork_1a98292f1272832febf221f2660673b60c"><code>public</code><a href="#classOptimizer"><code>Optimizer</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a98292f1272832febf221f2660673b60c"><code>GetOptimizer</code></a><code>()</code></h4>
<h4 id="classNeuralNetwork_1a58c83f661d1afc455fa6a848d238e823"><code>public virtual void</code><a href="#classNeuralNetwork_1a58c83f661d1afc455fa6a848d238e823"><code>SetDeviceCPU</code></a><code>()</code></h4>
<p>신경망 그래프 학습에 사용되는 장치를 CPU로 전환하는 메소드</p>
<p>NeuralNetwork의 Device 멤버변수를 CPU로 전환하고, Excutable <a href="#classOperator">Operator</a> Container의 각 Operator들에서 Operator<DTYPE>::SetDeviceCPU() 메소드를 순서대로 호출하고, Lossfunction의 LossFunction<DTYPE>::SetDeviceCPU() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classNeuralNetwork_1a411566bb635a12dbbb67fa38af7eb10f"><code>public void</code><a href="#classNeuralNetwork_1a411566bb635a12dbbb67fa38af7eb10f"><code>SetDeviceCPUOnNeuralNetwork</code></a><code>()</code></h4>
<h4 id="classNeuralNetwork_1a9f60df7d21b76fc1a194bfc7f5857ebd"><code>public int</code><a href="#classNeuralNetwork_1a9f60df7d21b76fc1a194bfc7f5857ebd"><code>Train</code></a><code>()</code></h4>
<p>신경망의 학습을 진행하는 메소드</p>
<p>NeuralNetwork의 Device 멤버 변수를 확인하여 CPU 시 NeuralNetwork<DTYPE>::TrainingOnCPU()을 호출하고, GPU 시 NeuralNetwork<DTYPE>::TrainingOnGPU()을 호출한다. </p>
<h5>Returns</h5>
<p>성공 시 TRUE, m_Device 멤버 변수가 잘못된 값을 갖고 있을 때 FALSE를 반환한다.</p>
<h4 id="classNeuralNetwork_1ad38d080bc60559e6f37ac3006dea1bb6"><code>public int</code><a href="#classNeuralNetwork_1ad38d080bc60559e6f37ac3006dea1bb6"><code>Test</code></a><code>()</code></h4>
<p>신경망의 테스트를 진행하는 메소드</p>
<p>NeuralNetwork의 Device 멤버 변수를 확인하여 CPU 시 NeuralNetwork<DTYPE>::TestingOnCPU()을 호출하고, GPU 시 NeuralNetwork<DTYPE>::TestingOnGPU()을 호출한다. </p>
<h5>Returns</h5>
<p>성공 시 TRUE, m_Device 멤버 변수가 잘못된 값을 갖고 있을 때 FALSE를 반환한다.</p>
<h4 id="classNeuralNetwork_1a6527833265b19ba3d2aaf755ea0fdfa3"><code>public int</code><a href="#classNeuralNetwork_1a6527833265b19ba3d2aaf755ea0fdfa3"><code>TrainOnCPU</code></a><code>()</code></h4>
<p>CPU를 활용해 신경망을 학습시키는 메소드</p>
<p>순서대로 Excutable Operator들의 Result와 Gradient를 초기화하고 Loss Function의 Result와 Gradient를 초기화하고 ForwardPropagate, BackwardPropagate 메소드를 호출하고 Optimizer로 파라미터를 학습시킨다.</p>
<p>각 메소드 참조 </p>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::ResetOperatorResult() NeuralNetwork<DTYPE>::ResetOperatorGradient() <a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278">NeuralNetwork<DTYPE>::ResetLossFunctionResult()</a><a href="#classNeuralNetwork_1a5e3c7ae5f4717a80089ccb89772394d3">NeuralNetwork<DTYPE>::ResetLossFunctionGradient()</a></p>
<p><strong>See also</strong>: <a href="#classModule_1a1bea4bd0b2831e0c21696998393cc263">NeuralNetwork<DTYPE>::ForwardPropagate()</a><a href="#classModule_1a561a89214a6252632cbc507ef6e35b58">NeuralNetwork<DTYPE>::BackPropagate()</a><a href="#classOptimizer_1a5a989eee4fa18a9b4ee81b1b9bac2814">Optimizer<DTYPE>::UpdateParameter()</a></p>
<h4 id="classNeuralNetwork_1a16bd0b041c7055340b0ef11bc95a59bf"><code>public int</code><a href="#classNeuralNetwork_1a16bd0b041c7055340b0ef11bc95a59bf"><code>TestOnCPU</code></a><code>()</code></h4>
<p>CPU를 활용해 신경망을 테스트하는 메소드</p>
<p>순서대로 Excutable Operator들의 Result를 초기화하고 Loss Function의 Result를 초기화하고 ForwardPropagate메소드를 호출한다.</p>
<p>각 메소드 참조 </p>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::ResetOperatorResult() <a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278">NeuralNetwork<DTYPE>::ResetLossFunctionResult()</a><a href="#classModule_1a1bea4bd0b2831e0c21696998393cc263">NeuralNetwork<DTYPE>::ForwardPropagate()</a></p>
<h4 id="classNeuralNetwork_1ac6a18d638c34093a325ef4e09dbc2978"><code>public int</code><a href="#classNeuralNetwork_1ac6a18d638c34093a325ef4e09dbc2978"><code>TrainOnGPU</code></a><code>()</code></h4>
<p>GPU를 활용해 신경망을 학습시키는 메소드</p>
<p>순서대로 Excutable Operator들의 Result와 Gradient를 초기화하고 Loss Function의 Result와 Gradient를 초기화하고 @detaisl ForwardPropagateOnGPU, BackwardPropagateOnGPU 메소드를 호출하고 Optimizer로 파라미터를 학습시킨다.</p>
<p>각 메소드 참조 </p>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::ResetOperatorResult() NeuralNetwork<DTYPE>::ResetOperatorGradient() <a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278">NeuralNetwork<DTYPE>::ResetLossFunctionResult()</a><a href="#classNeuralNetwork_1a5e3c7ae5f4717a80089ccb89772394d3">NeuralNetwork<DTYPE>::ResetLossFunctionGradient()</a></p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::ForwardPropagateOnGPU() NeuralNetwork<DTYPE>::BackPropagateOnGPU() Optimizer<DTYPE>::UpdateParameterOnGPU()</p>
<h4 id="classNeuralNetwork_1afcdc8ca3b16f063b4d67c3e4b72d5ee0"><code>public int</code><a href="#classNeuralNetwork_1afcdc8ca3b16f063b4d67c3e4b72d5ee0"><code>TestOnGPU</code></a><code>()</code></h4>
<p>GPU를 활용해 신경망을 테스트하는 메소드</p>
<p>순서대로 Excutable Operator들의 Result를 초기화하고 Loss Function의 Result를 초기화하고 ForwardPropagateOnGPU메소드를 호출한다.</p>
<p>각 메소드 참조 </p>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: NeuralNetwork<DTYPE>::ResetOperatorResult() <a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278">NeuralNetwork<DTYPE>::ResetLossFunctionResult()</a> NeuralNetwork<DTYPE>::ForwardPropagateOnGPU()</p>
<h4 id="classNeuralNetwork_1a3562597ed1ba1d43eae487a699bcf91a"><code>public float</code><a href="#classNeuralNetwork_1a3562597ed1ba1d43eae487a699bcf91a"><code>GetAccuracy</code></a><code>(int numOfClass)</code></h4>
<p>분류(Classification)를 위해 학습된 신경망의 Top 1 Accuracy를 계산하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>numOfClass</code> 데이터의 분류(Classification)에 이용되는 label의 개수 </li>
</ul>
<h5>Returns</h5>
<p>신경망의 Top 1 Accuracy : 0. ~ 1.</p>
<h4 id="classNeuralNetwork_1a82da1af0e953ca99fff74684802dcd33"><code>public int</code><a href="#classNeuralNetwork_1a82da1af0e953ca99fff74684802dcd33"><code>GetMaxIndex</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * data,int ba,int ti,int numOfClass)</code></h4>
<p>Tensor의 LongArray의 Element들 중 가장 큰 값의 인덱스를 계산해 반환하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>data</code> 탐색하고자 하는 <a href="#classTensor">Tensor</a></p>
</li>
<li>
<p><code>ba</code> Tensor의 batch Size </p>
</li>
<li>
<p><code>ti</code> Tensor의 Time Size </p>
</li>
<li>
<p><code>numOfClass</code> Tensor의 LongArray의 Element 개수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>매개변수로 전달받은 Tensor의 LongArray의 Element들 중 가장 큰 값의 인덱스</p>
<h4 id="classNeuralNetwork_1a8b2e1e719ed1429aed9f425d228937fb"><code>public float</code><a href="#classNeuralNetwork_1a8b2e1e719ed1429aed9f425d228937fb"><code>GetTop5Accuracy</code></a><code>(int numOfClass)</code></h4>
<p>분류(Classification)를 위해 학습된 신경망의 Top 5 Accuracy를 계산하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>numOfClass</code> 데이터의 분류(Classification)에 이용되는 label의 개수 </li>
</ul>
<h5>Returns</h5>
<p>신경망의 Accuracy : 0. ~ 1.</p>
<h4 id="classNeuralNetwork_1aa068fb156df1718020f9ada53eb2cb38"><code>public void</code><a href="#classNeuralNetwork_1aa068fb156df1718020f9ada53eb2cb38"><code>GetTop5Index</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * data,int * top5Index,int ba,int ti,int numOfClass)</code></h4>
<p>Tensor의 LongArray의 Element들 중 가장 큰 다섯 개 값에 대한 인덱스를 계산해 반환하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>data</code> 탐색하고자 하는 <a href="#classTensor">Tensor</a></p>
</li>
<li>
<p><code>ba</code> Tensor의 batch Size </p>
</li>
<li>
<p><code>ti</code> Tensor의 Time Size </p>
</li>
<li>
<p><code>numOfClass</code> Tensor의 LongArray의 Element 개수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>매개변수로 전달받은 Tensor의 LongArray의 Element들 중 가장 큰 다섯 개 값에 대한 인덱스</p>
<h4 id="classNeuralNetwork_1af33f9fefe93bbaf0dc87f5fac6632539"><code>public float</code><a href="#classNeuralNetwork_1af33f9fefe93bbaf0dc87f5fac6632539"><code>GetLoss</code></a><code>()</code></h4>
<p>데이터에 대해 학습된 신경망의 평균 Loss를 계산하여 반환하는 메소드</p>
<h5>Returns</h5>
<p>학습된 신경망의 평균 Loss</p>
<h4 id="classNeuralNetwork_1a8c2e90c65b99b7da8a4cf1ee70c7d479"><code>public void</code><a href="#classNeuralNetwork_1a8c2e90c65b99b7da8a4cf1ee70c7d479"><code>PrintGraphInformation</code></a><code>()</code></h4>
<p>신경망 그래프의 각 구성 요소에 대해 정보를 출력하는 메소드</p>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Operator<DTYPE>::PrintInformation() LossFunction<DTYPE>::GetName()</p>
<h4 id="classNeuralNetwork_1af408546e239aab642945d8142223e278"><code>public int</code><a href="#classNeuralNetwork_1af408546e239aab642945d8142223e278"><code>ResetLossFunctionResult</code></a><code>()</code></h4>
<p>LossFunction의 Result Tensor를 초기화시킨다.</p>
<p>LossFunction의 <a href="#classLossFunction_1a218be336d4c24afd3ca91ee58ea600e0">LossFunction<DTYPE>::ResetResult()</a> 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classNeuralNetwork_1a5e3c7ae5f4717a80089ccb89772394d3"><code>public int</code><a href="#classNeuralNetwork_1a5e3c7ae5f4717a80089ccb89772394d3"><code>ResetLossFunctionGradient</code></a><code>()</code></h4>
<p>LossFunction의 Gradient Tensor를 초기화시킨다.</p>
<p>LossFunction의 Lossfunction<DTYPE>::ResetGradient() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classNeuralNetwork_1a4cb542f78efa4472bdcd317aa79087d6"><code>public int</code><a href="#classNeuralNetwork_1a4cb542f78efa4472bdcd317aa79087d6"><code>ResetParameterGradient</code></a><code>()</code></h4>
<p>Optimizer의 Gradient와 Parameter들의 Gradient를 초기화시킨다.</p>
<p>Optimizer의 Optimzier<DTYPE>::ResetParameterGradient() 메소드를 호출한다. </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classNeuralNetwork_1a28f8478e6b84704f11b52cfa6c291a81"><code>public</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; *</code><a href="#classNeuralNetwork_1a28f8478e6b84704f11b52cfa6c291a81"><code>SearchOperator</code></a><code>(std::string pName)</code></h4>
<h4 id="classNeuralNetwork_1abb8436142f9031d3c7385b5a7f274442"><code>public void</code><a href="#classNeuralNetwork_1abb8436142f9031d3c7385b5a7f274442"><code>InputToFeature</code></a><code>(int inDim,int noSample,float * pSamples,int outDim,float * pFeatures,int batchSize)</code></h4>
<hr />
<h2 id="classNoiseGenerator">class <code>NoiseGenerator</code><a class="headerlink" href="#classNoiseGenerator" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class NoiseGenerator
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<p><a href="#classTensor">Tensor</a> 클래스의 Random_normal 함수를 사용하여 범위 내의 임의의 값을 갖는 <a href="#classTensor">Tensor</a> 생성</p>
<p><a href="#classOperator">Operator</a> 형식이지만 Tensor를 저장하는 용도로만 사용</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classNoiseGenerator_1a0914cd702e5a449df57ca18a5771d157"><code>NoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classNoiseGenerator_1a7d16c1f9aa5bace194c7bfff7e9e0d3c"><code>NoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classNoiseGenerator_1a0d7e50b7fe67c356c65023f4d672e4cf"><code>~NoiseGenerator</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classNoiseGenerator_1a0914cd702e5a449df57ca18a5771d157"><code>public inline</code><a href="#classNoiseGenerator_1a0914cd702e5a449df57ca18a5771d157"><code>NoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName)</code></h4>
<h4 id="classNoiseGenerator_1a7d16c1f9aa5bace194c7bfff7e9e0d3c"><code>public inline</code><a href="#classNoiseGenerator_1a7d16c1f9aa5bace194c7bfff7e9e0d3c"><code>NoiseGenerator</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,std::string pName)</code></h4>
<h4 id="classNoiseGenerator_1a0d7e50b7fe67c356c65023f4d672e4cf"><code>public inline</code><a href="#classNoiseGenerator_1a0d7e50b7fe67c356c65023f4d672e4cf"><code>~NoiseGenerator</code></a><code>()</code></h4>
<hr />
<h2 id="classOperator">class <code>Operator</code><a class="headerlink" href="#classOperator" title="Permanent link">&para;</a></h2>
<p>본 프래임워크의 가장 작은 연산 단위.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classOperator_1acd1324c1a03947cd33fb88b445a0a39a"><code>Operator</code></a><code>(std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator_1a08fa1d32571c8bd2ffd42fef58925a0e"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator_1a28b8580b946a75f0b8d5a58cb22954c5"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator_1a13392572eaf76c36e45534f492cda060"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput2,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator_1a620d301674f2a2f7b9cbf907ef31ad21"><code>Operator</code></a><code>(int numInput,...)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator_1a3fdf52b48772b7025c7baca76c7378f4"><code>~Operator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1ae7bbac482bcec78495554f1c65d35ef1"><code>AddEdgebetweenOperators</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a991087201b942fab657c2c0b0443a178"><code>AddEdgebetweenOperators</code></a><code>(int numInput,va_list ap)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1aa2316371d2058460f3e62e13fba385f5"><code>AddEdgebetweenOperators</code></a><code>(int numInput,...)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a93c7f1c2190df793af1260c0ca43a3f2"><code>AddResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a0afb3e4d2c98796c513b98d259f7c9d8"><code>AddGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a77805e7510c3f37ddfc3c736af3a012e"><code>AddDelta</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a88221e83a8df456434bba59e3b30cabe"><code>SetResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a6a0a0d6afabdedf0d8d9276e01136f92"><code>SetGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1ad12157211e348fef2dd17b6133724bc1"><code>SetDelta</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a1f176cc41bbb083ff1093c6257e385c5"><code>SetDevice</code></a><code>(Device pDevice)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1acb1289501c960cc9d1df70c70f97e40e"><code>SetDeviceID</code></a><code>(unsigned int idOfDevice)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a06bd203382508c442b475c155c716977"><code>SetIsTensorholder</code></a><code>(int pIsParameter)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1ab7944e858af96f1cecad24b323d26e82"><code>SetIsTrainable</code></a><code>(int pIsTrainable)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a4824e1608881401f8d14a96c9e1c4438"><code>SetModeTrain</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a142ad78819c1ecf4c49953e33119c8e6"><code>SetModeAccumulate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1ad81f3e8a1656100cbc4d79954957c29d"><code>SetModeInference</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; **</code><a href="#classOperator_1ad7be1cef2f71adcb0c22dc6f051cd445"><code>GetOutput</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a2aaef42413eba0597b3566f15f3c0b30"><code>GetOutputContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; **</code><a href="#classOperator_1a42d8adb079719054278d20b080c427db"><code>GetInput</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a7b3fea224107fbd9afbef5df03163caa"><code>GetInputContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1adecf0400d0808f396df03409da96a7f1"><code>GetResult</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a9abbb587f199f755336dca416578cf6b"><code>GetResultContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1a4851981c3868c8b9755dc5e9294964a0"><code>GetGradient</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a56728499112d7d5c7ac46be21d443bd7"><code>GetGradientContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1aa73e50f59bb10fa2ddd16f19ba746570"><code>GetDelta</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1ab45d910fd0780a845516acbbb336ddc7"><code>GetDeltaContainer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public std::string</code><a href="#classOperator_1a8d4325a95bcc43efc8f0b61f013afe89"><code>GetName</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual Device</code><a href="#classOperator_1afba23ac8b7ef98da83a8d32b34a183df"><code>GetDevice</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1aa2450a0e0dc58a850c80003c3f38cd71"><code>GetDeviceID</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a790df61eaa66bcbdbfd5938848940ec9"><code>GetIsTensorholder</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOperator_1a5d0c55b1780c3d9cfcbcc1b5e6e0460e"><code>GetIsTrainable</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a6a409fc71926fcc9839ad24fecf58a9a"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a6d587c2552338a90a7f59767bdbfef44"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a5c980663d286c420e502450d5fc84867"><code>ResetResult</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a953a44849b76004f8e9e0ae76a4ed57a"><code>ResetGradient</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classOperator_1a9ea8ed916722bc4bfbc8f765d62f3585"><code>PrintInformation</code></a><code>(int level)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual void</code><a href="#classOperator_1ae322cf78613b9c3c1b72dcbf133e6157"><code>SetDeviceCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a3a96036162c9c4e5af2c214793237ade"><code>SetResultOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a58a436df26798b574dbb52065c226505"><code>SetGradientOnCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a7b06ca1781b552310dd8e05bd4afa369"><code>Save</code></a><code>(char * nameOfFile)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a241885dbc7d5e5b35e2106ef9bbed53c"><code>Load</code></a><code>(char * nameOfFile)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1a16d495a83c27bad4aeacd6ce4569a8f7"><code>Load</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOperator_1afd997818c44df1bdf94385cc1611d0e7"><code>Save</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classOperator_1acd1324c1a03947cd33fb88b445a0a39a"><code>public</code><a href="#classOperator_1acd1324c1a03947cd33fb88b445a0a39a"><code>Operator</code></a><code>(std::string pName,int pLoadflag)</code></h4>
<h4 id="classOperator_1a08fa1d32571c8bd2ffd42fef58925a0e"><code>public</code><a href="#classOperator_1a08fa1d32571c8bd2ffd42fef58925a0e"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<h4 id="classOperator_1a28b8580b946a75f0b8d5a58cb22954c5"><code>public</code><a href="#classOperator_1a28b8580b946a75f0b8d5a58cb22954c5"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></h4>
<h4 id="classOperator_1a13392572eaf76c36e45534f492cda060"><code>public</code><a href="#classOperator_1a13392572eaf76c36e45534f492cda060"><code>Operator</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput2,std::string pName,int pLoadflag)</code></h4>
<h4 id="classOperator_1a620d301674f2a2f7b9cbf907ef31ad21"><code>public</code><a href="#classOperator_1a620d301674f2a2f7b9cbf907ef31ad21"><code>Operator</code></a><code>(int numInput,...)</code></h4>
<h4 id="classOperator_1a3fdf52b48772b7025c7baca76c7378f4"><code>public virtual</code><a href="#classOperator_1a3fdf52b48772b7025c7baca76c7378f4"><code>~Operator</code></a><code>()</code></h4>
<h4 id="classOperator_1ae7bbac482bcec78495554f1c65d35ef1"><code>public int</code><a href="#classOperator_1ae7bbac482bcec78495554f1c65d35ef1"><code>AddEdgebetweenOperators</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<h4 id="classOperator_1a991087201b942fab657c2c0b0443a178"><code>public int</code><a href="#classOperator_1a991087201b942fab657c2c0b0443a178"><code>AddEdgebetweenOperators</code></a><code>(int numInput,va_list ap)</code></h4>
<h4 id="classOperator_1aa2316371d2058460f3e62e13fba385f5"><code>public int</code><a href="#classOperator_1aa2316371d2058460f3e62e13fba385f5"><code>AddEdgebetweenOperators</code></a><code>(int numInput,...)</code></h4>
<h4 id="classOperator_1a93c7f1c2190df793af1260c0ca43a3f2"><code>public int</code><a href="#classOperator_1a93c7f1c2190df793af1260c0ca43a3f2"><code>AddResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1a0afb3e4d2c98796c513b98d259f7c9d8"><code>public int</code><a href="#classOperator_1a0afb3e4d2c98796c513b98d259f7c9d8"><code>AddGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1a77805e7510c3f37ddfc3c736af3a012e"><code>public int</code><a href="#classOperator_1a77805e7510c3f37ddfc3c736af3a012e"><code>AddDelta</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1a88221e83a8df456434bba59e3b30cabe"><code>public int</code><a href="#classOperator_1a88221e83a8df456434bba59e3b30cabe"><code>SetResult</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1a6a0a0d6afabdedf0d8d9276e01136f92"><code>public int</code><a href="#classOperator_1a6a0a0d6afabdedf0d8d9276e01136f92"><code>SetGradient</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1ad12157211e348fef2dd17b6133724bc1"><code>public int</code><a href="#classOperator_1ad12157211e348fef2dd17b6133724bc1"><code>SetDelta</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classOperator_1a1f176cc41bbb083ff1093c6257e385c5"><code>public int</code><a href="#classOperator_1a1f176cc41bbb083ff1093c6257e385c5"><code>SetDevice</code></a><code>(Device pDevice)</code></h4>
<h4 id="classOperator_1acb1289501c960cc9d1df70c70f97e40e"><code>public int</code><a href="#classOperator_1acb1289501c960cc9d1df70c70f97e40e"><code>SetDeviceID</code></a><code>(unsigned int idOfDevice)</code></h4>
<h4 id="classOperator_1a06bd203382508c442b475c155c716977"><code>public int</code><a href="#classOperator_1a06bd203382508c442b475c155c716977"><code>SetIsTensorholder</code></a><code>(int pIsParameter)</code></h4>
<h4 id="classOperator_1ab7944e858af96f1cecad24b323d26e82"><code>public int</code><a href="#classOperator_1ab7944e858af96f1cecad24b323d26e82"><code>SetIsTrainable</code></a><code>(int pIsTrainable)</code></h4>
<h4 id="classOperator_1a4824e1608881401f8d14a96c9e1c4438"><code>public virtual int</code><a href="#classOperator_1a4824e1608881401f8d14a96c9e1c4438"><code>SetModeTrain</code></a><code>()</code></h4>
<h4 id="classOperator_1a142ad78819c1ecf4c49953e33119c8e6"><code>public virtual int</code><a href="#classOperator_1a142ad78819c1ecf4c49953e33119c8e6"><code>SetModeAccumulate</code></a><code>()</code></h4>
<h4 id="classOperator_1ad81f3e8a1656100cbc4d79954957c29d"><code>public virtual int</code><a href="#classOperator_1ad81f3e8a1656100cbc4d79954957c29d"><code>SetModeInference</code></a><code>()</code></h4>
<h4 id="classOperator_1ad7be1cef2f71adcb0c22dc6f051cd445"><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; **</code><a href="#classOperator_1ad7be1cef2f71adcb0c22dc6f051cd445"><code>GetOutput</code></a><code>()</code></h4>
<h4 id="classOperator_1a2aaef42413eba0597b3566f15f3c0b30"><code>public virtual</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a2aaef42413eba0597b3566f15f3c0b30"><code>GetOutputContainer</code></a><code>()</code></h4>
<h4 id="classOperator_1a42d8adb079719054278d20b080c427db"><code>public virtual</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; **</code><a href="#classOperator_1a42d8adb079719054278d20b080c427db"><code>GetInput</code></a><code>()</code></h4>
<h4 id="classOperator_1a7b3fea224107fbd9afbef5df03163caa"><code>public virtual</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a7b3fea224107fbd9afbef5df03163caa"><code>GetInputContainer</code></a><code>()</code></h4>
<h4 id="classOperator_1adecf0400d0808f396df03409da96a7f1"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1adecf0400d0808f396df03409da96a7f1"><code>GetResult</code></a><code>() const</code></h4>
<h4 id="classOperator_1a9abbb587f199f755336dca416578cf6b"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a9abbb587f199f755336dca416578cf6b"><code>GetResultContainer</code></a><code>()</code></h4>
<h4 id="classOperator_1a4851981c3868c8b9755dc5e9294964a0"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1a4851981c3868c8b9755dc5e9294964a0"><code>GetGradient</code></a><code>() const</code></h4>
<h4 id="classOperator_1a56728499112d7d5c7ac46be21d443bd7"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1a56728499112d7d5c7ac46be21d443bd7"><code>GetGradientContainer</code></a><code>()</code></h4>
<h4 id="classOperator_1aa73e50f59bb10fa2ddd16f19ba746570"><code>public virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classOperator_1aa73e50f59bb10fa2ddd16f19ba746570"><code>GetDelta</code></a><code>() const</code></h4>
<h4 id="classOperator_1ab45d910fd0780a845516acbbb336ddc7"><code>public virtual</code><a href="#classTensor"><code>Container](#classContainer)&lt; [Tensor</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOperator_1ab45d910fd0780a845516acbbb336ddc7"><code>GetDeltaContainer</code></a><code>()</code></h4>
<h4 id="classOperator_1a8d4325a95bcc43efc8f0b61f013afe89"><code>public std::string</code><a href="#classOperator_1a8d4325a95bcc43efc8f0b61f013afe89"><code>GetName</code></a><code>() const</code></h4>
<h4 id="classOperator_1afba23ac8b7ef98da83a8d32b34a183df"><code>public virtual Device</code><a href="#classOperator_1afba23ac8b7ef98da83a8d32b34a183df"><code>GetDevice</code></a><code>()</code></h4>
<h4 id="classOperator_1aa2450a0e0dc58a850c80003c3f38cd71"><code>public virtual int</code><a href="#classOperator_1aa2450a0e0dc58a850c80003c3f38cd71"><code>GetDeviceID</code></a><code>()</code></h4>
<h4 id="classOperator_1a790df61eaa66bcbdbfd5938848940ec9"><code>public int</code><a href="#classOperator_1a790df61eaa66bcbdbfd5938848940ec9"><code>GetIsTensorholder</code></a><code>()</code></h4>
<h4 id="classOperator_1a5d0c55b1780c3d9cfcbcc1b5e6e0460e"><code>public int</code><a href="#classOperator_1a5d0c55b1780c3d9cfcbcc1b5e6e0460e"><code>GetIsTrainable</code></a><code>()</code></h4>
<h4 id="classOperator_1a6a409fc71926fcc9839ad24fecf58a9a"><code>public virtual int</code><a href="#classOperator_1a6a409fc71926fcc9839ad24fecf58a9a"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classOperator_1a6d587c2552338a90a7f59767bdbfef44"><code>public virtual int</code><a href="#classOperator_1a6d587c2552338a90a7f59767bdbfef44"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classOperator_1a5c980663d286c420e502450d5fc84867"><code>public virtual int</code><a href="#classOperator_1a5c980663d286c420e502450d5fc84867"><code>ResetResult</code></a><code>()</code></h4>
<h4 id="classOperator_1a953a44849b76004f8e9e0ae76a4ed57a"><code>public virtual int</code><a href="#classOperator_1a953a44849b76004f8e9e0ae76a4ed57a"><code>ResetGradient</code></a><code>()</code></h4>
<h4 id="classOperator_1a9ea8ed916722bc4bfbc8f765d62f3585"><code>public virtual void</code><a href="#classOperator_1a9ea8ed916722bc4bfbc8f765d62f3585"><code>PrintInformation</code></a><code>(int level)</code></h4>
<h4 id="classOperator_1ae322cf78613b9c3c1b72dcbf133e6157"><code>public virtual void</code><a href="#classOperator_1ae322cf78613b9c3c1b72dcbf133e6157"><code>SetDeviceCPU</code></a><code>()</code></h4>
<h4 id="classOperator_1a3a96036162c9c4e5af2c214793237ade"><code>public virtual int</code><a href="#classOperator_1a3a96036162c9c4e5af2c214793237ade"><code>SetResultOnCPU</code></a><code>()</code></h4>
<h4 id="classOperator_1a58a436df26798b574dbb52065c226505"><code>public virtual int</code><a href="#classOperator_1a58a436df26798b574dbb52065c226505"><code>SetGradientOnCPU</code></a><code>()</code></h4>
<h4 id="classOperator_1a7b06ca1781b552310dd8e05bd4afa369"><code>public virtual int</code><a href="#classOperator_1a7b06ca1781b552310dd8e05bd4afa369"><code>Save</code></a><code>(char * nameOfFile)</code></h4>
<h4 id="classOperator_1a241885dbc7d5e5b35e2106ef9bbed53c"><code>public virtual int</code><a href="#classOperator_1a241885dbc7d5e5b35e2106ef9bbed53c"><code>Load</code></a><code>(char * nameOfFile)</code></h4>
<h4 id="classOperator_1a16d495a83c27bad4aeacd6ce4569a8f7"><code>public virtual int</code><a href="#classOperator_1a16d495a83c27bad4aeacd6ce4569a8f7"><code>Load</code></a><code>(FILE * fp)</code></h4>
<h4 id="classOperator_1afd997818c44df1bdf94385cc1611d0e7"><code>public virtual int</code><a href="#classOperator_1afd997818c44df1bdf94385cc1611d0e7"><code>Save</code></a><code>(FILE * fp)</code></h4>
<hr />
<h2 id="classOptimizer">class <code>Optimizer</code><a class="headerlink" href="#classOptimizer" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classOptimizer_1aceb51b5bd9ed8a62dbc89c224402fe9a"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; ** pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer_1a0faabf351dc7d77fa7697fbe44926fb8"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classOptimizer">Optimizer</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classOptimizer_1a805b3b65ce443424374a2afc83000bd0"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,float pWeightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classOptimizer">Optimizer</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classOptimizer_1a83af99102cb516cf496aafbfea9c09cb"><code>~Optimizer</code></a><code>()</code></td>
<td><a href="#classOptimizer">Optimizer</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1ada0841fe22979c1e14c265e06439e152"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classOptimizer">Optimizer</a> 클래스의 멤버 변수들에 값을 할당하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1a8d49956747bcf80e7bfd5a3a75539f6d"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,float pWeightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td><a href="#classOptimizer">Optimizer</a> 클래스의 멤버 변수들에 값을 할당하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1a9231bd83ca0e7d78c20dd93621aedd96"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual int</code><a href="#classOptimizer_1a5a989eee4fa18a9b4ee81b1b9bac2814"><code>UpdateParameter</code></a><code>()</code></td>
<td>Trainable <a href="#classTensor">Tensor</a> Container의 Operator들의 파라미터들을 순서대로 업데이트하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1ad76af45ccec70ffc2668f477b3ecc42e"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pTrainableTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classOptimizer_1a9d5d625eb42a27951b98757364e3f6b9"><code>SetLearningRate</code></a><code>(float pLearningRate)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classOptimizer_1a63213e3d65db1a88782afa122cc9fba5"><code>SetTrainableTensorDegree</code></a><code>(int pTrainableTensorDegree)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classOptimizer_1aae30446ea6b1c7367d213ac5b868f6ba"><code>SetWeightDecayRate</code></a><code>(int pWeightDecayRate)</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classOptimizer_1ad9387dd121ed55a119e98242359aa2f8"><code>GetLearningRate</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1a993c37ff4e3e3bd572c9cf2f41d7a562"><code>GetOptimizeDirection</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOptimizer_1a8aaa2dcbe9a5897a4817f14a3583d7f8"><code>GetTrainableTensor</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1a9ce341664492509a90ba11b335d4cebe"><code>GetTrainableTensorDegree</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public float</code><a href="#classOptimizer_1ac95806a3d3897f54cf1c3da8525db2e9"><code>GetWeightDecayRate</code></a><code>() const</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classOptimizer_1a6afc4f5bf1b0da229aafeefe5ae2bb12"><code>ResetParameterGradient</code></a><code>()</code></td>
<td>Trainable <a href="#classTensor">Tensor</a> Container의 Operator들의 Gradient를 초기화하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classOptimizer_1aceb51b5bd9ed8a62dbc89c224402fe9a"><code>public</code><a href="#classOptimizer_1aceb51b5bd9ed8a62dbc89c224402fe9a"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; ** pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></h4>
<h4 id="classOptimizer_1a0faabf351dc7d77fa7697fbe44926fb8"><code>public</code><a href="#classOptimizer_1a0faabf351dc7d77fa7697fbe44926fb8"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classOptimizer">Optimizer</a> 클래스 생성자</p>
<p>멤버 변수들을 0 또는 NULL로 초기화하고,</p>
<p>전달받은 매개변수를 매개변수로 하여 Optimizer의 Alloc 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameters</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 Trainable <a href="#classTensor">Tensor</a> container </p>
</li>
<li>
<p><code>pLearningRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 learning Rate </p>
</li>
<li>
<p><code>pOptimizeDirection</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 optimize Direction </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classOptimizer_1ada0841fe22979c1e14c265e06439e152">Optimizer<DTYPE>::Alloc(Container<Operator\<DTYPE> *> *pParameters, float pLearningRate, OptimizeDirection pOptimizeDirection)</a></p>
<h4 id="classOptimizer_1a805b3b65ce443424374a2afc83000bd0"><code>public</code><a href="#classOptimizer_1a805b3b65ce443424374a2afc83000bd0"><code>Optimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,float pWeightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classOptimizer">Optimizer</a> 클래스 생성자</p>
<p>멤버 변수들을 0 또는 NULL로 초기화하고,</p>
<p>전달받은 매개변수를 매개변수로 하여 Optimizer의 Alloc 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameters</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 Trainable <a href="#classTensor">Tensor</a> container </p>
</li>
<li>
<p><code>pLearningRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 learning Rate </p>
</li>
<li>
<p><code>pWeightDecayRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 Weight Decay Rate </p>
</li>
<li>
<p><code>pOptimizeDirection</code> <a href="#classOptimizer">Optimizer</a> 클래스의 alloc 메소드의 파라미터로 전달할 optimize Direction </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classOptimizer_1a8d49956747bcf80e7bfd5a3a75539f6d">Optimizer<DTYPE>::Alloc(Container<Operator\<DTYPE> *> *pParameters, float pLearningRate, float pWeightDecayRate, OptimizeDirection pOptimizeDirection)</a></p>
<h4 id="classOptimizer_1a83af99102cb516cf496aafbfea9c09cb"><code>public virtual</code><a href="#classOptimizer_1a83af99102cb516cf496aafbfea9c09cb"><code>~Optimizer</code></a><code>()</code></h4>
<p><a href="#classOptimizer">Optimizer</a> 클래스 소멸자</p>
<p>Optimizer<DTYPE>::Delete() 메소드를 호출하고 클래스를 소멸시킨다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classOptimizer_1ada0841fe22979c1e14c265e06439e152"><code>public int</code><a href="#classOptimizer_1ada0841fe22979c1e14c265e06439e152"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classOptimizer">Optimizer</a> 클래스의 멤버 변수들에 값을 할당하는 메소드</p>
<p>매개변수로 전달 받은 값들을 각각 Trainable <a href="#classTensor">Tensor</a> Conatiner, learning rate, Optimize Direction, Weight Decay Rate 멤버 변수에 할당한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameters</code> <a href="#classOptimizer">Optimizer</a> 클래스에의 Trainable <a href="#classTensor">Tensor</a> container 멤버 변수 </p>
</li>
<li>
<p><code>pLearningRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 learning Rate 멤버 변수 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> <a href="#classOptimizer">Optimizer</a> 클래스의 optimize Direction 멤버 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classOptimizer_1a8d49956747bcf80e7bfd5a3a75539f6d"><code>public int</code><a href="#classOptimizer_1a8d49956747bcf80e7bfd5a3a75539f6d"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameters,float pLearningRate,float pWeightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p><a href="#classOptimizer">Optimizer</a> 클래스의 멤버 변수들에 값을 할당하는 메소드</p>
<p>매개변수로 전달 받은 값들을 각각 Trainable <a href="#classTensor">Tensor</a> Conatiner, learning rate, Optimize Direction, Weight Decay Rate 멤버 변수에 할당한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameters</code> <a href="#classOptimizer">Optimizer</a> 클래스에의 Trainable <a href="#classTensor">Tensor</a> container 멤버 변수 </p>
</li>
<li>
<p><code>pLearningRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 learning Rate 멤버 변수 </p>
</li>
<li>
<p><code>pWeightDecayRate</code> <a href="#classOptimizer">Optimizer</a> 클래스의 Weight Decay Rate 멤버 변수 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> <a href="#classOptimizer">Optimizer</a> 클래스의 optimize Direction 멤버 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classOptimizer_1a9231bd83ca0e7d78c20dd93621aedd96"><code>public int</code><a href="#classOptimizer_1a9231bd83ca0e7d78c20dd93621aedd96"><code>Delete</code></a><code>()</code></h4>
<h4 id="classOptimizer_1a5a989eee4fa18a9b4ee81b1b9bac2814"><code>public virtual int</code><a href="#classOptimizer_1a5a989eee4fa18a9b4ee81b1b9bac2814"><code>UpdateParameter</code></a><code>()</code></h4>
<p>Trainable <a href="#classTensor">Tensor</a> Container의 Operator들의 파라미터들을 순서대로 업데이트하는 메소드</p>
<p>파생 클래스에서 오버라이드해서 사용하는 메소드 </p>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classOptimizer_1ad76af45ccec70ffc2668f477b3ecc42e"><code>public int</code><a href="#classOptimizer_1ad76af45ccec70ffc2668f477b3ecc42e"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pTrainableTensor)</code></h4>
<h4 id="classOptimizer_1a9d5d625eb42a27951b98757364e3f6b9"><code>public void</code><a href="#classOptimizer_1a9d5d625eb42a27951b98757364e3f6b9"><code>SetLearningRate</code></a><code>(float pLearningRate)</code></h4>
<h4 id="classOptimizer_1a63213e3d65db1a88782afa122cc9fba5"><code>public void</code><a href="#classOptimizer_1a63213e3d65db1a88782afa122cc9fba5"><code>SetTrainableTensorDegree</code></a><code>(int pTrainableTensorDegree)</code></h4>
<h4 id="classOptimizer_1aae30446ea6b1c7367d213ac5b868f6ba"><code>public void</code><a href="#classOptimizer_1aae30446ea6b1c7367d213ac5b868f6ba"><code>SetWeightDecayRate</code></a><code>(int pWeightDecayRate)</code></h4>
<h4 id="classOptimizer_1ad9387dd121ed55a119e98242359aa2f8"><code>public float</code><a href="#classOptimizer_1ad9387dd121ed55a119e98242359aa2f8"><code>GetLearningRate</code></a><code>() const</code></h4>
<h4 id="classOptimizer_1a993c37ff4e3e3bd572c9cf2f41d7a562"><code>public int</code><a href="#classOptimizer_1a993c37ff4e3e3bd572c9cf2f41d7a562"><code>GetOptimizeDirection</code></a><code>() const</code></h4>
<h4 id="classOptimizer_1a8aaa2dcbe9a5897a4817f14a3583d7f8"><code>public</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; *</code><a href="#classOptimizer_1a8aaa2dcbe9a5897a4817f14a3583d7f8"><code>GetTrainableTensor</code></a><code>()</code></h4>
<h4 id="classOptimizer_1a9ce341664492509a90ba11b335d4cebe"><code>public int</code><a href="#classOptimizer_1a9ce341664492509a90ba11b335d4cebe"><code>GetTrainableTensorDegree</code></a><code>() const</code></h4>
<h4 id="classOptimizer_1ac95806a3d3897f54cf1c3da8525db2e9"><code>public float</code><a href="#classOptimizer_1ac95806a3d3897f54cf1c3da8525db2e9"><code>GetWeightDecayRate</code></a><code>() const</code></h4>
<h4 id="classOptimizer_1a6afc4f5bf1b0da229aafeefe5ae2bb12"><code>public int</code><a href="#classOptimizer_1a6afc4f5bf1b0da229aafeefe5ae2bb12"><code>ResetParameterGradient</code></a><code>()</code></h4>
<p>Trainable <a href="#classTensor">Tensor</a> Container의 Operator들의 Gradient를 초기화하는 메소드</p>
<h5>Returns</h5>
<p>TRUE Operator<DTYPE>::ResetGradient()</p>
<hr />
<h2 id="classPRelu">class <code>PRelu</code><a class="headerlink" href="#classPRelu" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class PRelu
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classPRelu_1af1ed227113a7afffeed338913cdfcc86"><code>PRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int pLoadflag)</code></td>
<td>PRelu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classPRelu_1af904bec278acd1c2cde8e0de5e830c74"><code>PRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,std::string pName,int pLoadflag)</code></td>
<td>PRelu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classPRelu_1aea861ee8bded154675345f7c92b1286d"><code>~PRelu</code></a><code>()</code></td>
<td>LRelu의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classPRelu_1ac58c97c1d86240738ee8add023ad8b63"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight)</code></td>
<td>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classPRelu_1a98f94512a517db1016b77abbb5af7f86"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classPRelu_1ad14b9b7c039f16cac149b083c1fd091d"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>PRelu의 ForwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classPRelu_1ac4bf8caf03e220deb028d81fb60de372"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>PRelu의 BackPropagate매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classPRelu_1af1ed227113a7afffeed338913cdfcc86"><code>public inline</code><a href="#classPRelu_1af1ed227113a7afffeed338913cdfcc86"><code>PRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int pLoadflag)</code></h4>
<p>PRelu의 생성자.</p>
<p>파라미터로 받은 pInput, pWeight으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> 입력값이 음수일 경우 사용하는 기울기 int <a href="#classPRelu_1ac58c97c1d86240738ee8add023ad8b63">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight)</a></p>
</li>
</ul>
<h4 id="classPRelu_1af904bec278acd1c2cde8e0de5e830c74"><code>public inline</code><a href="#classPRelu_1af904bec278acd1c2cde8e0de5e830c74"><code>PRelu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,std::string pName,int pLoadflag)</code></h4>
<p>PRelu의 생성자.</p>
<p>파라미터로 받은 pInput, pWeight으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> 입력값이 음수일 경우 사용하는 기울기 </p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classPRelu_1ac58c97c1d86240738ee8add023ad8b63">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight)</a></p>
</li>
</ul>
<h4 id="classPRelu_1aea861ee8bded154675345f7c92b1286d"><code>public inline</code><a href="#classPRelu_1aea861ee8bded154675345f7c92b1286d"><code>~PRelu</code></a><code>()</code></h4>
<p>LRelu의 소멸자.</p>
<p><strong>See also</strong>: void Delete()</p>
<h4 id="classPRelu_1ac58c97c1d86240738ee8add023ad8b63"><code>public inline int</code><a href="#classPRelu_1ac58c97c1d86240738ee8add023ad8b63"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight)</code></h4>
<p>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> 입력값이 음수일 경우 사용하는 Tensor의 정보를 가진 <a href="#classOperator">Operator</a></p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classPRelu_1a98f94512a517db1016b77abbb5af7f86"><code>public inline void</code><a href="#classPRelu_1a98f94512a517db1016b77abbb5af7f86"><code>Delete</code></a><code>()</code></h4>
<h4 id="classPRelu_1ad14b9b7c039f16cac149b083c1fd091d"><code>public inline virtual int</code><a href="#classPRelu_1ad14b9b7c039f16cac149b083c1fd091d"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>PRelu의 ForwardPropagate 매소드.</p>
<p>input의 Tensor값들 중 0.f이상의 값은 그대로 result에 저장하고,</p>
<p>0.f미만의 값은 weight Tensor의 값과 곱한 후 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classPRelu_1ac4bf8caf03e220deb028d81fb60de372"><code>public inline virtual int</code><a href="#classPRelu_1ac4bf8caf03e220deb028d81fb60de372"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>PRelu의 BackPropagate매소드.</p>
<p>input_delta는 result값이 0보다 클 경우 input_delta에 더하고,</p>
<p>0보다 작을 경우 input_delta에 weight을 곱한 후 더한다.</p>
<p>weight_delta는 result값이 0보다 클 경우 0에 더하고,</p>
<p>0보다 작을 경우 input_delta에 input을 곱한 후 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> pInput의 m_timesize값, default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classReconstructionError">class <code>ReconstructionError</code><a class="headerlink" href="#classReconstructionError" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class ReconstructionError
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classReconstructionError_1a42bb64ce990b27859ce8f3e5b96d627a"><code>ReconstructionError</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classReconstructionError_1a47509ee05c71ffdd7c800fb0d201c06d"><code>~ReconstructionError</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classReconstructionError_1a170ac27ced0bcdf8b914aa7a096c3fd2"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classReconstructionError_1a467a2f8d2f5c9b110962bb9e3e3e3bfd"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classReconstructionError_1a8bc001621b3e481734ad8c4628a664f1"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classReconstructionError_1a42bb64ce990b27859ce8f3e5b96d627a"><code>public inline</code><a href="#classReconstructionError_1a42bb64ce990b27859ce8f3e5b96d627a"><code>ReconstructionError</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classReconstructionError_1a47509ee05c71ffdd7c800fb0d201c06d"><code>public inline virtual</code><a href="#classReconstructionError_1a47509ee05c71ffdd7c800fb0d201c06d"><code>~ReconstructionError</code></a><code>()</code></h4>
<h4 id="classReconstructionError_1a170ac27ced0bcdf8b914aa7a096c3fd2"><code>public inline virtual int</code><a href="#classReconstructionError_1a170ac27ced0bcdf8b914aa7a096c3fd2"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<h4 id="classReconstructionError_1a467a2f8d2f5c9b110962bb9e3e3e3bfd"><code>public inline virtual int</code><a href="#classReconstructionError_1a467a2f8d2f5c9b110962bb9e3e3e3bfd"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classReconstructionError_1a8bc001621b3e481734ad8c4628a664f1"><code>public inline virtual int</code><a href="#classReconstructionError_1a8bc001621b3e481734ad8c4628a664f1"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classRecurrent">class <code>Recurrent</code><a class="headerlink" href="#classRecurrent" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Recurrent
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classRecurrent_1a3562481a571babfb398903433aef90a5"><code>Recurrent</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRecurrent_1af14bf54fb5aa314ddbfd60261835b586"><code>Recurrent</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRecurrent_1acae26988a139a05841174c810c682961"><code>~Recurrent</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRecurrent_1a59099f3fd92474384462c87539fa3605"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classRecurrent_1a1675e9d111d5b1320d9f15fda459135b"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRecurrent_1ad5bdcf85fb28e8e8b64edab2a5da615f"><code>ForwardPropagate</code></a><code>(int pTime,int pThreadNum)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRecurrent_1a70db063ca6efe80e69af73cd67e0789c"><code>BackPropagate</code></a><code>(int pTime,int pThreadNum)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classRecurrent_1a3562481a571babfb398903433aef90a5"><code>public inline</code><a href="#classRecurrent_1a3562481a571babfb398903433aef90a5"><code>Recurrent</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY)</code></h4>
<h4 id="classRecurrent_1af14bf54fb5aa314ddbfd60261835b586"><code>public inline</code><a href="#classRecurrent_1af14bf54fb5aa314ddbfd60261835b586"><code>Recurrent</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY,std::string pName)</code></h4>
<h4 id="classRecurrent_1acae26988a139a05841174c810c682961"><code>public inline</code><a href="#classRecurrent_1acae26988a139a05841174c810c682961"><code>~Recurrent</code></a><code>()</code></h4>
<h4 id="classRecurrent_1a59099f3fd92474384462c87539fa3605"><code>public inline int</code><a href="#classRecurrent_1a59099f3fd92474384462c87539fa3605"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightXH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHH,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeightHY)</code></h4>
<h4 id="classRecurrent_1a1675e9d111d5b1320d9f15fda459135b"><code>public inline void</code><a href="#classRecurrent_1a1675e9d111d5b1320d9f15fda459135b"><code>Delete</code></a><code>()</code></h4>
<h4 id="classRecurrent_1ad5bdcf85fb28e8e8b64edab2a5da615f"><code>public inline int</code><a href="#classRecurrent_1ad5bdcf85fb28e8e8b64edab2a5da615f"><code>ForwardPropagate</code></a><code>(int pTime,int pThreadNum)</code></h4>
<h4 id="classRecurrent_1a70db063ca6efe80e69af73cd67e0789c"><code>public inline int</code><a href="#classRecurrent_1a70db063ca6efe80e69af73cd67e0789c"><code>BackPropagate</code></a><code>(int pTime,int pThreadNum)</code></h4>
<hr />
<h2 id="classRelu">class <code>Relu</code><a class="headerlink" href="#classRelu" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Relu
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classRelu_1a4f35caa00fa86940cdc1a65933108418"><code>Relu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pLoadflag)</code></td>
<td>Relu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRelu_1a414112090cda5ec045e471f2d8b3af0a"><code>Relu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td>Relu의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRelu_1a6f3c23501b1755c4b97dd8f6873a975c"><code>~Relu</code></a><code>()</code></td>
<td>Relu의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRelu_1a65c4666084bb5bd929c6b7881ceb957c"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classRelu_1a74e3682d6b222c36cf5f6f49668aae37"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classRelu_1aceeba8398158f592380232690e2e90ec"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Relu의 ForwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classRelu_1a7c41f1cf4e9cad9efb70fdbc9b6d7ea3"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>Relu의 BackPropagate매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classRelu_1a4f35caa00fa86940cdc1a65933108418"><code>public inline</code><a href="#classRelu_1a4f35caa00fa86940cdc1a65933108418"><code>Relu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pLoadflag)</code></h4>
<p>Relu의 생성자.</p>
<p>파라미터로 받은 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a> int <a href="#classRelu_1a65c4666084bb5bd929c6b7881ceb957c">Alloc(Operator<DTYPE> *pInput)</a></li>
</ul>
<h4 id="classRelu_1a414112090cda5ec045e471f2d8b3af0a"><code>public inline</code><a href="#classRelu_1a414112090cda5ec045e471f2d8b3af0a"><code>Relu</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<p>Relu의 생성자.</p>
<p>파라미터로 받은 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classRelu_1a65c4666084bb5bd929c6b7881ceb957c">Alloc(Operator<DTYPE> *pInput)</a></p>
</li>
</ul>
<h4 id="classRelu_1a6f3c23501b1755c4b97dd8f6873a975c"><code>public inline</code><a href="#classRelu_1a6f3c23501b1755c4b97dd8f6873a975c"><code>~Relu</code></a><code>()</code></h4>
<p>Relu의 소멸자.</p>
<p><strong>See also</strong>: void Delete()</p>
<h4 id="classRelu_1a65c4666084bb5bd929c6b7881ceb957c"><code>public inline int</code><a href="#classRelu_1a65c4666084bb5bd929c6b7881ceb957c"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<p>파라미터로 받은 pinput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classRelu_1a74e3682d6b222c36cf5f6f49668aae37"><code>public inline void</code><a href="#classRelu_1a74e3682d6b222c36cf5f6f49668aae37"><code>Delete</code></a><code>()</code></h4>
<h4 id="classRelu_1aceeba8398158f592380232690e2e90ec"><code>public inline virtual int</code><a href="#classRelu_1aceeba8398158f592380232690e2e90ec"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Relu의 ForwardPropagate 매소드.</p>
<p>input의 Tensor값들 중 0.f이상의 값은 그대로 result에 저장하고, 0.f미만의 값은 0.f로 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classRelu_1a7c41f1cf4e9cad9efb70fdbc9b6d7ea3"><code>public inline virtual int</code><a href="#classRelu_1a7c41f1cf4e9cad9efb70fdbc9b6d7ea3"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>Relu의 BackPropagate매소드.</p>
<p>result값이 0보다 클 경우 input_delta에 더하고, 0보다 작을 경우 0.f를 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classReShape">class <code>ReShape</code><a class="headerlink" href="#classReShape" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class ReShape
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classReShape_1a8889691defdc4983f9b41ca045d11365"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></td>
<td>ReShape의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classReShape_1aa3d007e81b3be85578554788bc95dd4b"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></td>
<td>ReShape의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classReShape_1af1b6f437bce0d7f39351f213d6dd4d50"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></td>
<td>ReShape의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classReShape_1ac0a21e892c406fe07c36e35f082af659"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></td>
<td>ReShape의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classReShape_1a23509148e95c2172165783cd831bf494"><code>~ReShape</code></a><code>()</code></td>
<td>ReShape의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classReShape_1a2bfd17eb047885e116a164533744c82b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize)</code></td>
<td>파라미터로 받은 값들로 Shape의 dim들을 바꾼다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classReShape_1ad24521b23a6fc48405711e0dc9e145b6"><code>Delete</code></a><code>()</code></td>
<td>Delete 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classReShape_1a85b38b417b41399119460adbc6e9be40"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>ReShape의 ForwardPropagate 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classReShape_1a707731ef524b6abc57de318d56960558"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>ReShape의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classReShape_1a8889691defdc4983f9b41ca045d11365"><code>public inline</code><a href="#classReShape_1a8889691defdc4983f9b41ca045d11365"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></h4>
<p>ReShape의 생성자</p>
<p>파라미터로 받은 pInput, pRowSize, pColSize으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> ReShape할 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pRowSize</code> ReShape으로 새로 만들어질 Tensor의 rowsize. </p>
</li>
<li>
<p><code>pColSize</code> ReShape으로 새로 만들어질 Tensor의 colsize. @paramp pName 사용자가 부여한 Operator의 이름. int <a href="#classReShape_1a2bfd17eb047885e116a164533744c82b">Alloc(Operator<DTYPE> *pInput, int pTimeSize, int pBatchSize, int pChannelSize, int pRowSize, int pColSize)</a></p>
</li>
</ul>
<h4 id="classReShape_1aa3d007e81b3be85578554788bc95dd4b"><code>public inline</code><a href="#classReShape_1aa3d007e81b3be85578554788bc95dd4b"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></h4>
<p>ReShape의 생성자</p>
<p>파라미터로 받은 pInput, pRowSize, pColSize으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> ReShape할 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pChannelSize</code> ReShape으로 새로 만들어질 Tensor의 channelsize </p>
</li>
<li>
<p><code>pRowSize</code> ReShape으로 새로 만들어질 Tensor의 rowsize. </p>
</li>
<li>
<p><code>pColSize</code> ReShape으로 새로 만들어질 Tensor의 colsize. @paramp pName 사용자가 부여한 Operator의 이름. int <a href="#classReShape_1a2bfd17eb047885e116a164533744c82b">Alloc(Operator<DTYPE> *pInput, int pTimeSize, int pBatchSize, int pChannelSize, int pRowSize, int pColSize)</a></p>
</li>
</ul>
<h4 id="classReShape_1af1b6f437bce0d7f39351f213d6dd4d50"><code>public inline</code><a href="#classReShape_1af1b6f437bce0d7f39351f213d6dd4d50"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></h4>
<p>ReShape의 생성자</p>
<p>파라미터로 받은 pInput, pRowSize, pColSize으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> ReShape할 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pBatchSize</code> ReShape으로 새로 만들어질 Tensor의 batchsize. </p>
</li>
<li>
<p><code>pChannelSize</code> ReShape으로 새로 만들어질 Tensor의 channelsize. </p>
</li>
<li>
<p><code>pRowSize</code> ReShape으로 새로 만들어질 Tensor의 rowsize. </p>
</li>
<li>
<p><code>pColSize</code> ReShape으로 새로 만들어질 Tensor의 colsize. @paramp pName 사용자가 부여한 Operator의 이름. int <a href="#classReShape_1a2bfd17eb047885e116a164533744c82b">Alloc(Operator<DTYPE> *pInput, int pTimeSize, int pBatchSize, int pChannelSize, int pRowSize, int pColSize)</a></p>
</li>
</ul>
<h4 id="classReShape_1ac0a21e892c406fe07c36e35f082af659"><code>public inline</code><a href="#classReShape_1ac0a21e892c406fe07c36e35f082af659"><code>ReShape</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pLoadflag)</code></h4>
<p>ReShape의 생성자</p>
<p>파라미터로 받은 pInput, pRowSize, pColSize으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> ReShape할 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pTimeSize</code> ReShape으로 새로 만들어질 Tensor의 timesize. </p>
</li>
<li>
<p><code>pBatchSize</code> ReShape으로 새로 만들어질 Tensor의 batchsize. </p>
</li>
<li>
<p><code>pChannelSize</code> ReShape으로 새로 만들어질 Tensor의 channelsize. </p>
</li>
<li>
<p><code>pRowSize</code> ReShape으로 새로 만들어질 Tensor의 rowsize. </p>
</li>
<li>
<p><code>pColSize</code> ReShape으로 새로 만들어질 Tensor의 colsize. @paramp pName 사용자가 부여한 Operator의 이름. int <a href="#classReShape_1a2bfd17eb047885e116a164533744c82b">Alloc(Operator<DTYPE> *pInput, int pTimeSize, int pBatchSize, int pChannelSize, int pRowSize, int pColSize)</a></p>
</li>
</ul>
<h4 id="classReShape_1a23509148e95c2172165783cd831bf494"><code>public inline</code><a href="#classReShape_1a23509148e95c2172165783cd831bf494"><code>~ReShape</code></a><code>()</code></h4>
<p>ReShape의 소멸자.</p>
<p>Delete 매소드를 사용한다. void <a href="#classReShape_1ad24521b23a6fc48405711e0dc9e145b6">Delete()</a></p>
<h4 id="classReShape_1a2bfd17eb047885e116a164533744c82b"><code>public inline int</code><a href="#classReShape_1a2bfd17eb047885e116a164533744c82b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize)</code></h4>
<p>파라미터로 받은 값들로 Shape의 dim들을 바꾼다.</p>
<p>result에 파라미터로 받은 값들로 result의 shape을 바꾸어 넣고,</p>
<p>Delta도 마찬가지로 받은 Dimension 정보들로 새로운 Tensor를 생성하여 넣는다, </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> ReShape할 <a href="#classOperator">Operator</a>. </p>
</li>
<li>
<p><code>pTimeSize</code> ReShape으로 새로 만들어질 Tensor의 timesize. </p>
</li>
<li>
<p><code>pBatchSize</code> ReShape으로 새로 만들어질 Tensor의 batchsize. </p>
</li>
<li>
<p><code>pChannelSize</code> ReShape으로 새로 만들어질 Tensor의 channelsize. </p>
</li>
<li>
<p><code>pRowSize</code> ReShape으로 새로 만들어질 Tensor의 rowsize. </p>
</li>
<li>
<p><code>pColSize</code> ReShape으로 새로 만들어질 Tensor의 colsize. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classReShape_1ad24521b23a6fc48405711e0dc9e145b6"><code>public inline void</code><a href="#classReShape_1ad24521b23a6fc48405711e0dc9e145b6"><code>Delete</code></a><code>()</code></h4>
<p>Delete 매소드.</p>
<p>별다른 기능은 없다.</p>
<h4 id="classReShape_1a85b38b417b41399119460adbc6e9be40"><code>public inline virtual int</code><a href="#classReShape_1a85b38b417b41399119460adbc6e9be40"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>ReShape의 ForwardPropagate 매소드</p>
<p>input값을 result(새로운 Shape을 갖는 <a href="#classTensor">Tensor</a>)에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classReShape_1a707731ef524b6abc57de318d56960558"><code>public inline virtual int</code><a href="#classReShape_1a707731ef524b6abc57de318d56960558"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>ReShape의 BackPropagate 매소드.</p>
<p>input_delta에 this_delta값을 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classRMSPropOptimizer">class <code>RMSPropOptimizer</code><a class="headerlink" href="#classRMSPropOptimizer" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class RMSPropOptimizer
  : public Optimizer&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classRMSPropOptimizer_1a4cdaa40c01f87df1c5836946fa441113"><code>RMSPropOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float decay,float epsilon,bool centered,OptimizeDirection pOptimizeDirection)</code></td>
<td>RMSPropOptmizer 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRMSPropOptimizer_1ac6abe48a03b007d65a8b960e92724433"><code>RMSPropOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float decay,float epsilon,bool centered,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></td>
<td>RMSPropOptmizer 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classRMSPropOptimizer_1aed19a3794af1602fb18279a0a6340440"><code>~RMSPropOptimizer</code></a><code>()</code></td>
<td>RMSPropOpmitzer 소멸자</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classRMSPropOptimizer_1a64a80ea59e761895c33582baf4577dce"><code>Delete</code></a><code>()</code></td>
<td>Optimizer의 Delete 매소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRMSPropOptimizer_1a6aa8a7a4aa983f2187a537f9260c12be"><code>Alloc</code></a><code>(float decay,float epsilon,bool centered)</code></td>
<td>Optimizer의 Alloc 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classRMSPropOptimizer_1aa13c77558353eacbdfc3421bd4b460cd"><code>UpdateParameter</code></a><code>()</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classRMSPropOptimizer_1aae96f574cf5bb4fca59f0c0bc8ff114c"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></td>
<td>UpdateParameter default 함수</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRMSPropOptimizer_1a166ce01205a276ebfe7260d03d6c5a3c"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanSquared)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classRMSPropOptimizer_1a1e9bcebf06655abf5380b83c36c89bf2"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanSquared,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanGrad)</code></td>
<td>파라미터 값들을 업데이트 하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classRMSPropOptimizer_1a4cdaa40c01f87df1c5836946fa441113"><code>public inline</code><a href="#classRMSPropOptimizer_1a4cdaa40c01f87df1c5836946fa441113"><code>RMSPropOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float decay,float epsilon,bool centered,OptimizeDirection pOptimizeDirection)</code></h4>
<p>RMSPropOptmizer 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>decay</code> m_aaMeanSquared, m_pMeanGrad, m_aaMeanGrad, gradient 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>centered</code> cemtered version enable boolean 변수 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(decay, epsilon, centered)</p>
<h4 id="classRMSPropOptimizer_1ac6abe48a03b007d65a8b960e92724433"><code>public inline</code><a href="#classRMSPropOptimizer_1ac6abe48a03b007d65a8b960e92724433"><code>RMSPropOptimizer</code></a><code>(</code><a href="#classOperator"><code>Container](#classContainer)&lt; [Operator</code></a><code>&lt; DTYPE &gt; * &gt; * pParameterContainer,float pLearningRate,float decay,float epsilon,bool centered,float weightDecayRate,OptimizeDirection pOptimizeDirection)</code></h4>
<p>RMSPropOptmizer 생성자.</p>
<p>맴버변수들을 초기화하고 Alloc 매소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>*pParameterContainer</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pLearningRate</code> Optimizer의 learning rate </p>
</li>
<li>
<p><code>decay</code> m_aaMeanSquared, m_pMeanGrad, m_aaMeanGrad, gradient 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> 분모 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>weightDecayRate</code> 가중치 매개변수가 클 때 패널티를 부과하는 값 </p>
</li>
<li>
<p><code>pOptimizeDirection</code> Optimizing의 방향(MAXIMIZE or MINIMIZE) </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: int Alloc(decay, epsilon, centered)</p>
<h4 id="classRMSPropOptimizer_1aed19a3794af1602fb18279a0a6340440"><code>public inline</code><a href="#classRMSPropOptimizer_1aed19a3794af1602fb18279a0a6340440"><code>~RMSPropOptimizer</code></a><code>()</code></h4>
<p>RMSPropOpmitzer 소멸자</p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classRMSPropOptimizer_1a64a80ea59e761895c33582baf4577dce"><code>public inline virtual void</code><a href="#classRMSPropOptimizer_1a64a80ea59e761895c33582baf4577dce"><code>Delete</code></a><code>()</code></h4>
<p>Optimizer의 Delete 매소드</p>
<p>맴버 변수 m_aaMeanSquared, m_aaMeanGrad의 메모리 할당을 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classRMSPropOptimizer_1a6aa8a7a4aa983f2187a537f9260c12be"><code>public inline int</code><a href="#classRMSPropOptimizer_1a6aa8a7a4aa983f2187a537f9260c12be"><code>Alloc</code></a><code>(float decay,float epsilon,bool centered)</code></h4>
<p>Optimizer의 Alloc 매소드</p>
<p>맴버 변수 m_ppParameter, m_numOfParameter, m_aaMeanSquared, m_aaMeanGrad를 초기화한다.</p>
<p>m_aaMeanSquared를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다.</p>
<p>m_aaMeanGrad를 m_ppParameter와 같은 Shape의 Tensor를 생성하여 넣는다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>decay</code> m_aaMeanSquared, m_pMeanGrad, m_aaMeanGrad, gradient 조정 가중치 값 </p>
</li>
<li>
<p><code>epsilon</code> Root Sqaure 값이 0이 되는 것을 방지 하는 값 </p>
</li>
<li>
<p><code>centered</code> cemtered version enable boolean 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: <a href="#classContainer">Container</a>&lt;<a href="#classOperator">Operator<DTYPE></a> <em>&gt;</em> GetTrainableTensor() </p>
<p><strong>See also</strong>: int GetTrainableTensorDegree()</p>
<h4 id="classRMSPropOptimizer_1aa13c77558353eacbdfc3421bd4b460cd"><code>public inline virtual int</code><a href="#classRMSPropOptimizer_1aa13c77558353eacbdfc3421bd4b460cd"><code>UpdateParameter</code></a><code>()</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_centered 유무에 따라 centered version 과 not use RMSProp UpdateParameter 호출 </p>
<h5>Returns</h5>
<p>성공 시 TRUE </p>
<p><strong>See also</strong>: int <a href="#classRMSPropOptimizer_1a166ce01205a276ebfe7260d03d6c5a3c">UpdateParameter(Operator<DTYPE> *pParameter, Tensor<DTYPE> *m_pMeanSquared)</a></p>
<p><strong>See also</strong>: int <a href="#classRMSPropOptimizer_1a1e9bcebf06655abf5380b83c36c89bf2">UpdateParameter(Operator<DTYPE> *pParameter, Tensor<DTYPE> *m_pMeanSquared, Tensor<DTYPE> *m_pMeanGrad)</a></p>
<h4 id="classRMSPropOptimizer_1aae96f574cf5bb4fca59f0c0bc8ff114c"><code>public inline virtual int</code><a href="#classRMSPropOptimizer_1aae96f574cf5bb4fca59f0c0bc8ff114c"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter)</code></h4>
<p>UpdateParameter default 함수</p>
<h5>Parameters</h5>
<ul>
<li><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classRMSPropOptimizer_1a166ce01205a276ebfe7260d03d6c5a3c"><code>public inline int</code><a href="#classRMSPropOptimizer_1a166ce01205a276ebfe7260d03d6c5a3c"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanSquared)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_decay 가중치로 조정된 m_pMeanSquared, gradinet로 m_pMeanSquared 업데이트 한다.</p>
<p>업데이트 된 m_pMeanSquared로 지수평균 이동 공식을 적용하여 파라미터를 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pMeanSquared</code> 업데이트 할 pMeanSquared </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<h4 id="classRMSPropOptimizer_1a1e9bcebf06655abf5380b83c36c89bf2"><code>public inline int</code><a href="#classRMSPropOptimizer_1a1e9bcebf06655abf5380b83c36c89bf2"><code>UpdateParameter</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pParameter,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanSquared,</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * m_pMeanGrad)</code></h4>
<p>파라미터 값들을 업데이트 하는 메소드</p>
<p>m_decay 가중치로 조정된 gradient로 m_pMeanGrad를 업데이트한다.</p>
<p>m_decay 가중치로 조정된 m_pMeanSquared, gradinet로 m_pMeanSquared 업데이트 한다.</p>
<p>업데이트 된 m_pMeanSquared와 업데이트 된 m_pMeanGrad의 제곱의 차를 지수평균이동공식에 적용하여 파라미터를 업데이트 한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pParameter</code> 업데이트 할 Tensor를 가지고 있는 Operator포인터 </p>
</li>
<li>
<p><code>pMeanSquared</code> 업데이트 할 pMeanSquared </p>
</li>
<li>
<p><code>pMeanGrad</code> 업데이트 할 pMeanGrad </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TURE</p>
<hr />
<h2 id="classSequential">class <code>Sequential</code><a class="headerlink" href="#classSequential" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Sequential
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classSequential_1acae5d700ca6c1ff7f235514b81ebffa3"><code>Sequential</code></a><code>(int numOfOperator,...)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSequential_1a36fed062f234a7448dac6fe388dc09e5"><code>~Sequential</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSequential_1acde7e6f535cea4e323aed1646b5cdfa8"><code>Alloc</code></a><code>(int numOfOperator,va_list * ap)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSequential_1a94b9a0a9690d3eabdba4ce7e6dc9bf40"><code>ForwardPropagate</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSequential_1a6857585bbadfa1175483341a56d72523"><code>BackPropagate</code></a><code>()</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classSequential_1acae5d700ca6c1ff7f235514b81ebffa3"><code>public inline</code><a href="#classSequential_1acae5d700ca6c1ff7f235514b81ebffa3"><code>Sequential</code></a><code>(int numOfOperator,...)</code></h4>
<h4 id="classSequential_1a36fed062f234a7448dac6fe388dc09e5"><code>public inline</code><a href="#classSequential_1a36fed062f234a7448dac6fe388dc09e5"><code>~Sequential</code></a><code>()</code></h4>
<h4 id="classSequential_1acde7e6f535cea4e323aed1646b5cdfa8"><code>public inline int</code><a href="#classSequential_1acde7e6f535cea4e323aed1646b5cdfa8"><code>Alloc</code></a><code>(int numOfOperator,va_list * ap)</code></h4>
<h4 id="classSequential_1a94b9a0a9690d3eabdba4ce7e6dc9bf40"><code>public inline int</code><a href="#classSequential_1a94b9a0a9690d3eabdba4ce7e6dc9bf40"><code>ForwardPropagate</code></a><code>()</code></h4>
<h4 id="classSequential_1a6857585bbadfa1175483341a56d72523"><code>public inline int</code><a href="#classSequential_1a6857585bbadfa1175483341a56d72523"><code>BackPropagate</code></a><code>()</code></h4>
<hr />
<h2 id="classShape">class <code>Shape</code><a class="headerlink" href="#classShape" title="Permanent link">&para;</a></h2>
<p>정보를 담고 있는 Shape을 저장하고 관리하는 클래스</p>
<p>Tensor의 차원 정보를 담고 있는 Shape을 저장하고 관리하는 클래스</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classShape_1a2a7cd5aaf62c49a15140e8fc042d68a2"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></td>
<td>5D-Shape 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classShape_1ab33a5234bbfa48f9fdd050f85602b093"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3)</code></td>
<td>4D-Shape 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classShape_1aa8720e80e9c9624a33a1a16ce9e559b6"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2)</code></td>
<td>3D-Shape 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classShape_1a4816b3286c1d5150aaafdacc56c2df33"><code>Shape</code></a><code>(int pSize0,int pSize1)</code></td>
<td>2D-Shape 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classShape_1a66339a1e7618d1a27ad04bb216a1683b"><code>Shape</code></a><code>(int pSize0)</code></td>
<td>1D-Shape 생성자</td>
</tr>
<tr>
<td><code>public</code><a href="#classShape_1a482c2a9c1b71e8229dea5052b94fdcf8"><code>Shape</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape)</code></td>
<td><a href="#classShape">Shape</a> 클래스를 매개변수로 받아 깊은 복사(Deep Copy)하는 <a href="#classShape">Shape</a> 생성자</td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classShape_1a935afc9e576015f967d90de56977167d"><code>~Shape</code></a><code>()</code></td>
<td><a href="#classShape">Shape</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1a93bc73b3237c0398c302b9014f5727aa"><code>GetRank</code></a><code>()</code></td>
<td><a href="#classShape">Shape</a> 클래스의 Rank 멤버 변수를 반환하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1a5418dc21436c259b6d715a42f4455315"><code>GetDim</code></a><code>(int pRanknum)</code></td>
<td>Rank 인덱스를 파라미터로 받아 Dimension을 반환하는 메소드</td>
</tr>
<tr>
<td><code>public int &amp;</code><a href="#classShape_1afb2f25c23fa4217c06bdc0ebc022d647"><code>operator[]</code></a><code>(int pRanknum)</code></td>
<td>[]연산자 오버로딩</td>
</tr>
<tr>
<td><code>public Device</code><a href="#classShape_1ad3bf16f5fdf16e37694e882dcd800da3"><code>GetDevice</code></a><code>()</code></td>
<td><a href="#classShape">Shape</a> 클래스의 Device 멤버 변수를 반환하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1a9dae5e077c70b9b4d89626a0cea57929"><code>GetDeviceID</code></a><code>()</code></td>
<td><a href="#classShape">Shape</a> 클래스의 idOfDevice 멤버 변수를 반환하는 메소드</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1aa6aba3540be5482aeaebff24636727e0"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></td>
<td>새로운 Shape을 만들어 반환 하는 메소드.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1ac33a6b0013bd8e66b86a61e03cc131ce"><code>ReShape</code></a><code>(int pRank,...)</code></td>
<td><a href="#classShape">Shape</a> 각 축의 Dimension정보를 초기화 하는 메소드.</td>
</tr>
<tr>
<td><code>public int</code><a href="#classShape_1a053362e2b59b2965bdcb765d9158003c"><code>SetDeviceCPU</code></a><code>()</code></td>
<td><a href="#classShape">Shape</a> 클래스의 Device 멤버 변수를 CPU로 변경한다.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classShape_1a2a7cd5aaf62c49a15140e8fc042d68a2"><code>public</code><a href="#classShape_1a2a7cd5aaf62c49a15140e8fc042d68a2"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></h4>
<p>5D-Shape 생성자</p>
<p>5개의 축의 Dimension을 매개변수로 받아 <a href="#classShape">Shape</a> 클래스를 생성하는 생성자 </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pSize0</code> 첫 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize1</code> 두 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize2</code> 세 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize3</code> 네 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize4</code> 다섯 번째 축의 Dimension 크기 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Shape::Alloc(int pRank, ...)</p>
<h4 id="classShape_1ab33a5234bbfa48f9fdd050f85602b093"><code>public</code><a href="#classShape_1ab33a5234bbfa48f9fdd050f85602b093"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3)</code></h4>
<p>4D-Shape 생성자</p>
<p>4개의 축의 Dimension을 매개변수로 받아 <a href="#classShape">Shape</a> 클래스를 생성하는 생성자 </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pSize0</code> 첫 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize1</code> 두 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize2</code> 세 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize3</code> 네 번째 축의 Dimension 크기 </p>
</li>
</ul>
<p><strong>See also</strong>: Shape::Alloc(int pRank, ...) </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classShape_1aa8720e80e9c9624a33a1a16ce9e559b6"><code>public</code><a href="#classShape_1aa8720e80e9c9624a33a1a16ce9e559b6"><code>Shape</code></a><code>(int pSize0,int pSize1,int pSize2)</code></h4>
<p>3D-Shape 생성자</p>
<p>3개의 축의 Dimension을 매개변수로 받아 <a href="#classShape">Shape</a> 클래스를 생성하는 생성자 </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pSize0</code> 첫 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize1</code> 두 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize2</code> 세 번째 축의 Dimension 크기 </p>
</li>
</ul>
<p><strong>See also</strong>: Shape::Alloc(int pRank, ...) </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classShape_1a4816b3286c1d5150aaafdacc56c2df33"><code>public</code><a href="#classShape_1a4816b3286c1d5150aaafdacc56c2df33"><code>Shape</code></a><code>(int pSize0,int pSize1)</code></h4>
<p>2D-Shape 생성자</p>
<p>2개의 축의 Dimension을 매개변수로 받아 <a href="#classShape">Shape</a> 클래스를 생성하는 생성자 </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pSize0</code> 첫 번째 축의 Dimension 크기 </p>
</li>
<li>
<p><code>pSize1</code> 두 번째 축의 Dimension 크기 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Shape::Alloc(int pRank, ...)</p>
<h4 id="classShape_1a66339a1e7618d1a27ad04bb216a1683b"><code>public</code><a href="#classShape_1a66339a1e7618d1a27ad04bb216a1683b"><code>Shape</code></a><code>(int pSize0)</code></h4>
<p>1D-Shape 생성자</p>
<p>1개의 축의 Dimension을 매개변수로 받아 <a href="#classShape">Shape</a> 클래스를 생성하는 생성자 </p>
<h5>Parameters</h5>
<ul>
<li><code>pSize0</code> 첫 번째 축의 Dimension 크기 </li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Shape::Alloc(int pRank, ...)</p>
<h4 id="classShape_1a482c2a9c1b71e8229dea5052b94fdcf8"><code>public</code><a href="#classShape_1a482c2a9c1b71e8229dea5052b94fdcf8"><code>Shape</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape)</code></h4>
<p><a href="#classShape">Shape</a> 클래스를 매개변수로 받아 깊은 복사(Deep Copy)하는 <a href="#classShape">Shape</a> 생성자</p>
<h5>Parameters</h5>
<ul>
<li><code>pShape</code> 깊은 복사(Deep Copy)의 대상이 되는 <a href="#classShape">Shape</a> 클래스 </li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Shape::Alloc(Shape *pShape)</p>
<h4 id="classShape_1a935afc9e576015f967d90de56977167d"><code>public virtual</code><a href="#classShape_1a935afc9e576015f967d90de56977167d"><code>~Shape</code></a><code>()</code></h4>
<p><a href="#classShape">Shape</a> 클래스 소멸자</p>
<p>해당 <a href="#classShape">Shape</a> 클래스를 위해 동적으로 할당된 메모리 공간을 반환하고 클래스를 소멸한다. </p>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: Shape::Delete()</p>
<h4 id="classShape_1a93bc73b3237c0398c302b9014f5727aa"><code>public int</code><a href="#classShape_1a93bc73b3237c0398c302b9014f5727aa"><code>GetRank</code></a><code>()</code></h4>
<p><a href="#classShape">Shape</a> 클래스의 Rank 멤버 변수를 반환하는 메소드</p>
<h5>Returns</h5>
<p>m_Rank</p>
<h4 id="classShape_1a5418dc21436c259b6d715a42f4455315"><code>public int</code><a href="#classShape_1a5418dc21436c259b6d715a42f4455315"><code>GetDim</code></a><code>(int pRanknum)</code></h4>
<p>Rank 인덱스를 파라미터로 받아 Dimension을 반환하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pRanknum</code> Dimension을 반환하고자 하는 축의 번호 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 m_aDim[pRanknum], 실패 시 예외 처리</p>
<h4 id="classShape_1afb2f25c23fa4217c06bdc0ebc022d647"><code>public int &amp;</code><a href="#classShape_1afb2f25c23fa4217c06bdc0ebc022d647"><code>operator[]</code></a><code>(int pRanknum)</code></h4>
<p>[]연산자 오버로딩</p>
<p>Rank 인덱스를 파라미터로 받아 Dimension을 반환하는 메소드 </p>
<h5>Parameters</h5>
<ul>
<li><code>pRanknum</code> Dimension을 반환하고자 하는 축의 번호 </li>
</ul>
<h5>Returns</h5>
<p>성공 시 m_aDim[pRanknum], 실패 시 예외 처리</p>
<h4 id="classShape_1ad3bf16f5fdf16e37694e882dcd800da3"><code>public Device</code><a href="#classShape_1ad3bf16f5fdf16e37694e882dcd800da3"><code>GetDevice</code></a><code>()</code></h4>
<p><a href="#classShape">Shape</a> 클래스의 Device 멤버 변수를 반환하는 메소드</p>
<h5>Returns</h5>
<p>m_Device</p>
<h4 id="classShape_1a9dae5e077c70b9b4d89626a0cea57929"><code>public int</code><a href="#classShape_1a9dae5e077c70b9b4d89626a0cea57929"><code>GetDeviceID</code></a><code>()</code></h4>
<p><a href="#classShape">Shape</a> 클래스의 idOfDevice 멤버 변수를 반환하는 메소드</p>
<h5>Returns</h5>
<p>m_idOfDevice</p>
<h4 id="classShape_1aa6aba3540be5482aeaebff24636727e0"><code>public int</code><a href="#classShape_1aa6aba3540be5482aeaebff24636727e0"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></h4>
<p>새로운 Shape을 만들어 반환 하는 메소드.</p>
<p>파마미터로 전달받은 각 축의 Dimension정보를 바탕으로 새로운 Shape을 생성하여 반환한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pSize0</code> Time의 Dimension </p>
</li>
<li>
<p><code>pSize1</code> Batch의 Dimension </p>
</li>
<li>
<p><code>pSize2</code> Channel의 Dimension </p>
</li>
<li>
<p><code>pSize3</code> Row의 Dimension </p>
</li>
<li>
<p><code>pSize4</code> Column의 Dimension </p>
</li>
</ul>
<h5>Returns</h5>
<p>파라미터 정보를 바탕으로 만든 <a href="#classShape">Shape</a></p>
<h4 id="classShape_1ac33a6b0013bd8e66b86a61e03cc131ce"><code>public int</code><a href="#classShape_1ac33a6b0013bd8e66b86a61e03cc131ce"><code>ReShape</code></a><code>(int pRank,...)</code></h4>
<p><a href="#classShape">Shape</a> 각 축의 Dimension정보를 초기화 하는 메소드.</p>
<p>파마미터로 전달받은 각 축의 Dimension정보를 m_aDim에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pRank</code> Shape을 이루는 축의 갯수를 나타내는 변수. </p>
</li>
<li>
<p><code>...</code> 각 축의 Dimension정보를 가지고 있는 가변인자. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE</p>
<h4 id="classShape_1a053362e2b59b2965bdcb765d9158003c"><code>public int</code><a href="#classShape_1a053362e2b59b2965bdcb765d9158003c"><code>SetDeviceCPU</code></a><code>()</code></h4>
<p><a href="#classShape">Shape</a> 클래스의 Device 멤버 변수를 CPU로 변경한다.</p>
<h5>Returns</h5>
<p>TRUE</p>
<hr />
<h2 id="classSigmoid">class <code>Sigmoid</code><a class="headerlink" href="#classSigmoid" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Sigmoid
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classSigmoid_1a30edeafdf59c9729cec91dda2f40611e"><code>Sigmoid</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td>Sigmoid의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSigmoid_1ac70e7aad5d73fbf3ba4c30490f388fda"><code>~Sigmoid</code></a><code>()</code></td>
<td>Sigmoid의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSigmoid_1a7f6383b1af4f0d422fcd4a320a94f211"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSigmoid_1a5878f3b62b3c79e001192c186b7cfbec"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Sigmoid의 ForwardPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSigmoid_1aab45c095325c1a08c0433d071acee4fc"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>SIGMOID의 BackPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classSigmoid_1aa4c668309336cef433d98b56abd3cda7"><code>SIGMOID</code></a><code>(DTYPE data)</code></td>
<td>SIGMOID 함수</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classSigmoid_1a30edeafdf59c9729cec91dda2f40611e"><code>public inline</code><a href="#classSigmoid_1a30edeafdf59c9729cec91dda2f40611e"><code>Sigmoid</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<p>Sigmoid의 생성자.</p>
<p>파라미터로 받은 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름. int <a href="#classSigmoid_1a7f6383b1af4f0d422fcd4a320a94f211">Alloc(Operator<DTYPE> *pInput)</a></p>
</li>
</ul>
<h4 id="classSigmoid_1ac70e7aad5d73fbf3ba4c30490f388fda"><code>public inline</code><a href="#classSigmoid_1ac70e7aad5d73fbf3ba4c30490f388fda"><code>~Sigmoid</code></a><code>()</code></h4>
<p>Sigmoid의 소멸자.</p>
<h4 id="classSigmoid_1a7f6383b1af4f0d422fcd4a320a94f211"><code>public inline int</code><a href="#classSigmoid_1a7f6383b1af4f0d422fcd4a320a94f211"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<p>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSigmoid_1a5878f3b62b3c79e001192c186b7cfbec"><code>public inline virtual int</code><a href="#classSigmoid_1a5878f3b62b3c79e001192c186b7cfbec"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Sigmoid의 ForwardPropagate 매소드.</p>
<p>input의 Tensor값들을 SIGMOID값을 취한 뒤 result에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSigmoid_1aab45c095325c1a08c0433d071acee4fc"><code>public inline virtual int</code><a href="#classSigmoid_1aab45c095325c1a08c0433d071acee4fc"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>SIGMOID의 BackPropagate 매소드.</p>
<p>result값으로 <a href="#classSigmoid">Sigmoid</a> 미분 값을 계산하여 input_delta에 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSigmoid_1aa4c668309336cef433d98b56abd3cda7"><code>public inline DTYPE</code><a href="#classSigmoid_1aa4c668309336cef433d98b56abd3cda7"><code>SIGMOID</code></a><code>(DTYPE data)</code></h4>
<p>SIGMOID 함수</p>
<p>1.0/(1.0 + e^(-x)) </p>
<h5>Parameters</h5>
<ul>
<li><code>data</code> SIGMOID할 값 </li>
</ul>
<h5>Returns</h5>
<p>data를 SIGMOID함수에 넣은 결과 값.</p>
<hr />
<h2 id="classSoftmax">class <code>Softmax</code><a class="headerlink" href="#classSoftmax" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Softmax
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classSoftmax_1ab07477db41c81b4febd7cc7604c372a5"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon,int pLoadflag)</code></td>
<td>Softmax의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSoftmax_1a39d599cd7ecaa03d09435edba3077599"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,std::string pName,int pLoadflag)</code></td>
<td>Softmax의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSoftmax_1ae0a60d30946abed3d4147f24cebdee7e"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon,std::string pName,int pLoadflag)</code></td>
<td>Softmax의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSoftmax_1a27d3ea98ca2e94214233277c6d256fb0"><code>~Softmax</code></a><code>()</code></td>
<td>Softmax의 소멸자.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSoftmax_1afe768ac9d4ccd2c9b21a36fe2c0a055e"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></td>
<td>파라미터로 받은 pOperator로 맴버변수들을 초기화 하고 Result, Gradient를 설정한다.</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classSoftmax_1accb5963f9a8216d02c3d58d008897eaa"><code>Delete</code></a><code>()</code></td>
<td>Alloc매소드에서 할당했던 sum, max를 삭제하고 포인터를 NULL로 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSoftmax_1addd20110453a6d0c5fefbb6f336d34ef"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Softmax의 ForwardPropagate 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSoftmax_1a397299ec79b62770e6696996be661f41"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>softmax의 BackPropagate 매소드.</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classSoftmax_1a575f0dfcdf281af95c020b03b6ee4fb7"><code>Max</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * input,int start,int end)</code></td>
<td>파라미터로 받은 Tensor에서 가장 큰 값을 반환하는 함수.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classSoftmax_1ab07477db41c81b4febd7cc7604c372a5"><code>public inline</code><a href="#classSoftmax_1ab07477db41c81b4febd7cc7604c372a5"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon,int pLoadflag)</code></h4>
<p>Softmax의 생성자.</p>
<p>파라미터로 받은 pOperator, epsilon을 Alloc시킨다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> Softmax할 대상 <a href="#classOperator">Operator</a>, 이 매소드에서 Alloc시킨다. </p>
</li>
<li>
<p><code>epsilon</code> ForwardPropagate에 사용힐 값. 0으로 나누어지는 것을 방지하는 역할을 한다. virtual int Alloc(<a href="#classOperator">Operator<DTYPE></a> *pOperator, DTYPE epsilon = 1e-6f</p>
</li>
</ul>
<h4 id="classSoftmax_1a39d599cd7ecaa03d09435edba3077599"><code>public inline</code><a href="#classSoftmax_1a39d599cd7ecaa03d09435edba3077599"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,std::string pName,int pLoadflag)</code></h4>
<p>Softmax의 생성자.</p>
<p>파라미터로 받은 pOperator을 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> Softmax할 대상 <a href="#classOperator">Operator</a>, 이 매소드에서 Alloc시킨다. </p>
</li>
<li>
<p><code>pName</code> 사용자가 Operator에 부여한 이름. virtual int Alloc(<a href="#classOperator">Operator<DTYPE></a> *pOperator, DTYPE epsilon = 1e-6f</p>
</li>
</ul>
<h4 id="classSoftmax_1ae0a60d30946abed3d4147f24cebdee7e"><code>public inline</code><a href="#classSoftmax_1ae0a60d30946abed3d4147f24cebdee7e"><code>Softmax</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon,std::string pName,int pLoadflag)</code></h4>
<p>Softmax의 생성자.</p>
<p>파라미터로 받은 pOperator, epsilon을 Alloc시킨다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> Softmax할 대상 <a href="#classOperator">Operator</a>, 이 매소드에서 Alloc시킨다. @prram epsilon ForwardPropagate에 사용힐 값. 0으로 나누어지는 것을 방지하는 역할을 한다. </p>
</li>
<li>
<p><code>pName</code> 사용자가 Operator에 부여한 이름. virtual int Alloc(<a href="#classOperator">Operator<DTYPE></a> *pOperator, DTYPE epsilon = 1e-6f</p>
</li>
</ul>
<h4 id="classSoftmax_1a27d3ea98ca2e94214233277c6d256fb0"><code>public inline</code><a href="#classSoftmax_1a27d3ea98ca2e94214233277c6d256fb0"><code>~Softmax</code></a><code>()</code></h4>
<p>Softmax의 소멸자.</p>
<h4 id="classSoftmax_1afe768ac9d4ccd2c9b21a36fe2c0a055e"><code>public inline virtual int</code><a href="#classSoftmax_1afe768ac9d4ccd2c9b21a36fe2c0a055e"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></h4>
<p>파라미터로 받은 pOperator로 맴버변수들을 초기화 하고 Result, Gradient를 설정한다.</p>
<p>input으로 받은 Operator의 Shape정보들로 맴버 변수드을 초기화 하고, 같은 Shape을 갖는 Tensor를 만들어 Result와 Gradient로 설정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> Softmax할 Operator들 </p>
</li>
<li>
<p><code>epsilon</code> 0으로 나누어지는 것을 방지하기위해 softmax식의 분모에 더하는 값. </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSoftmax_1accb5963f9a8216d02c3d58d008897eaa"><code>public inline virtual void</code><a href="#classSoftmax_1accb5963f9a8216d02c3d58d008897eaa"><code>Delete</code></a><code>()</code></h4>
<p>Alloc매소드에서 할당했던 sum, max를 삭제하고 포인터를 NULL로 초기화 한다.</p>
<h4 id="classSoftmax_1addd20110453a6d0c5fefbb6f336d34ef"><code>public inline virtual int</code><a href="#classSoftmax_1addd20110453a6d0c5fefbb6f336d34ef"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Softmax의 ForwardPropagate 매소드</p>
<p>max값을 계산하고, exp()한 모든 값들을 더해 sum을 구한 뒤, 각각의 exp(input)한 값을 sum으로 나누어주어 확률값을 구하고 result에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSoftmax_1a397299ec79b62770e6696996be661f41"><code>public inline virtual int</code><a href="#classSoftmax_1a397299ec79b62770e6696996be661f41"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>softmax의 BackPropagate 매소드.</p>
<p>softmax의 미분 값을 구하여 input_delta에 넣어준다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classSoftmax_1a575f0dfcdf281af95c020b03b6ee4fb7"><code>public inline DTYPE</code><a href="#classSoftmax_1a575f0dfcdf281af95c020b03b6ee4fb7"><code>Max</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * input,int start,int end)</code></h4>
<p>파라미터로 받은 Tensor에서 가장 큰 값을 반환하는 함수.</p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>input</code> 가장 큰 값을 찾을 대상 <a href="#classTensor">Tensor</a>. </p>
</li>
<li>
<p><code>start</code> 값을 찾을 Tensor안에서의 시작위치. </p>
</li>
<li>
<p><code>end</code> 값을 찾을 Tensor안에서의 종료위치. </p>
</li>
</ul>
<h5>Returns</h5>
<p>input Tensor의 값들 중 가장 큰 값..</p>
<hr />
<h2 id="classSoftmaxCrossEntropy">class <code>SoftmaxCrossEntropy</code><a class="headerlink" href="#classSoftmaxCrossEntropy" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class SoftmaxCrossEntropy
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<p>이용해 뉴럴 네트워크의 손실 함수를 계산하는 클래스</p>
<p>Cross Entropy 계산 식을 이용해 뉴럴 네트워크의 순전파를 통해 계산된 출력 Tensor와 레이블 값의 손실 함수를 계산한다</p>
<p><a href="#classSoftmax">Softmax</a> Function을 뉴럴 네트워크의 마지막 Operator로 사용해 뉴럴 네트워크의 Gradient 계산을 용이하게 한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classSoftmaxCrossEntropy_1a0190d98c392818fee9d3d3e2668ecb76"><code>SoftmaxCrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></td>
<td><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSoftmaxCrossEntropy_1a9964624a80b390e30b20d5ce408080d3"><code>SoftmaxCrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classSoftmaxCrossEntropy_1ac40b96b5be1ce3338f005ae694a53e90"><code>~SoftmaxCrossEntropy</code></a><code>()</code></td>
<td><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></td>
<td><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> 클래스의 멤버 변수들을 초기화하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classSoftmaxCrossEntropy_1a1b4820bab7f3c703b701d616fb3a11c9"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당한 멤버 변수들을 메모리 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classSoftmaxCrossEntropy_1a4daa0844f71d8f660dc19178b77a186a"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classSoftmaxCrossEntropy_1a74ade47b66aa72fd0b712ed0e5cb18c3"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td><a href="#classSoftmax">Softmax</a><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 역전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline DTYPE</code><a href="#classSoftmaxCrossEntropy_1a2f9be5e8bec2ef55ec57a8d7cbb902be"><code>Max</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * input,int start,int end)</code></td>
<td>지정된 범위 안에서 입력 Tensor의 데이터 값 중 최댓값을 반환하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classSoftmaxCrossEntropy_1a0190d98c392818fee9d3d3e2668ecb76"><code>public inline</code><a href="#classSoftmaxCrossEntropy_1a0190d98c392818fee9d3d3e2668ecb76"><code>SoftmaxCrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></h4>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 epsilon을 매개변수로 전달하여 <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>epsilon</code> 연산에 대한 translation 요소 </p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름, 지정하지 않을 시 "NO NAME"으로 초기화 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a></p>
<h4 id="classSoftmaxCrossEntropy_1a9964624a80b390e30b20d5ce408080d3"><code>public inline</code><a href="#classSoftmaxCrossEntropy_1a9964624a80b390e30b20d5ce408080d3"><code>SoftmaxCrossEntropy</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 생성자</p>
<p><a href="#classLossFunction">LossFunction</a> 클래스의 생성자를 호출하고, Operator와 1e-6f에 해당하는 epsilon 값을 매개변수로 전달하여 <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a> 메소드를 호출한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a> 메소드의 매개변수로 전달할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pLabel</code> LossFunction의 입력 레이블에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> LossFunction의 이름, 지정하지 않을 시 "NO NAME"으로 초기화 </p>
</li>
</ul>
<h5>Returns</h5>
<p>없음 </p>
<p><strong>See also</strong>: <a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a">SoftmaxCrossEntropy<DTYPE>::Alloc(Operator<DTYPE> *pOperator, DTYPE epsilon)</a></p>
<h4 id="classSoftmaxCrossEntropy_1ac40b96b5be1ce3338f005ae694a53e90"><code>public inline virtual</code><a href="#classSoftmaxCrossEntropy_1ac40b96b5be1ce3338f005ae694a53e90"><code>~SoftmaxCrossEntropy</code></a><code>()</code></h4>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a><a href="#classLossFunction">LossFunction</a> 클래스 소멸자</p>
<p><a href="#classSoftmaxCrossEntropy_1a1b4820bab7f3c703b701d616fb3a11c9">SoftmaxCrossEntropy<DTYPE>::Delete()</a> 메소드를 호출하고 클래스를 소멸시킨다 </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a"><code>public inline int</code><a href="#classSoftmaxCrossEntropy_1a27e9fa313fea3f313e0db9465f096f0a"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></h4>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> 클래스의 멤버 변수들을 초기화하는 메소드</p>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> 클래스의 멤버 변수들의 값을 초기화 하고 포인터 멤버 변수들에 동적으로 메모리를 할당한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pOperator</code> <a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> 클래스에 대한 입력 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>epsilon</code> 연산에 대한 translation 요소 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE</p>
<h4 id="classSoftmaxCrossEntropy_1a1b4820bab7f3c703b701d616fb3a11c9"><code>public inline virtual void</code><a href="#classSoftmaxCrossEntropy_1a1b4820bab7f3c703b701d616fb3a11c9"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당한 멤버 변수들을 메모리 해제하는 메소드</p>
<p>softmax Result 텐서 포인터, sum 포인터, max 포인터를 할당 해제한다 </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classSoftmaxCrossEntropy_1a4daa0844f71d8f660dc19178b77a186a"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classSoftmaxCrossEntropy_1a4daa0844f71d8f660dc19178b77a186a"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classSoftmaxCrossEntropy">SoftmaxCrossEntropy</a> LossFunction의 순전파를 수행하는 메소드</p>
<p>LossFunction의 입력 Operator의 <a href="#classTensor">Tensor</a> 값에 대해서 softmax 함수 값을 계산하고 이를 레이블 값과 비교해 Cross Entropy를 구한다</p>
<p>연산을 용이하게 하기 위해 Max값과 epsilon 값을 사용한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>LossFunction의 입력 Operator에 대한 <a href="#classSoftmax">Softmax</a> Cross Entropy</p>
<h4 id="classSoftmaxCrossEntropy_1a74ade47b66aa72fd0b712ed0e5cb18c3"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classSoftmaxCrossEntropy_1a74ade47b66aa72fd0b712ed0e5cb18c3"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p><a href="#classSoftmax">Softmax</a><a href="#classCrossEntropy">CrossEntropy</a> LossFunction의 역전파를 수행하는 메소드</p>
<p>구성한 뉴럴 네트워크에서 얻어진 <a href="#classSoftmax">Softmax</a><a href="#classCrossEntropy">CrossEntropy</a> LossFunction에 대한 입력 Tensor의 Gradient를 계산한다 </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 입력 Tensor의 Time 축의 Dimension </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classSoftmaxCrossEntropy_1a2f9be5e8bec2ef55ec57a8d7cbb902be"><code>public inline DTYPE</code><a href="#classSoftmaxCrossEntropy_1a2f9be5e8bec2ef55ec57a8d7cbb902be"><code>Max</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * input,int start,int end)</code></h4>
<p>지정된 범위 안에서 입력 Tensor의 데이터 값 중 최댓값을 반환하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>input</code> 입력 Tensor의 포인터 </p>
</li>
<li>
<p><code>start</code> 범위의 시작 인덱스 </p>
</li>
<li>
<p><code>end</code> 범위 종료 인덱스 </p>
</li>
</ul>
<h5>Returns</h5>
<p>지정된 범위 안에서 입력 Tensor의 데이터 값의 최댓값</p>
<hr />
<h2 id="classSwitch">class <code>Switch</code><a class="headerlink" href="#classSwitch" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Switch
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classSwitch_1adc84c8b3706ee8d27d590eaa161fe8a4"><code>Switch</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSwitch_1a4d5ac4ec7af6e172ba4b7c552f38570e"><code>Switch</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classSwitch_1ac049eaffd119e48a3f67e2f2f2b71255"><code>~Switch</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSwitch_1a2fae9496027394657c2b388d637a1190"><code>GetSwitchNumber</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSwitch_1ada8401727fb815f606fd68863a56c518"><code>SetSwitchNumber</code></a><code>(int pSwitchNumber)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classSwitch_1ac1c7ddc5229cd38ca5a526fc2f60cb96"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classSwitch_1a483b34050a7e839ad4b6d8aa489dc00d"><code>Delete</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSwitch_1a560d3a9c26ab6a09ca6189c556da225c"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classSwitch_1a39c9f3cf791c861696814d5aca4c1075"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classSwitch_1adc84c8b3706ee8d27d590eaa161fe8a4"><code>public inline</code><a href="#classSwitch_1adc84c8b3706ee8d27d590eaa161fe8a4"><code>Switch</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,int pLoadflag)</code></h4>
<h4 id="classSwitch_1a4d5ac4ec7af6e172ba4b7c552f38570e"><code>public inline</code><a href="#classSwitch_1a4d5ac4ec7af6e172ba4b7c552f38570e"><code>Switch</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1,std::string pName,int pLoadflag)</code></h4>
<h4 id="classSwitch_1ac049eaffd119e48a3f67e2f2f2b71255"><code>public inline</code><a href="#classSwitch_1ac049eaffd119e48a3f67e2f2f2b71255"><code>~Switch</code></a><code>()</code></h4>
<h4 id="classSwitch_1a2fae9496027394657c2b388d637a1190"><code>public inline int</code><a href="#classSwitch_1a2fae9496027394657c2b388d637a1190"><code>GetSwitchNumber</code></a><code>()</code></h4>
<h4 id="classSwitch_1ada8401727fb815f606fd68863a56c518"><code>public inline int</code><a href="#classSwitch_1ada8401727fb815f606fd68863a56c518"><code>SetSwitchNumber</code></a><code>(int pSwitchNumber)</code></h4>
<h4 id="classSwitch_1ac1c7ddc5229cd38ca5a526fc2f60cb96"><code>public inline int</code><a href="#classSwitch_1ac1c7ddc5229cd38ca5a526fc2f60cb96"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput0,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput1)</code></h4>
<h4 id="classSwitch_1a483b34050a7e839ad4b6d8aa489dc00d"><code>public inline void</code><a href="#classSwitch_1a483b34050a7e839ad4b6d8aa489dc00d"><code>Delete</code></a><code>()</code></h4>
<h4 id="classSwitch_1a560d3a9c26ab6a09ca6189c556da225c"><code>public inline virtual int</code><a href="#classSwitch_1a560d3a9c26ab6a09ca6189c556da225c"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classSwitch_1a39c9f3cf791c861696814d5aca4c1075"><code>public inline virtual int</code><a href="#classSwitch_1a39c9f3cf791c861696814d5aca4c1075"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classTanh">class <code>Tanh</code><a class="headerlink" href="#classTanh" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class Tanh
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classTanh_1aa6d97169d17ed3d91129261a372c4b3c"><code>Tanh</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></td>
<td>Tanh의 생성자</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTanh_1af7916f1b1cd5a24826f6a1305f8fbc5d"><code>~Tanh</code></a><code>()</code></td>
<td>Tanh의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTanh_1a5b67680673cd5ad16f5e4dfe12e1a3d8"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></td>
<td>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classTanh_1ac7f3f0ff7e6a8f41d3cdec5ac1bf6439"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>Tanh의 ForwardPropagate 매소드</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classTanh_1a461a7d2e40e24b754dc440293996fff2"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>Tanh의 BackPropagate 매소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTanh_1aa6d97169d17ed3d91129261a372c4b3c"><code>public inline</code><a href="#classTanh_1aa6d97169d17ed3d91129261a372c4b3c"><code>Tanh</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,std::string pName,int pLoadflag)</code></h4>
<p>Tanh의 생성자</p>
<p>파라미터로 받은 pInput으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> Alloc할 대상 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pName</code> Operator에 사용자가 부여한 이름.</p>
</li>
</ul>
<h4 id="classTanh_1af7916f1b1cd5a24826f6a1305f8fbc5d"><code>public inline</code><a href="#classTanh_1af7916f1b1cd5a24826f6a1305f8fbc5d"><code>~Tanh</code></a><code>()</code></h4>
<p>Tanh의 소멸자.</p>
<h4 id="classTanh_1a5b67680673cd5ad16f5e4dfe12e1a3d8"><code>public inline int</code><a href="#classTanh_1a5b67680673cd5ad16f5e4dfe12e1a3d8"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput)</code></h4>
<p>파라미터로 받은 pInput으로부터 맴버 변수들을 초기화 한다.</p>
<p>Result와 Gradient를 저장하기 위해 pInput의 Shape과 같은 dim을 갖는 Tensor를 생성한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pInput</code> 생성 할 Tensor의 Shape정보를 가진 <a href="#classOperator">Operator</a></li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classTanh_1ac7f3f0ff7e6a8f41d3cdec5ac1bf6439"><code>public inline virtual int</code><a href="#classTanh_1ac7f3f0ff7e6a8f41d3cdec5ac1bf6439"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>Tanh의 ForwardPropagate 매소드</p>
<p>input의 Tensor값들을 Tanh을 취한 뒤 result에 저장한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classTanh_1a461a7d2e40e24b754dc440293996fff2"><code>public inline virtual int</code><a href="#classTanh_1a461a7d2e40e24b754dc440293996fff2"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>Tanh의 BackPropagate 매소드.</p>
<p>result값으로 tanh의 미분 값을 계산하여 input_delta에 더한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classTensor">class <code>Tensor</code><a class="headerlink" href="#classTensor" title="Permanent link">&para;</a></h2>
<p>저장하고 관리하는 클래스</p>
<p>학습에 사용될 Tensor를 정의하기 위한 클래스</p>
<p>Tensor클래스는 Shape와 LongArray를 이용하여 Tensor의 모양과 데이터를 저장한다.</p>
<p>Operator클래스에서 m_aaResult(ForwardPropagate한 값)와 m_aaGradient(BackPropagate한 값)을 저장한다.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public</code><a href="#classTensor_1aa20e4455987cf99194c00bd46286f8bf"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1a68da0c8c62a77512f83f5802b4716196"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1aadb1340f4bed2b4e4babcf0c3fb65088"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1afe220f73c7aa5a5c8da12141a095e49c"><code>Tensor</code></a><code>(int pSize0,int pSize1,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1a84b521a3f07d8e26a7c7fe64e2fc0289"><code>Tensor</code></a><code>(int pSize0,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1a406cfed64111646a8007d0e9ba39f8fa"><code>Tensor</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,IsUseTime pAnswer)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classTensor_1a2ccac9a451c8ca9a5685ac6e4c177a02"><code>Tensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td></td>
</tr>
<tr>
<td><code>public virtual</code><a href="#classTensor_1af7a84a67cd4a8157d05a16bcbf81f735"><code>~Tensor</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classShape"><code>Shape</code></a><code>*</code><a href="#classTensor_1a6f3381bacc67b4251d1a0de0ed090ca2"><code>GetShape</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1ad73ec299e9298a7530f61d8103839de1"><code>GetRank</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a249f6eb67fec9e3cb5eda26fbb81bbc4"><code>GetDim</code></a><code>(int pRanknum)</code></td>
<td></td>
</tr>
<tr>
<td><code>public</code><a href="#classLongArray"><code>LongArray</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTensor_1a78cf4c5b86e1fc2ffe7f3bd1bdcf7cea"><code>GetLongArray</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a7c835b1abb2c0d5b441c662288630537"><code>GetCapacity</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a7234157cfe4cd02e72e7d6c5490a8aad"><code>GetElement</code></a><code>(unsigned int index)</code></td>
<td></td>
</tr>
<tr>
<td><code>public DTYPE &amp;</code><a href="#classTensor_1a11cfde5038c40ab36f315960079e3d77"><code>operator[]</code></a><code>(unsigned int index)</code></td>
<td></td>
</tr>
<tr>
<td><code>public Device</code><a href="#classTensor_1a5e25ecadd90a889393c9ec1340644492"><code>GetDevice</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public IsUseTime</code><a href="#classTensor_1ab736c3bd8f1ab90285fcb2ff6d0e57ec"><code>GetIsUseTime</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public DTYPE *</code><a href="#classTensor_1a2f0d3b84baa1fc052c6bfe8e58b24497"><code>GetCPULongArray</code></a><code>(unsigned int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1ab0eb9c7f66e536582df4af3718667d3b"><code>GetTimeSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a164dacb610b0ad1436362fbdbe6b63b5"><code>GetBatchSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a8dc5ce2ae24cddd6f9d9979e795dedeb"><code>GetChannelSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1aaa893ffee48e86000bd372128e39a173"><code>GetRowSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a92ffa915d8e09ba68409528ac3048df8"><code>GetColSize</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a12190442774f6293243d64be2330470e"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a4c47e331e35d5de574ecd3995e43ba6b"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a30a392fb7d63b589428442a0d72eeb81"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1aa573a9456feaa4a43e85be4a7f9c686d"><code>ReShape</code></a><code>(int pSize0,int pSize1)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1affe015e33f9bc1db0f2c21b86a1abf97"><code>ReShape</code></a><code>(int pSize0)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classTensor_1aa38f808b76ef62ebd82452a9bc5ff7b2"><code>Reset</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classTensor_1a8b86a6ff0bc43a13636c1a9b04238884"><code>SetDeviceCPU</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1ab53312ec1be20f5c2f252bf08c8002cc"><code>Save</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classTensor_1a6c3a5202d2fb1dacc51c155e4d1c46e2"><code>Load</code></a><code>(FILE * fp)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classTensor_1a1fbf9588e12fba1c08fb673e77d18a33"><code>Clip</code></a><code>(float min,float max)</code></td>
<td></td>
</tr>
<tr>
<td><code>public void</code><a href="#classTensor_1a9fb8c0ccec9bb0ea615e3d2c7551d6bf"><code>MultiplyScalar</code></a><code>(unsigned int pTime,float pScalar)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTensor_1aa20e4455987cf99194c00bd46286f8bf"><code>public</code><a href="#classTensor_1aa20e4455987cf99194c00bd46286f8bf"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1a68da0c8c62a77512f83f5802b4716196"><code>public</code><a href="#classTensor_1a68da0c8c62a77512f83f5802b4716196"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1aadb1340f4bed2b4e4babcf0c3fb65088"><code>public</code><a href="#classTensor_1aadb1340f4bed2b4e4babcf0c3fb65088"><code>Tensor</code></a><code>(int pSize0,int pSize1,int pSize2,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1afe220f73c7aa5a5c8da12141a095e49c"><code>public</code><a href="#classTensor_1afe220f73c7aa5a5c8da12141a095e49c"><code>Tensor</code></a><code>(int pSize0,int pSize1,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1a84b521a3f07d8e26a7c7fe64e2fc0289"><code>public</code><a href="#classTensor_1a84b521a3f07d8e26a7c7fe64e2fc0289"><code>Tensor</code></a><code>(int pSize0,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1a406cfed64111646a8007d0e9ba39f8fa"><code>public</code><a href="#classTensor_1a406cfed64111646a8007d0e9ba39f8fa"><code>Tensor</code></a><code>(</code><a href="#classShape"><code>Shape</code></a><code>* pShape,IsUseTime pAnswer)</code></h4>
<h4 id="classTensor_1a2ccac9a451c8ca9a5685ac6e4c177a02"><code>public</code><a href="#classTensor_1a2ccac9a451c8ca9a5685ac6e4c177a02"><code>Tensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<h4 id="classTensor_1af7a84a67cd4a8157d05a16bcbf81f735"><code>public virtual</code><a href="#classTensor_1af7a84a67cd4a8157d05a16bcbf81f735"><code>~Tensor</code></a><code>()</code></h4>
<h4 id="classTensor_1a6f3381bacc67b4251d1a0de0ed090ca2"><code>public</code><a href="#classShape"><code>Shape</code></a><code>*</code><a href="#classTensor_1a6f3381bacc67b4251d1a0de0ed090ca2"><code>GetShape</code></a><code>()</code></h4>
<h4 id="classTensor_1ad73ec299e9298a7530f61d8103839de1"><code>public int</code><a href="#classTensor_1ad73ec299e9298a7530f61d8103839de1"><code>GetRank</code></a><code>()</code></h4>
<h4 id="classTensor_1a249f6eb67fec9e3cb5eda26fbb81bbc4"><code>public int</code><a href="#classTensor_1a249f6eb67fec9e3cb5eda26fbb81bbc4"><code>GetDim</code></a><code>(int pRanknum)</code></h4>
<h4 id="classTensor_1a78cf4c5b86e1fc2ffe7f3bd1bdcf7cea"><code>public</code><a href="#classLongArray"><code>LongArray</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTensor_1a78cf4c5b86e1fc2ffe7f3bd1bdcf7cea"><code>GetLongArray</code></a><code>()</code></h4>
<h4 id="classTensor_1a7c835b1abb2c0d5b441c662288630537"><code>public int</code><a href="#classTensor_1a7c835b1abb2c0d5b441c662288630537"><code>GetCapacity</code></a><code>()</code></h4>
<h4 id="classTensor_1a7234157cfe4cd02e72e7d6c5490a8aad"><code>public int</code><a href="#classTensor_1a7234157cfe4cd02e72e7d6c5490a8aad"><code>GetElement</code></a><code>(unsigned int index)</code></h4>
<h4 id="classTensor_1a11cfde5038c40ab36f315960079e3d77"><code>public DTYPE &amp;</code><a href="#classTensor_1a11cfde5038c40ab36f315960079e3d77"><code>operator[]</code></a><code>(unsigned int index)</code></h4>
<h4 id="classTensor_1a5e25ecadd90a889393c9ec1340644492"><code>public Device</code><a href="#classTensor_1a5e25ecadd90a889393c9ec1340644492"><code>GetDevice</code></a><code>()</code></h4>
<h4 id="classTensor_1ab736c3bd8f1ab90285fcb2ff6d0e57ec"><code>public IsUseTime</code><a href="#classTensor_1ab736c3bd8f1ab90285fcb2ff6d0e57ec"><code>GetIsUseTime</code></a><code>()</code></h4>
<h4 id="classTensor_1a2f0d3b84baa1fc052c6bfe8e58b24497"><code>public DTYPE *</code><a href="#classTensor_1a2f0d3b84baa1fc052c6bfe8e58b24497"><code>GetCPULongArray</code></a><code>(unsigned int pTime)</code></h4>
<h4 id="classTensor_1ab0eb9c7f66e536582df4af3718667d3b"><code>public int</code><a href="#classTensor_1ab0eb9c7f66e536582df4af3718667d3b"><code>GetTimeSize</code></a><code>()</code></h4>
<h4 id="classTensor_1a164dacb610b0ad1436362fbdbe6b63b5"><code>public int</code><a href="#classTensor_1a164dacb610b0ad1436362fbdbe6b63b5"><code>GetBatchSize</code></a><code>()</code></h4>
<h4 id="classTensor_1a8dc5ce2ae24cddd6f9d9979e795dedeb"><code>public int</code><a href="#classTensor_1a8dc5ce2ae24cddd6f9d9979e795dedeb"><code>GetChannelSize</code></a><code>()</code></h4>
<h4 id="classTensor_1aaa893ffee48e86000bd372128e39a173"><code>public int</code><a href="#classTensor_1aaa893ffee48e86000bd372128e39a173"><code>GetRowSize</code></a><code>()</code></h4>
<h4 id="classTensor_1a92ffa915d8e09ba68409528ac3048df8"><code>public int</code><a href="#classTensor_1a92ffa915d8e09ba68409528ac3048df8"><code>GetColSize</code></a><code>()</code></h4>
<h4 id="classTensor_1a12190442774f6293243d64be2330470e"><code>public int</code><a href="#classTensor_1a12190442774f6293243d64be2330470e"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3,int pSize4)</code></h4>
<h4 id="classTensor_1a4c47e331e35d5de574ecd3995e43ba6b"><code>public int</code><a href="#classTensor_1a4c47e331e35d5de574ecd3995e43ba6b"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2,int pSize3)</code></h4>
<h4 id="classTensor_1a30a392fb7d63b589428442a0d72eeb81"><code>public int</code><a href="#classTensor_1a30a392fb7d63b589428442a0d72eeb81"><code>ReShape</code></a><code>(int pSize0,int pSize1,int pSize2)</code></h4>
<h4 id="classTensor_1aa573a9456feaa4a43e85be4a7f9c686d"><code>public int</code><a href="#classTensor_1aa573a9456feaa4a43e85be4a7f9c686d"><code>ReShape</code></a><code>(int pSize0,int pSize1)</code></h4>
<h4 id="classTensor_1affe015e33f9bc1db0f2c21b86a1abf97"><code>public int</code><a href="#classTensor_1affe015e33f9bc1db0f2c21b86a1abf97"><code>ReShape</code></a><code>(int pSize0)</code></h4>
<h4 id="classTensor_1aa38f808b76ef62ebd82452a9bc5ff7b2"><code>public void</code><a href="#classTensor_1aa38f808b76ef62ebd82452a9bc5ff7b2"><code>Reset</code></a><code>()</code></h4>
<h4 id="classTensor_1a8b86a6ff0bc43a13636c1a9b04238884"><code>public void</code><a href="#classTensor_1a8b86a6ff0bc43a13636c1a9b04238884"><code>SetDeviceCPU</code></a><code>()</code></h4>
<h4 id="classTensor_1ab53312ec1be20f5c2f252bf08c8002cc"><code>public int</code><a href="#classTensor_1ab53312ec1be20f5c2f252bf08c8002cc"><code>Save</code></a><code>(FILE * fp)</code></h4>
<h4 id="classTensor_1a6c3a5202d2fb1dacc51c155e4d1c46e2"><code>public int</code><a href="#classTensor_1a6c3a5202d2fb1dacc51c155e4d1c46e2"><code>Load</code></a><code>(FILE * fp)</code></h4>
<h4 id="classTensor_1a1fbf9588e12fba1c08fb673e77d18a33"><code>public void</code><a href="#classTensor_1a1fbf9588e12fba1c08fb673e77d18a33"><code>Clip</code></a><code>(float min,float max)</code></h4>
<h4 id="classTensor_1a9fb8c0ccec9bb0ea615e3d2c7551d6bf"><code>public void</code><a href="#classTensor_1a9fb8c0ccec9bb0ea615e3d2c7551d6bf"><code>MultiplyScalar</code></a><code>(unsigned int pTime,float pScalar)</code></h4>
<hr />
<h2 id="classTensorholder">class <code>Tensorholder</code><a class="headerlink" href="#classTensorholder" title="Permanent link">&para;</a></h2>
<p>Result만 사용하기 위한 클래스.</p>
<p>주로 Network의 input, label값을 저장하기 위해 구현되었다.</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classTensorholder_1abe241533158621e13d68ee4f24264623"><code>Tensorholder</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor,std::string pName,int pTrainable,int pLoadflag)</code></td>
<td>Tensorholder의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTensorholder_1a57d1fb2ecee587dccc045351d98792ae"><code>Tensorholder</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pTrainable,int pLoadflag)</code></td>
<td>Tensorholder의 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTensorholder_1a904cee43a83113a6e81ea56b90c1c575"><code>~Tensorholder</code></a><code>()</code></td>
<td>Tensorholder의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTensorholder_1ab18caabed6344ba06bbb7f00f20a4c84"><code>Alloc</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor,int pTrainable)</code></td>
<td>파라미터로 뱓은 pTensor로 Tensorholder를 설정한다.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTensorholder_1ab7d9f1f53c524d2bd53d271033251415"><code>Alloc</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,int pTrainable)</code></td>
<td>파라미터로 뱓은 변수들로 pTensor를 생성하고 Tensorholder를 설정한다.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTensorholder_1a2e667f2bfd21edd144a1ff5c3b055094"><code>GetTensor</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classTensorholder_1a7ea9ae1a6146391965e7d351be8e8c1f"><code>SetTensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td>파라미터로 받은 Tensor를 Result로 설정한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classTensorholder_1ab4e8ab628467d10a19951648cba83c40"><code>FeedTensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></td>
<td>파라미터로 받은 Tensor를 Result로 설정한다.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTensorholder_1abe241533158621e13d68ee4f24264623"><code>public inline</code><a href="#classTensorholder_1abe241533158621e13d68ee4f24264623"><code>Tensorholder</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor,std::string pName,int pTrainable,int pLoadflag)</code></h4>
<p>Tensorholder의 생성자.</p>
<p>파라미터로 받은 pTensor, pTrainable으로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pTensor</code> Alloc에 사용할 <a href="#classTensor">Tensor</a>, 결론적으로 Tensorholder의 Result로 설정된다. </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Tensorholder의 이름. </p>
</li>
<li>
<p><code>pTrainable</code> 생성 할 <a href="#classOperator">Operator(Tensorholder)</a>가 Trainable인지 알리는 변수. default로 TRUE를 사용한다. int <a href="#classTensorholder_1ab18caabed6344ba06bbb7f00f20a4c84">Alloc(Tensor<DTYPE> *pTensor, int pTrainable)</a></p>
</li>
</ul>
<h4 id="classTensorholder_1a57d1fb2ecee587dccc045351d98792ae"><code>public inline</code><a href="#classTensorholder_1a57d1fb2ecee587dccc045351d98792ae"><code>Tensorholder</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,std::string pName,int pTrainable,int pLoadflag)</code></h4>
<p>Tensorholder의 생성자.</p>
<p>파리미터로 받은 pTimeSize, pBatchSize, pChannelSize, pRowSize, pColSize, pTrainable로 Alloc한다.</p>
<p>파라미터로 받은 변수들은 Alloc에서 생성 할 Tensor의 Shape을 결정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pTimeSize</code> Alloc에 사용 할 timesize. </p>
</li>
<li>
<p><code>pBatchSize</code> Alloc에 사용 할 batchsize. </p>
</li>
<li>
<p><code>pChannelSize</code> Alloc에 사용 할 channelsize. </p>
</li>
<li>
<p><code>pRowSize</code> Alloc에 사용 할 rowsize </p>
</li>
<li>
<p><code>pColSize</code> Alloc에 사용 할 colsize </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Tensorholder의 이름. </p>
</li>
<li>
<p><code>pTrainable</code> 생성 할 <a href="#classOperator">Operator(Tensorholder)</a>가 Trainable인지 알리는 변수. default로 TRUE를 사용한다. int <a href="#classTensorholder_1ab7d9f1f53c524d2bd53d271033251415">Alloc(int pTimeSize, int pBatchSize, int pChannelSize, int pRowSize, int pColSize, int pTrainable)</a></p>
</li>
</ul>
<h4 id="classTensorholder_1a904cee43a83113a6e81ea56b90c1c575"><code>public inline</code><a href="#classTensorholder_1a904cee43a83113a6e81ea56b90c1c575"><code>~Tensorholder</code></a><code>()</code></h4>
<p>Tensorholder의 소멸자.</p>
<p>딱히 하는 일은 없다.</p>
<h4 id="classTensorholder_1ab18caabed6344ba06bbb7f00f20a4c84"><code>public inline int</code><a href="#classTensorholder_1ab18caabed6344ba06bbb7f00f20a4c84"><code>Alloc</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor,int pTrainable)</code></h4>
<p>파라미터로 뱓은 pTensor로 Tensorholder를 설정한다.</p>
<p>파라미터로 받은 pTensor를 Result값으로 설정한다.</p>
<p>SetIsTensorholder를 통해 Tensorholder임을 설정하고, pTensor의 Shape과 같은 Shape을 갖는 Tensor를 만들어 Gradient로 설정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pTensor</code> Tensorholder의 Result로 저장 될값을 가진 <a href="#classTensor">Tensor</a>. </p>
</li>
<li>
<p><code>pTrainable</code> Training이 가능한지 아닌지 알리는 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE. int Operator<DTYPE>::ResetResult() int Operator<DTYPE>::SetIsTensorholder(int pIsParameter) int Operator<DTYPE>::SetIsTrainable(int pIsTrainable) int Operator<DTYPE>::AddGradient(Tensor<DTYPE> *pTensor)</p>
<h4 id="classTensorholder_1ab7d9f1f53c524d2bd53d271033251415"><code>public inline int</code><a href="#classTensorholder_1ab7d9f1f53c524d2bd53d271033251415"><code>Alloc</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,int pTrainable)</code></h4>
<p>파라미터로 뱓은 변수들로 pTensor를 생성하고 Tensorholder를 설정한다.</p>
<p>파라미터로 받은 변수들로 pTensor를 생성하고 Result로 설정한다.</p>
<p>생성한 pTensor의 Shape과 같은 Tensor를 생성하여 Gradient로 설정한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pTimeSize</code> 생성할 pTensor의 timesize </p>
</li>
<li>
<p><code>pBatchSize</code> 생성할 pTensor의 batchsize </p>
</li>
<li>
<p><code>pChannelSize</code> 생성할 pTensor의 channelsize </p>
</li>
<li>
<p><code>pRowSize</code> 생성할 pTensor의 rowsize </p>
</li>
<li>
<p><code>pColSize</code> 생성할 pTensor의 colsize </p>
</li>
<li>
<p><code>pTrainable</code> Training이 가능한지 아닌지 알리는 변수 </p>
</li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE. int Operator<DTYPE>::ResetResult() int Operator<DTYPE>::SetIsTensorholder(int pIsParameter) int Operator<DTYPE>::SetIsTrainable(int pIsTrainable) <a href="#classShape">Shape</a> *Tensor<DTYPE>::GetShape() int Operator<DTYPE>::AddGradient(Tensor<DTYPE> *pTensor)</p>
<h4 id="classTensorholder_1a2e667f2bfd21edd144a1ff5c3b055094"><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTensorholder_1a2e667f2bfd21edd144a1ff5c3b055094"><code>GetTensor</code></a><code>()</code></h4>
<h4 id="classTensorholder_1a7ea9ae1a6146391965e7d351be8e8c1f"><code>public inline void</code><a href="#classTensorholder_1a7ea9ae1a6146391965e7d351be8e8c1f"><code>SetTensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<p>파라미터로 받은 Tensor를 Result로 설정한다.</p>
<h5>Parameters</h5>
<ul>
<li><code>pTensor</code> Result로 설정 할 <a href="#classTensor">Tensor</a>.</li>
</ul>
<h4 id="classTensorholder_1ab4e8ab628467d10a19951648cba83c40"><code>public inline void</code><a href="#classTensorholder_1ab4e8ab628467d10a19951648cba83c40"><code>FeedTensor</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * pTensor)</code></h4>
<p>파라미터로 받은 Tensor를 Result로 설정한다.</p>
<h5>Parameters</h5>
<ul>
<li><code>pTensor</code> Result로 설정 할 <a href="#classTensor">Tensor</a>.</li>
</ul>
<hr />
<h2 id="classTransposedConvolution2D">class <code>TransposedConvolution2D</code><a class="headerlink" href="#classTransposedConvolution2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class TransposedConvolution2D
  : public Operator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classTransposedConvolution2D_1a4823926469a618fa912baf03150954dc"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,std::string pName,int pLoadflag)</code></td>
<td><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTransposedConvolution2D_1ad03412e0c92c77e8a691ea68b6c6c00a"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding,std::string pName,int pLoadflag)</code></td>
<td><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTransposedConvolution2D_1a4ae7864232a60a094933f3350fbb4516"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2,std::string pName,int pLoadflag)</code></td>
<td><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTransposedConvolution2D_1a4cf6b21bdcdf857b388b743a56059240"><code>~TransposedConvolution2D</code></a><code>()</code></td>
<td>TransposedConvolution2D의 소멸자.</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2)</code></td>
<td>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2으로 맴버 변수들을 초기화 한다.</td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classTransposedConvolution2D_1aa3f3ecaa0bd9cd0752bfa171756be95d"><code>Delete</code></a><code>()</code></td>
<td>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classTransposedConvolution2D_1ada8f56cda24d89a955744add42df8742"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>TransposedConvolution2D의 ForwardPropagate 메소드.</td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classTransposedConvolution2D_1a30821ce98f67cb3157a8749c70f2a12f"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>TRANSPOSEDCONVOLUTION_2D의 BackPropagate 메소드.</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTransposedConvolution2D_1a4823926469a618fa912baf03150954dc"><code>public inline</code><a href="#classTransposedConvolution2D_1a4823926469a618fa912baf03150954dc"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,std::string pName,int pLoadflag)</code></h4>
<p><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> TransposedConvolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> TransposedConvolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classTransposedConvolution2D_1ad03412e0c92c77e8a691ea68b6c6c00a"><code>public inline</code><a href="#classTransposedConvolution2D_1ad03412e0c92c77e8a691ea68b6c6c00a"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding,std::string pName,int pLoadflag)</code></h4>
<p><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> TransposedConvolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> TransposedConvolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding</code> padding 할 값. height, width 모두 이 값으로 한다. </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classTransposedConvolution2D_1a4ae7864232a60a094933f3350fbb4516"><code>public inline</code><a href="#classTransposedConvolution2D_1a4ae7864232a60a094933f3350fbb4516"><code>TransposedConvolution2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2,std::string pName,int pLoadflag)</code></h4>
<p><a href="#classTransposedConvolution2D">TransposedConvolution2D</a> 생성자.</p>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2로 Alloc한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> TransposedConvolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> TransposedConvolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding1</code> height padding값 </p>
</li>
<li>
<p><code>padding2</code> width padding값 </p>
</li>
<li>
<p><code>pName</code> 사용자가 부여한 Operator이름. int <a href="#classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6">Alloc(Operator<DTYPE> *pInput, Operator<DTYPE> *pWeight, int stride1, int stride2, int padding1, int padding2)</a></p>
</li>
</ul>
<h4 id="classTransposedConvolution2D_1a4cf6b21bdcdf857b388b743a56059240"><code>public inline virtual</code><a href="#classTransposedConvolution2D_1a4cf6b21bdcdf857b388b743a56059240"><code>~TransposedConvolution2D</code></a><code>()</code></h4>
<p>TransposedConvolution2D의 소멸자.</p>
<p>Delete매소드를 사용해 GPU에 할당했던 값들을 해제한다. void <a href="#classTransposedConvolution2D_1aa3f3ecaa0bd9cd0752bfa171756be95d">Delete()</a></p>
<h4 id="classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6"><code>public inline int</code><a href="#classTransposedConvolution2D_1af65884be81ea23dd834a5820cec32fe6"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pWeight,int stride1,int stride2,int padding1,int padding2)</code></h4>
<p>파라미터로 받은 pInput, pWeight, stride1, stride2, padding1, padding2으로 맴버 변수들을 초기화 한다.</p>
<p>pInput과 pWeight의 Shape과 stride, padding값으로 output으로 Result와 Delta로 사용 할 Tensor의 Shape을 정의한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> transposedConvolution할 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pWeight</code> transposedConvolution할 weight. </p>
</li>
<li>
<p><code>stride1</code> stride row값 </p>
</li>
<li>
<p><code>stride2</code> stride colunm값 </p>
</li>
<li>
<p><code>padding1</code> height padding값 </p>
</li>
<li>
<p><code>padding2</code> width padding값</p>
</li>
</ul>
<h4 id="classTransposedConvolution2D_1aa3f3ecaa0bd9cd0752bfa171756be95d"><code>public inline void</code><a href="#classTransposedConvolution2D_1aa3f3ecaa0bd9cd0752bfa171756be95d"><code>Delete</code></a><code>()</code></h4>
<p>GPU에 할당했던 메모리를 해제하고 각 포인터들을 NULL로 초기화한다.</p>
<p>inputTensorDesc, outputTensorDesc,deltaDesc, inputDeltaDesc, convDesc, filterDesc,filterDeltaDesc들을 삭제하고 NULL로 초기화한다.</p>
<p>cudnn연산을 위해 할당 했던 메모리들을 해제시킨다.</p>
<h4 id="classTransposedConvolution2D_1ada8f56cda24d89a955744add42df8742"><code>public inline virtual int</code><a href="#classTransposedConvolution2D_1ada8f56cda24d89a955744add42df8742"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>TransposedConvolution2D의 ForwardPropagate 메소드.</p>
<p>weight(filter size = rowsizeOfWeight * colsizeOfWeight)와 input의 곱한 값을 result에 더해 넣는다.</p>
<p>이때 m_stride값들 만큼 이동하며 result를 계산한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<h4 id="classTransposedConvolution2D_1a30821ce98f67cb3157a8749c70f2a12f"><code>public inline virtual int</code><a href="#classTransposedConvolution2D_1a30821ce98f67cb3157a8749c70f2a12f"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>TRANSPOSEDCONVOLUTION_2D의 BackPropagate 메소드.</p>
<p>TransposedConvolution의 미분 값(weight * this_delta, input * this_delta)을 계산하여 input_delta와 weight_gradient에 각각 더해 넣는다.</p>
<p>이때 m_stride값들 만큼 이동하며 미분 값을 넣을 위치를 계산한다. </p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 연산 할 Tensor가 위치한 Time값. default는 0을 사용. </li>
</ul>
<h5>Returns</h5>
<p>성공 시 TRUE.</p>
<hr />
<h2 id="classTransposedConvolutionLayer2D">class <code>TransposedConvolutionLayer2D</code><a class="headerlink" href="#classTransposedConvolutionLayer2D" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class TransposedConvolutionLayer2D
  : public Module&lt; DTYPE &gt;
</code></pre></div>

<p>구성해 2-Dimensional TransposedConvolution Layer의 기능을 수행하는 모듈을 생성하는 클래스</p>
<p>Operator들을 뉴럴 네트워크의 서브 그래프로 구성해 2-Dimensional Transposedconvolution Layer의 기능을 수행한다</p>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classTransposedConvolutionLayer2D_1a7d9568737d2ea26cee8bfab6c0293577"><code>TransposedConvolutionLayer2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPadding,int use_bias,std::string pName)</code></td>
<td><a href="#classTransposedConvolutionLayer2D">TransposedConvolutionLayer2D</a> 클래스 생성자</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTransposedConvolutionLayer2D_1a8f44ef6a070ba74789ff1eed98e60ab2"><code>~TransposedConvolutionLayer2D</code></a><code>()</code></td>
<td><a href="#classTransposedConvolutionLayer2D">TransposedConvolutionLayer2D</a> 클래스 소멸자</td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTransposedConvolutionLayer2D_1a2e301be572bc7ece3487c7bc6f9f031e"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPaddingRow,int pPaddingCol,int use_bias,std::string pName)</code></td>
<td>2D TransposedConvolution Layer 그래프를 동적으로 할당 및 구성하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTransposedConvolutionLayer2D_1a7d9568737d2ea26cee8bfab6c0293577"><code>public inline</code><a href="#classTransposedConvolutionLayer2D_1a7d9568737d2ea26cee8bfab6c0293577"><code>TransposedConvolutionLayer2D</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPadding,int use_bias,std::string pName)</code></h4>
<p><a href="#classTransposedConvolutionLayer2D">TransposedConvolutionLayer2D</a> 클래스 생성자</p>
<p><a href="#classTransposedConvolutionLayer2D">TransposedConvolutionLayer2D</a> 클래스의 Alloc 함수를 호출한다. 
<strong>See also</strong>: <a href="#classTransposedConvolutionLayer2D_1a2e301be572bc7ece3487c7bc6f9f031e">TransposedConvolutionLayer2D<DTYPE>::Alloc(Operator<DTYPE> *pInput, int pNumInputChannel, int pNumOutputChannel, int pNumKernelRow, int pNumKernelCol, int pStrideRow, int pStrideCol, int pPaddingRow, int pPaddingCol, int use_bias, std::string pName)</a></p>
<h4 id="classTransposedConvolutionLayer2D_1a8f44ef6a070ba74789ff1eed98e60ab2"><code>public inline virtual</code><a href="#classTransposedConvolutionLayer2D_1a8f44ef6a070ba74789ff1eed98e60ab2"><code>~TransposedConvolutionLayer2D</code></a><code>()</code></h4>
<p><a href="#classTransposedConvolutionLayer2D">TransposedConvolutionLayer2D</a> 클래스 소멸자</p>
<p>단, 동적 할당 받은 Operator들은 NeuralNetwork에서 할당 해제한다.</p>
<h4 id="classTransposedConvolutionLayer2D_1a2e301be572bc7ece3487c7bc6f9f031e"><code>public inline int</code><a href="#classTransposedConvolutionLayer2D_1a2e301be572bc7ece3487c7bc6f9f031e"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pInput,int pNumInputChannel,int pNumOutputChannel,int pNumKernelRow,int pNumKernelCol,int pStrideRow,int pStrideCol,int pPaddingRow,int pPaddingCol,int use_bias,std::string pName)</code></h4>
<p>2D TransposedConvolution Layer 그래프를 동적으로 할당 및 구성하는 메소드</p>
<p>Input Operator의 Element에 대해 2D TransposedConvolution 수행한다.</p>
<p>Input Operator의 Element에 대해 Weight를 이용해 2차원 전치합성 곱(2D TransposedConvolution)을 수행하고 Bias가 존재할 시 Bias를 합(Column Wise Addition)해 Output Operator로 내보내는 layer를 구성한다. </p>
<h5>Parameters</h5>
<ul>
<li>
<p><code>pInput</code> 해당 Layer의 Input에 해당하는 <a href="#classOperator">Operator</a></p>
</li>
<li>
<p><code>pNumInputChannel</code> 해당 Layer의 Input Operator의 Channel의 갯수, Input Column에 대한 Dimension </p>
</li>
<li>
<p><code>pNumOutputChannel</code> 해당 Layer의 Output Operator의 Channel의 갯수, Output Column에 대한 Dimension </p>
</li>
<li>
<p><code>pNumKernelRow</code> 2D TransposedConvolution Layer 커널의 Row Size </p>
</li>
<li>
<p><code>pNumKernelCol</code> 2D TransposedConvolution Layer 커널의 Column Size </p>
</li>
<li>
<p><code>pStrideRow</code> 2D TransposedConvolution Layer의 Row Stride Size </p>
</li>
<li>
<p><code>pStrideCol</code> 2D TransposedConvolution Layer의 Column Stride Size </p>
</li>
<li>
<p><code>pPaddingRow</code> 2D TransposedConvolution Layer의 Row Padding 값 </p>
</li>
<li>
<p><code>pPaddingCol</code> 2D TransposedConvolution Layer의 Column Padding 값 </p>
</li>
<li>
<p><code>use_bias</code> Bias 사용 유무, 0일 시 사용 안 함, 0이 아닐 시 사용 </p>
</li>
<li>
<p><code>pName</code> Module의 이름 </p>
</li>
</ul>
<h5>Returns</h5>
<p>TRUE </p>
<p><strong>See also</strong>: <a href="#classTransposedConvolutionLayer2D_1a7d9568737d2ea26cee8bfab6c0293577">TransposedConvolutionLayer2D<DTYPE>::TransposedConvolutionLayer2D</a>(<a href="#classOperator">Operator<DTYPE></a> *pInput, <a href="#classOperator">Operator<DTYPE></a> *pWeight, int stride1, int stride2, std::string pName = "NO NAME") AddColWise<DTYPE>::AddColWise(Operator<DTYPE> *pInput, Operator<DTYPE> *pBias, std::string pName) <a href="#classModule_1a7a8ca0c6ddde4bffde9d806ff64ba614">Module<DTYPE>::AnalyzeGraph(Operator<DTYPE> *pResultOperator)</a></p>
<hr />
<h2 id="classTripletLoss">class <code>TripletLoss</code><a class="headerlink" href="#classTripletLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class TripletLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classTripletLoss_1a23bba0ec84bc8109fa5610018e449f90"><code>TripletLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE margin,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTripletLoss_1aa73d1a54468e42cbeeab30a8a47c9730"><code>TripletLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE margin,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTripletLoss_1a9d49800a7d2184db7598bb9561d0073e"><code>~TripletLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classTripletLoss_1a2e8b33b71498bbdbbcc3ece877446afa"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE margin)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classTripletLoss_1a2d992cd9dde39d73db9cffe5890c2d6f"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTripletLoss_1a2feac7ce4fd47d6d1d2c87dc850fae47"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTripletLoss_1a40d30a0c03da6f8ef5a9cfdaddbba1f0"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classTripletLoss_1a23bba0ec84bc8109fa5610018e449f90"><code>public inline</code><a href="#classTripletLoss_1a23bba0ec84bc8109fa5610018e449f90"><code>TripletLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE margin,std::string pName)</code></h4>
<h4 id="classTripletLoss_1aa73d1a54468e42cbeeab30a8a47c9730"><code>public inline</code><a href="#classTripletLoss_1aa73d1a54468e42cbeeab30a8a47c9730"><code>TripletLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE margin,std::string pName)</code></h4>
<h4 id="classTripletLoss_1a9d49800a7d2184db7598bb9561d0073e"><code>public inline</code><a href="#classTripletLoss_1a9d49800a7d2184db7598bb9561d0073e"><code>~TripletLoss</code></a><code>()</code></h4>
<h4 id="classTripletLoss_1a2e8b33b71498bbdbbcc3ece877446afa"><code>public inline int</code><a href="#classTripletLoss_1a2e8b33b71498bbdbbcc3ece877446afa"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE margin)</code></h4>
<h4 id="classTripletLoss_1a2d992cd9dde39d73db9cffe5890c2d6f"><code>public inline virtual void</code><a href="#classTripletLoss_1a2d992cd9dde39d73db9cffe5890c2d6f"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classTripletLoss_1a2feac7ce4fd47d6d1d2c87dc850fae47"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTripletLoss_1a2feac7ce4fd47d6d1d2c87dc850fae47"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classTripletLoss_1a40d30a0c03da6f8ef5a9cfdaddbba1f0"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classTripletLoss_1a40d30a0c03da6f8ef5a9cfdaddbba1f0"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classUniformNoiseGenerator">class <code>UniformNoiseGenerator</code><a class="headerlink" href="#classUniformNoiseGenerator" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class UniformNoiseGenerator
  : public NoiseGenerator&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classUniformNoiseGenerator_1a95696eba2f5b4068da94b4227503a02f"><code>UniformNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float pLowerLimit,float pUpperLimit,IsUseTime pAnswer,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classUniformNoiseGenerator_1a337fb04cd2395de389ee6918ed2b6f54"><code>~UniformNoiseGenerator</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classUniformNoiseGenerator_1a29597ad355345a8121f2ffc2d709dae3"><code>StartProduce</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline void</code><a href="#classUniformNoiseGenerator_1abbf991a8aac279bbb5b7afb686d57ba8"><code>StopProduce</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classUniformNoiseGenerator_1a6caf923bb95b14f09a8cc7c1bee20fdd"><code>GenerateNoise</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline int</code><a href="#classUniformNoiseGenerator_1a051db44452897a81c4e743efaa6aa292"><code>AddNoise2Buffer</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * noise)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classUniformNoiseGenerator_1a5a290c30855ab3b7e45b7fcc03240a5d"><code>GetNoiseFromBuffer</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classUniformNoiseGenerator_1a14a686b99bb811bb7bf8bfeaf8ddba8c"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classUniformNoiseGenerator_1a5165db89c318df8f72e73b4fa3f14be7"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classUniformNoiseGenerator_1a95696eba2f5b4068da94b4227503a02f"><code>public inline</code><a href="#classUniformNoiseGenerator_1a95696eba2f5b4068da94b4227503a02f"><code>UniformNoiseGenerator</code></a><code>(int pTimeSize,int pBatchSize,int pChannelSize,int pRowSize,int pColSize,float pLowerLimit,float pUpperLimit,IsUseTime pAnswer,std::string pName)</code></h4>
<h4 id="classUniformNoiseGenerator_1a337fb04cd2395de389ee6918ed2b6f54"><code>public inline</code><a href="#classUniformNoiseGenerator_1a337fb04cd2395de389ee6918ed2b6f54"><code>~UniformNoiseGenerator</code></a><code>()</code></h4>
<h4 id="classUniformNoiseGenerator_1a29597ad355345a8121f2ffc2d709dae3"><code>public inline void</code><a href="#classUniformNoiseGenerator_1a29597ad355345a8121f2ffc2d709dae3"><code>StartProduce</code></a><code>()</code></h4>
<h4 id="classUniformNoiseGenerator_1abbf991a8aac279bbb5b7afb686d57ba8"><code>public inline void</code><a href="#classUniformNoiseGenerator_1abbf991a8aac279bbb5b7afb686d57ba8"><code>StopProduce</code></a><code>()</code></h4>
<h4 id="classUniformNoiseGenerator_1a6caf923bb95b14f09a8cc7c1bee20fdd"><code>public inline int</code><a href="#classUniformNoiseGenerator_1a6caf923bb95b14f09a8cc7c1bee20fdd"><code>GenerateNoise</code></a><code>()</code></h4>
<h4 id="classUniformNoiseGenerator_1a051db44452897a81c4e743efaa6aa292"><code>public inline int</code><a href="#classUniformNoiseGenerator_1a051db44452897a81c4e743efaa6aa292"><code>AddNoise2Buffer</code></a><code>(</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; * noise)</code></h4>
<h4 id="classUniformNoiseGenerator_1a5a290c30855ab3b7e45b7fcc03240a5d"><code>public inline</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classUniformNoiseGenerator_1a5a290c30855ab3b7e45b7fcc03240a5d"><code>GetNoiseFromBuffer</code></a><code>()</code></h4>
<h4 id="classUniformNoiseGenerator_1a14a686b99bb811bb7bf8bfeaf8ddba8c"><code>public inline virtual int</code><a href="#classUniformNoiseGenerator_1a14a686b99bb811bb7bf8bfeaf8ddba8c"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<h4 id="classUniformNoiseGenerator_1a5165db89c318df8f72e73b4fa3f14be7"><code>public inline virtual int</code><a href="#classUniformNoiseGenerator_1a5165db89c318df8f72e73b4fa3f14be7"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<hr />
<h2 id="classVanillaGANDiscriminatorLoss">class <code>VanillaGANDiscriminatorLoss</code><a class="headerlink" href="#classVanillaGANDiscriminatorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class VanillaGANDiscriminatorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classVanillaGANDiscriminatorLoss_1a768fb6d1ee98c8759f94d750bc020691"><code>VanillaGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classVanillaGANDiscriminatorLoss_1ab388824430697310825a387f9f7abc7f"><code>VanillaGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classVanillaGANDiscriminatorLoss_1ae43cf40a77a9fe4d80cd9503e3960bd7"><code>~VanillaGANDiscriminatorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classVanillaGANDiscriminatorLoss_1a3e3a8ba187653fabfa7a58386118d0d3"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classVanillaGANDiscriminatorLoss_1a36da0c69fb3af583ca096bdbd50dda36"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANDiscriminatorLoss_1a8780b4f5d982cae80f5daf9206c83675"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANDiscriminatorLoss_1ac458b5ad199bcf7d0945618ee36c02d5"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classVanillaGANDiscriminatorLoss_1a768fb6d1ee98c8759f94d750bc020691"><code>public inline</code><a href="#classVanillaGANDiscriminatorLoss_1a768fb6d1ee98c8759f94d750bc020691"><code>VanillaGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></h4>
<h4 id="classVanillaGANDiscriminatorLoss_1ab388824430697310825a387f9f7abc7f"><code>public inline</code><a href="#classVanillaGANDiscriminatorLoss_1ab388824430697310825a387f9f7abc7f"><code>VanillaGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classVanillaGANDiscriminatorLoss_1ae43cf40a77a9fe4d80cd9503e3960bd7"><code>public inline virtual</code><a href="#classVanillaGANDiscriminatorLoss_1ae43cf40a77a9fe4d80cd9503e3960bd7"><code>~VanillaGANDiscriminatorLoss</code></a><code>()</code></h4>
<h4 id="classVanillaGANDiscriminatorLoss_1a3e3a8ba187653fabfa7a58386118d0d3"><code>public inline virtual int</code><a href="#classVanillaGANDiscriminatorLoss_1a3e3a8ba187653fabfa7a58386118d0d3"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></h4>
<h4 id="classVanillaGANDiscriminatorLoss_1a36da0c69fb3af583ca096bdbd50dda36"><code>public inline virtual void</code><a href="#classVanillaGANDiscriminatorLoss_1a36da0c69fb3af583ca096bdbd50dda36"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classVanillaGANDiscriminatorLoss_1a8780b4f5d982cae80f5daf9206c83675"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANDiscriminatorLoss_1a8780b4f5d982cae80f5daf9206c83675"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classVanillaGANDiscriminatorLoss_1ac458b5ad199bcf7d0945618ee36c02d5"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANDiscriminatorLoss_1ac458b5ad199bcf7d0945618ee36c02d5"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classVanillaGANGeneratorLoss">class <code>VanillaGANGeneratorLoss</code><a class="headerlink" href="#classVanillaGANGeneratorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class VanillaGANGeneratorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classVanillaGANGeneratorLoss_1ab47c3b1dd2a1f56e0696aac2b049c2b0"><code>VanillaGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classVanillaGANGeneratorLoss_1ae1e28b7beedc4e546d029fe86c63ea88"><code>VanillaGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classVanillaGANGeneratorLoss_1a3e44ac1c339ec64db012d52ec9013b82"><code>~VanillaGANGeneratorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classVanillaGANGeneratorLoss_1a0fd0a5418cfa5c5d17807b583702d84b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classVanillaGANGeneratorLoss_1a3e7e87cd9571a031b4706d8c20819857"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANGeneratorLoss_1ae6499cffcfe3ca5755b10eea036bec58"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANGeneratorLoss_1ab6bff598db3fd349585638e0efb47c6a"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classVanillaGANGeneratorLoss_1ab47c3b1dd2a1f56e0696aac2b049c2b0"><code>public inline</code><a href="#classVanillaGANGeneratorLoss_1ab47c3b1dd2a1f56e0696aac2b049c2b0"><code>VanillaGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,DTYPE epsilon,std::string pName)</code></h4>
<h4 id="classVanillaGANGeneratorLoss_1ae1e28b7beedc4e546d029fe86c63ea88"><code>public inline</code><a href="#classVanillaGANGeneratorLoss_1ae1e28b7beedc4e546d029fe86c63ea88"><code>VanillaGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classVanillaGANGeneratorLoss_1a3e44ac1c339ec64db012d52ec9013b82"><code>public inline virtual</code><a href="#classVanillaGANGeneratorLoss_1a3e44ac1c339ec64db012d52ec9013b82"><code>~VanillaGANGeneratorLoss</code></a><code>()</code></h4>
<h4 id="classVanillaGANGeneratorLoss_1a0fd0a5418cfa5c5d17807b583702d84b"><code>public inline virtual int</code><a href="#classVanillaGANGeneratorLoss_1a0fd0a5418cfa5c5d17807b583702d84b"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,DTYPE epsilon)</code></h4>
<h4 id="classVanillaGANGeneratorLoss_1a3e7e87cd9571a031b4706d8c20819857"><code>public inline virtual void</code><a href="#classVanillaGANGeneratorLoss_1a3e7e87cd9571a031b4706d8c20819857"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classVanillaGANGeneratorLoss_1ae6499cffcfe3ca5755b10eea036bec58"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANGeneratorLoss_1ae6499cffcfe3ca5755b10eea036bec58"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classVanillaGANGeneratorLoss_1ab6bff598db3fd349585638e0efb47c6a"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classVanillaGANGeneratorLoss_1ab6bff598db3fd349585638e0efb47c6a"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classWData">class <code>WData</code><a class="headerlink" href="#classWData" title="Permanent link">&para;</a></h2>
<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public DTYPE *</code><a href="#classWData_1ad36845cd4699b9ab85a5ca524ab912aa"><code>m_aData</code></a></td>
<td></td>
</tr>
<tr>
<td><code>public int</code><a href="#classWData_1af06220886bb98127c3e3105f91763ba4"><code>m_capacity</code></a></td>
<td></td>
</tr>
<tr>
<td><code>public inline</code><a href="#classWData_1a50e554ad7f5d167bf60b3e863742d304"><code>WData</code></a><code>(DTYPE * data,int capacity)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classWData_1af665dc6eab06ac705fa3d08b83534634"><code>~WData</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual DTYPE *</code><a href="#classWData_1ae93432315649b12c3dbd834c4440df64"><code>GetData</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classWData_1af8f92f28b659824b59a55eabfde4cd0a"><code>GetCapacity</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline DTYPE &amp;</code><a href="#classWData_1a649cada43f6bedfd6039a59c52fecf19"><code>operator[]</code></a><code>(int idx)</code></td>
<td></td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classWData_1ad36845cd4699b9ab85a5ca524ab912aa"><code>public DTYPE *</code><a href="#classWData_1ad36845cd4699b9ab85a5ca524ab912aa"><code>m_aData</code></a></h4>
<h4 id="classWData_1af06220886bb98127c3e3105f91763ba4"><code>public int</code><a href="#classWData_1af06220886bb98127c3e3105f91763ba4"><code>m_capacity</code></a></h4>
<h4 id="classWData_1a50e554ad7f5d167bf60b3e863742d304"><code>public inline</code><a href="#classWData_1a50e554ad7f5d167bf60b3e863742d304"><code>WData</code></a><code>(DTYPE * data,int capacity)</code></h4>
<h4 id="classWData_1af665dc6eab06ac705fa3d08b83534634"><code>public inline virtual</code><a href="#classWData_1af665dc6eab06ac705fa3d08b83534634"><code>~WData</code></a><code>()</code></h4>
<h4 id="classWData_1ae93432315649b12c3dbd834c4440df64"><code>public inline virtual DTYPE *</code><a href="#classWData_1ae93432315649b12c3dbd834c4440df64"><code>GetData</code></a><code>()</code></h4>
<h4 id="classWData_1af8f92f28b659824b59a55eabfde4cd0a"><code>public inline virtual int</code><a href="#classWData_1af8f92f28b659824b59a55eabfde4cd0a"><code>GetCapacity</code></a><code>()</code></h4>
<h4 id="classWData_1a649cada43f6bedfd6039a59c52fecf19"><code>public inline DTYPE &amp;</code><a href="#classWData_1a649cada43f6bedfd6039a59c52fecf19"><code>operator[]</code></a><code>(int idx)</code></h4>
<hr />
<h2 id="classWGANDiscriminatorLoss">class <code>WGANDiscriminatorLoss</code><a class="headerlink" href="#classWGANDiscriminatorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class WGANDiscriminatorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classWGANDiscriminatorLoss_1a4c87bb209bfcd5200f4eed964db52e08"><code>WGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classWGANDiscriminatorLoss_1a33c614cb3dc1b874b3509ed6a4086b27"><code>~WGANDiscriminatorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classWGANDiscriminatorLoss_1ad02ab0e0cb15d1da8aabb3b397c1e203"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classWGANDiscriminatorLoss_1a2d10a3616ed329476fca86bf91eba47d"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANDiscriminatorLoss_1ad788399d3f79109e938873c1217c4fda"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANDiscriminatorLoss_1a1ebcb93edef6fee4c8a05cadfdfd4b4c"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classWGANDiscriminatorLoss_1a4c87bb209bfcd5200f4eed964db52e08"><code>public inline</code><a href="#classWGANDiscriminatorLoss_1a4c87bb209bfcd5200f4eed964db52e08"><code>WGANDiscriminatorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classWGANDiscriminatorLoss_1a33c614cb3dc1b874b3509ed6a4086b27"><code>public inline virtual</code><a href="#classWGANDiscriminatorLoss_1a33c614cb3dc1b874b3509ed6a4086b27"><code>~WGANDiscriminatorLoss</code></a><code>()</code></h4>
<h4 id="classWGANDiscriminatorLoss_1ad02ab0e0cb15d1da8aabb3b397c1e203"><code>public inline virtual int</code><a href="#classWGANDiscriminatorLoss_1ad02ab0e0cb15d1da8aabb3b397c1e203"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<h4 id="classWGANDiscriminatorLoss_1a2d10a3616ed329476fca86bf91eba47d"><code>public inline virtual void</code><a href="#classWGANDiscriminatorLoss_1a2d10a3616ed329476fca86bf91eba47d"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classWGANDiscriminatorLoss_1ad788399d3f79109e938873c1217c4fda"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANDiscriminatorLoss_1ad788399d3f79109e938873c1217c4fda"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classWGANDiscriminatorLoss_1a1ebcb93edef6fee4c8a05cadfdfd4b4c"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANDiscriminatorLoss_1a1ebcb93edef6fee4c8a05cadfdfd4b4c"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<hr />
<h2 id="classWGANGeneratorLoss">class <code>WGANGeneratorLoss</code><a class="headerlink" href="#classWGANGeneratorLoss" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code>class WGANGeneratorLoss
  : public LossFunction&lt; DTYPE &gt;
</code></pre></div>

<h2> Summary </h2>

<table>
<thead>
<tr>
<th>Members</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>public inline</code><a href="#classWGANGeneratorLoss_1a8341d62f2b2a4bec46a9d4eb96c2c133"><code>WGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classWGANGeneratorLoss_1a5ec911513d25ec26884a709ef60e79fd"><code>~WGANGeneratorLoss</code></a><code>()</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual int</code><a href="#classWGANGeneratorLoss_1a3e5b65237ee97ba99a6b16fbe75bf19d"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></td>
<td></td>
</tr>
<tr>
<td><code>public inline virtual void</code><a href="#classWGANGeneratorLoss_1a28dabeaf32a7d7ec03b0e84ccd8a322d"><code>Delete</code></a><code>()</code></td>
<td>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANGeneratorLoss_1a5354d9a780b8be53775610526787b3ec"><code>ForwardPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 순전파를 수행하는 메소드</td>
</tr>
<tr>
<td><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANGeneratorLoss_1a36f645111dde1d73aa924ed539486286"><code>BackPropagate</code></a><code>(int pTime)</code></td>
<td>LossFunction의 역전파를 수행하는 메소드</td>
</tr>
</tbody>
</table>
<h2> Members </h2>

<h4 id="classWGANGeneratorLoss_1a8341d62f2b2a4bec46a9d4eb96c2c133"><code>public inline</code><a href="#classWGANGeneratorLoss_1a8341d62f2b2a4bec46a9d4eb96c2c133"><code>WGANGeneratorLoss</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator,</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pLabel,std::string pName)</code></h4>
<h4 id="classWGANGeneratorLoss_1a5ec911513d25ec26884a709ef60e79fd"><code>public inline virtual</code><a href="#classWGANGeneratorLoss_1a5ec911513d25ec26884a709ef60e79fd"><code>~WGANGeneratorLoss</code></a><code>()</code></h4>
<h4 id="classWGANGeneratorLoss_1a3e5b65237ee97ba99a6b16fbe75bf19d"><code>public inline virtual int</code><a href="#classWGANGeneratorLoss_1a3e5b65237ee97ba99a6b16fbe75bf19d"><code>Alloc</code></a><code>(</code><a href="#classOperator"><code>Operator</code></a><code>&lt; DTYPE &gt; * pOperator)</code></h4>
<h4 id="classWGANGeneratorLoss_1a28dabeaf32a7d7ec03b0e84ccd8a322d"><code>public inline virtual void</code><a href="#classWGANGeneratorLoss_1a28dabeaf32a7d7ec03b0e84ccd8a322d"><code>Delete</code></a><code>()</code></h4>
<p>동적으로 할당받은 LossFunction의 멤버 변수들을 할당 해제하는 메소드</p>
<p>Result와 Gradient에 해당하는 Tensor들의 메모리를 할당 해제한다. </p>
<h5>Returns</h5>
<p>없음</p>
<h4 id="classWGANGeneratorLoss_1a5354d9a780b8be53775610526787b3ec"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANGeneratorLoss_1a5354d9a780b8be53775610526787b3ec"><code>ForwardPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 순전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<h4 id="classWGANGeneratorLoss_1a36f645111dde1d73aa924ed539486286"><code>public inline virtual</code><a href="#classTensor"><code>Tensor</code></a><code>&lt; DTYPE &gt; *</code><a href="#classWGANGeneratorLoss_1a36f645111dde1d73aa924ed539486286"><code>BackPropagate</code></a><code>(int pTime)</code></h4>
<p>LossFunction의 역전파를 수행하는 메소드</p>
<h5>Parameters</h5>
<ul>
<li><code>pTime</code> 학습 데이터 텐서의 Time 인덱스, 값을 전달하지 않을 시 0으로 초기화 됨 </li>
</ul>
<h5>Returns</h5>
<p>NULL</p>
<p>Generated by <a href="https://sourcey.com/moxygen">Moxygen</a></p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../about/" title="About" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  이전
                </span>
                About
              </div>
            </div>
          </a>
        
        
          <a href="../dev/wicwiu/about/" title="1. About WICWIU" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  다음
                </span>
                1. About WICWIU
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2018-2020 HGU DL Lab
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://github.com/WICWIU" target="_blank" rel="noopener" title="github.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.c3dc8c49.min.js"></script>
      <script src="../assets/javascripts/bundle.f9edbbd5.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "\ud074\ub9bd\ubcf4\ub4dc\ub85c \ubcf5\uc0ac", "clipboard.copied": "\ud074\ub9bd\ubcf4\ub4dc\uc5d0 \ubcf5\uc0ac\ub428", "search.config.lang": "en", "search.config.pipeline": " ", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "\uac80\uc0c9\uc5b4\ub97c \uc785\ub825\ud558\uc138\uc694", "search.result.none": "\uac80\uc0c9\uc5b4\uc640 \uc77c\uce58\ud558\ub294 \ubb38\uc11c\uac00 \uc5c6\uc2b5\ub2c8\ub2e4", "search.result.one": "1\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c", "search.result.other": "#\uac1c\uc758 \uc77c\uce58\ud558\ub294 \ubb38\uc11c"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.8e2cddea.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>